{"cells":[{"source":["from IPython import get_ipython, display\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" <a href=\"https://colab.research.google.com/github/vyphamhung10/khoa_luan/blob/master/price_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"],"metadata":{}},{"source":["# -*- coding: utf-8 -*-\n","# region Import\n","# Data download\n","# Import basic\n","import csv\n","import math\n","import os\n","import warnings\n","# Init google drive\n","# from google.colab import drive\n","from datetime import datetime\n","from timeit import default_timer as timer\n","\n","import numpy as np\n","import pandas as pd\n","# Plottool\n","import plotly.graph_objs as go\n","# IPython\n","from IPython.display import display\n","# Hyperopt bayesian optimization\n","from hyperopt import hp, Trials, tpe, fmin, STATUS_OK, partial\n","# Keras\n","import tensorflow as tf\n","import tensorflow \n","from tensorflow.keras import Sequential\n","from tensorflow.keras import optimizers\n","from tensorflow.keras.activations import softmax\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint  \n","from tensorflow.keras.initializers import random_normal, Ones \n","from tensorflow.keras.layers import LSTM, Dropout, Input, Dense\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.models import load_model\n","import tensorflow.keras.backend as K\n","# SKLearn\n","from sklearn.metrics import mean_absolute_error, mean_squared_error\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.externals import joblib\n","# Yfinance\n","get_ipython().system('pip install yfinance')\n","import yfinance as yf\n","\n","get_ipython().system('pip install pandas_market_calendars')\n","import pandas_market_calendars as mcal\n","\n","# endregion\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# Region config config\n","try:\n","  from google.colab import drive\n","  IN_COLAB = True\n","except:\n","  IN_COLAB = False\n","\n","config = {}\n","config['current_timestamp'] = datetime.now().strftime('%d%m%Y_%H%M%S')\n","if not IN_COLAB:\n","    \n","    # region File mount and config\n","    # drive.mount('/content/gdrive', force_remount=True)\n","    config['root_dir'] = \"\"\n","    \n","    config['time_dir'] = os.path.join(config['root_dir'], \"result\")\n","    config['time_dir'] = os.path.join(config['time_dir'], '')\n","    \n","    config['data_dir'] = os.path.join(config['root_dir'], 'data')\n","    config['model_dir'] = os.path.join(config['time_dir'], 'model')\n","    config['plot_dir'] = os.path.join(config['time_dir'], 'plot')\n","    config['result_dir'] = os.path.join(config['time_dir'], 'result')\n","    # Create folder if not exists\n","    \n","    if not os.path.exists(config['data_dir']):\n","        os.makedirs(config['data_dir'])\n","\n","    if not os.path.exists(config['model_dir']):\n","        os.makedirs(config['model_dir'])\n","    \n","    if not os.path.exists(config['plot_dir']):\n","        os.makedirs(config['plot_dir'])\n","        \n","    if not os.path.exists(config['result_dir']):\n","        os.makedirs(config['result_dir'])\n","else:\n","    drive.mount('/content/gdrive', force_remount=True)\n","    config['root_dir'] = \"/content/gdrive/My Drive/stock\"\n","    \n","    config['time_dir'] = os.path.join(config['root_dir'], \"result\")\n","    \n","    config['data_dir'] = os.path.join(config['root_dir'], \"data\")\n","    config['model_dir'] = os.path.join(config['time_dir'], 'model')\n","    config['plot_dir'] = os.path.join(config['time_dir'], 'plot')\n","    config['result_dir'] = os.path.join(config['time_dir'], 'result')\n","\n","config['input_col'] = ['<Close>', '<Open>', '<High>', '<Low>']\n","config['output_col'] = ['<Close>']\n","config['time_col'] = ['<DTYYYYMMDD>']\n","# Number of session to prediction as one time\n","config['prediction_size'] = 1\n","# For each time model is train, the first is display\n","config['sample_display_test_size'] = 5\n","# windows size\n","config['windows_size'] = 5\n","config['train_split'] = 0.7\n","config['validation_split'] = 0.1\n","config['test_split'] = 0.2\n","# model config\n","config['lstm_neuron_count'] = 128\n","config['lstm_layer_count'] = 5\n","config['drop_rate'] = 0.2\n","config['stateful'] = False\n","\n","# data normalize\n","config['scaler_feature_range'] = (0, 1)\n","\n","# train\n","config['epochs'] = 200\n","config['batch_size'] = 5\n","config['start_time'] = datetime(2006, 1, 1, 0, 0)\n","config['end_time'] = datetime(2016, 11, 13, 0, 0) \n","config['force_train'] = False\n","\n","pd.options.display.max_columns = 12\n","pd.options.display.max_rows = 24\n","\n","# disable warnings in Anaconda\n","warnings.filterwarnings('ignore')\n","\n","# endregion\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# region Data Loading\n","def get_data(config, stock_file_name = '000002.SS'):\n","    data_dir = config['data_dir']\n","    start_time = config['start_time']\n","    end_time = config['end_time']\n","    time_col = config['time_col']\n","    time_col = time_col[0]\n","    data_file_path = f'{data_dir}/{stock_file_name}.csv'\n","\n","    if os.path.exists(data_file_path):\n","        df_org = pd.read_csv(data_file_path, parse_dates=[time_col])\n","        # df_org = df_org[np.logical_and(df_org[time_col].dt.to_pydatetime() >= config['start_time'], df_org[time_col].dt.to_pydatetime() <= config['end_time'])]\n","    else:\n","        df_org = yf.download(stock_file_name, interval=\"1d\")\n","        df_org.to_csv(data_file_path)\n","\n","\n","    df_org = df_org.sort_values(time_col)\n","    df_org.reset_index(inplace=True)\n","\n","    return df_org\n","\n","def calculate_change(df, target_col_name = 'Close', change_col_name = 'Change'):\n","    df_change = df[target_col_name].copy()\n","    df_change = df_change.pct_change(periods=1, fill_method='ffill')\n","    df_change = df_change.fillna(0)\n","\n","    df[change_col_name] = df_change\n","\n","    return df\n","\n","# region Data ploting\n","def plot_ohlc(df, stock_name):\n","    trace = go.Ohlc(x=df['Date'],\n","                    open=df['Open'],\n","                    high=df['High'],\n","                    low=df['Low'],\n","                    close=df['Close'],\n","                    increasing=dict(line=dict(color='#58FA58')),\n","                    decreasing=dict(line=dict(color='#FA5858')))\n","\n","    layout = {\n","        'title': f'{stock_name} Historical Price',\n","        'xaxis': {'title': 'Date',\n","                  'rangeslider': {'visible': False}},\n","        'yaxis': {'title': f'Price'}\n","    }\n","\n","    data = [trace]\n","\n","    fig = go.Figure(data=data, layout=layout)\n","    fig.show()\n","    return fig\n","\n","def get_df_intersect_col(df, col_list):\n","    return np.intersect1d(df.columns.values, col_list, assume_unique=True)\n","\n","# endregion\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# region Declare model\n","# declare model\n","def none_to_default(value, value_if_fall):\n","    try:\n","        return value_if_fall if value is None else value\n","    except:\n","        return value_if_fall\n","\n","def softmax_axis1(x):\n","    return softmax(x, axis=1)\n","\n","\n","def get_model(config = config):\n","    input_dim = config['input_dim']\n","    windows_size = config['windows_size']\n","    output_dim = config['output_dim']\n","    lstm_neuron_count = none_to_default(config['lstm_neuron_count'], 128)\n","    lstm_layer_count = none_to_default(config['lstm_layer_count'], 5)\n","    drop_rate = none_to_default(config['drop_rate'], 0.2)\n","    stateful = none_to_default(config['stateful'], False)\n","    batch_size = config['batch_size']\n","    model = Sequential()\n","    \n","    if stateful:\n","      model.add(LSTM(units=lstm_neuron_count, batch_input_shape=(batch_size, windows_size, input_dim), return_sequences=True, stateful = stateful, dropout=drop_rate, recurrent_dropout=drop_rate))\n","    else:\n","      model.add(LSTM(units=lstm_neuron_count, input_shape=(windows_size, input_dim), return_sequences=True, stateful = stateful, dropout=drop_rate, recurrent_dropout=drop_rate))\n","\n","    for i in range(lstm_layer_count - 2):\n","        model.add(LSTM(units=lstm_neuron_count, return_sequences=True, stateful = stateful, dropout=drop_rate, recurrent_dropout=drop_rate))\n","        model.add(Dropout(rate=drop_rate))\n","    \n","    model.add(LSTM(units=lstm_neuron_count, return_sequences=False, stateful = stateful, dropout=drop_rate, recurrent_dropout=drop_rate))\n","    model.add(Dropout(rate=drop_rate))\n","    model.add(Dense(output_dim, activation='linear'))\n","    opt = optimizers.Adam(lr=0.05, beta_1=0.99, beta_2=0.999)\n","    softmax_activation = softmax_axis1\n","    model.compile(loss='MSE', optimizer='adam')\n","    \n","    return model\n","\n","\n","# endregion\n","\n","# region Error metric\n","def mean_absolute_percentage_error(y_true, y_pred):\n","    y_true, y_pred = np.array(y_true), np.array(y_pred)\n","\n","    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n","\n","def root_mean_square_error(y_true, y_pred):\n","    y_true, y_pred = np.array(y_true), np.array(y_pred)\n","\n","    return np.mean((y_true - y_pred) / y_true)\n","\n","\n","def relative_root_mean_square_error(y_true, y_pred):\n","    y_true, y_pred = np.array(y_true), np.array(y_pred)\n","    res = (y_true - y_pred) / y_true\n","    res = np.power(res, 2)\n","    res = np.mean(res)\n","    res = math.sqrt(res)\n","\n","    return res\n","\n","\n","# endregion\n","\n","# region Data preprocessing\n","# reprocessing data\n","def next_window(df, i, config = config):\n","    windows_size = config['windows_size']\n","    prediction_size = config['prediction_size']\n","    input_col = config['input_col']\n","    output_col = config['output_col']\n","    time_col = config['time_col']\n","\n","    '''Generates the next data window from the given index location i'''\n","    window = df[i: i + windows_size + prediction_size]\n","    x = window[input_col][:-prediction_size]\n","    y = window[output_col][-prediction_size:]\n","    y_time = window[time_col][-prediction_size:]\n","    return x, y, y_time\n","\n","def smooting_data(df, config = config):\n","    windows_size = config['windows_size']\n","    return df.ewm(span=windows_size).mean()\n","\n","def preprocessing_data(df, config = config):\n","    '''\n","    Create x, y train data windows\n","    Warning: batch method, not generative, make sure you have enough memory \n","    '''\n","    windows_size = config['windows_size']\n","    prediction_size = config['prediction_size']\n","    input_col = config['input_col']\n","    output_col = config['output_col']\n","    time_col = config['time_col']\n","\n","    data_x = []\n","    data_y = []\n","    data_y_time = []\n","    for i in range(len(df) - windows_size - prediction_size):\n","        x, y, y_time = next_window(df, i, config)\n","        data_x.append(x.values)\n","        data_y.append(y.values)\n","        data_y_time.append(y_time)\n","\n","    time = pd.concat(data_y_time)\n","\n","    return np.array(data_x), np.array(data_y), time.values\n","\n","# endregion\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# region Model train\n","# Trainning model\n","def train_model(model, X_train, y_train, save_fname):\n","    model_save_fname = os.path.join(config['model_dir'], '%s.h5' % (save_fname))\n","    callbacks = [\n","        EarlyStopping(monitor='loss', patience=100),\n","        ModelCheckpoint(filepath=model_save_fname, monitor='loss', save_best_only=True)\n","    ]\n","    epochs = none_to_default(config['epochs'], 1000)\n","    batch_size = none_to_default(config['batch_size'], 1000)\n","    train_split = none_to_default(config['train_split'], 0.7)\n","    validation_split = none_to_default(config['validation_split'], 0.1)\n","\n","    history = model.fit(\n","        X_train,\n","        y_train,\n","        epochs=epochs,\n","        batch_size=batch_size,\n","        validation_split= float(validation_split) / float(train_split),\n","        verbose=1,\n","        callbacks=callbacks,\n","        shuffle=False)\n","\n","    model.save(model_save_fname)\n","    \n","    return history\n","\n","def load_save_model(stock_name):\n","    model_save_fname = os.path.join(config['model_dir'], '%s.h5' % (stock_name))\n","    scaler_save_fname = os.path.join(config['model_dir'], '%s.scaler' % (stock_name))\n","    \n","    if os.path.exists(model_save_fname) and os.path.exists(scaler_save_fname):\n","        return {'model' : load_model(model_save_fname), 'scaler': joblib.load(scaler_save_fname)}\n","        \n","    return None\n","\n","# endregion"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["def plot_test_result(df_test_result, stock_name, config):\n","    # Plotly\n","    output_col = config['output_col']\n","    prediction_col = config['prediction_col']\n","    time_col = config['time_col']\n","    trace0 = go.Scatter(\n","        x=df_test_result.index,\n","        y=df_test_result[output_col[0]],\n","        name='Thực tế',\n","        line=dict(\n","            color=('#5042f4'),\n","            width=2)\n","    )\n","\n","    trace1 = go.Scatter(\n","        x=df_test_result.index,\n","        y=df_test_result[prediction_col],\n","        name='Dự đoán',\n","        line=dict(\n","            color=('#005b4e'),\n","            width=2,\n","            dash='dot'\n","        )  # dash options include 'dash', 'dot', and 'dashdot'\n","    )\n","\n","    data = [trace0, trace1]\n","\n","    # Edit the layout\n","    layout = dict(title='Biểu đồ dự đoán',\n","                  xaxis=dict(title='Date'),\n","                  yaxis=dict(title='Price'),\n","                  paper_bgcolor='#FFF9F5',\n","                  plot_bgcolor='#FFF9F5'\n","                  )\n","\n","    fig = go.Figure(data=data, layout=layout)\n","    plot_dir = config['plot_dir']\n","    fig.show()\n","    fig.write_html(os.path.join(plot_dir, '%s_test.html' % (stock_name)), auto_open=False)\n","# endregion\n","\n","# Region do main thing\n","def do_train(stock_name, config = config): \n","    result = {}\n","\n","    train_split = config['train_split']\n","    validation_split = config['validation_split']\n","    test_split = config['test_split']\n","\n","    df = get_data(config, stock_name)\n","    input_col = get_df_intersect_col(df, config['input_col'])\n","    output_col = get_df_intersect_col(df, config['output_col'])\n","    time_col = get_df_intersect_col(df, config['time_col'])\n","    \n","    config['input_col'] = input_col\n","    config['output_col'] = output_col\n","    config['time_col'] = time_col\n","    config['input_dim'] = len(input_col)\n","    config['output_dim'] = len(output_col)\n","    \n","\n","    df_train, df_test = train_test_split(df, test_size=test_split, shuffle=False)\n","    \n","    model = get_model(config=config)\n","    \n","    start = timer()\n","\n","    # Handle data\n","    scaler_feature_range = config.get('scaler_feature_range', (0, 1))\n","    scaler = MinMaxScaler(feature_range=scaler_feature_range)\n","    scaled_cols = scaler.fit(df_train[input_col])\n","\n","    # Save scaler\n","    scaler_save_fname = os.path.join(config['model_dir'], '%s.scaler' % (stock_name))\n","    joblib.dump(scaler, scaler_save_fname) \n","    \n","    # Transform train data\n","    scaled_cols = scaler.transform(df_train[input_col])\n","    df_train[input_col] = scaled_cols\n","\n","    X_train, y_train, time_train = preprocessing_data(df_train, config)\n","\n","    # Reshape data\n","    y_train = y_train.reshape((y_train.shape[0], y_train.shape[1]))\n","\n","    # Perform n_train\n","    history = train_model(model, X_train, y_train, stock_name)\n","    \n","    run_time = timer() - start\n","\n","    return {'scaler' : scaler, 'model' : model, 'history' : history, 'run_time' : run_time} \n","    # %%\n","def do_test(stock_name, data, config = config):\n","\n","    prediction_size = config['prediction_size']\n","    input_col =  config['input_col']\n","    output_col =  config['output_col']\n","    time_col =  config['time_col']\n","    batch_size =  config['batch_size']\n","    \n","    df = get_data(config, stock_name)\n","    input_col = get_df_intersect_col(df, input_col)\n","    output_col = get_df_intersect_col(df, output_col)\n","    output_col = output_col[0]\n","    time_col = get_df_intersect_col(df, time_col)\n","    time_col =  time_col[0]\n","    df_org = df[[output_col, time_col]].copy()\n","\n","    test_split = config['test_split']\n","    df_train, df_test = train_test_split(df, test_size=test_split, shuffle=False)\n","    scaler = data['scaler']\n","    scaled_cols = scaler.transform(df_test[input_col])\n","    df_test[input_col] = scaled_cols\n","\n","    X_test, y_test, time_test = preprocessing_data(df_test, config)\n","    \n","    # Reshape data\n","    y_test = y_test.reshape((y_test.shape[0], y_test.shape[1]))\n","\n","    # Test generated loss\n","    model = data['model']\n","    y_pred = model.predict(X_test)\n","    y_pred = np.repeat(y_pred, len(input_col), axis=1)\n","    y_pred = scaler.inverse_transform(y_pred)[:, [0]]\n","    y_pred = pd.Series(y_pred.flatten())\n","\n","    df_test_result = pd.DataFrame(time_test, columns=[time_col])\n","    prediction_col = f'{output_col} Prediction'\n","    config['prediction_col'] = prediction_col\n","    df_test_result[config['prediction_col']] = y_pred\n","    df_test_result.set_index(time_col, inplace=True)\n","\n","    df_test_result = df_test_result.join(df_org.set_index(time_col))\n","\n","\n","    score = model.evaluate(X_test, y_test, batch_size, 1)\n","    mae = mean_absolute_error(df_test_result[output_col], df_test_result[prediction_col])\n","    mse = mean_squared_error(df_test_result[output_col], df_test_result[prediction_col])\n","    mape = mean_absolute_percentage_error(df_test_result[output_col], df_test_result[prediction_col])\n","    rrmse = relative_root_mean_square_error(df_test_result[output_col], df_test_result[prediction_col])\n","\n","    # File to save first results\\n\n","    result_dir = config['result_dir']\n","    result_save_fname = os.path.join(result_dir, 'result_%s.csv' % (stock_name))\n","    of_connection = open(result_save_fname, 'w')\n","    writer = csv.writer(of_connection)\n","    # Write the headers to the file\\n\n","    writer.writerow(['stock_name', 'score', 'mae', 'mse', 'mape', 'rrmse', 'time_stamp'])\n","    writer.writerow([stock_name, score, mae, mse, mape, rrmse, datetime.now().strftime('%d%m%Y_%H%M%S')])\n","    of_connection.close()\n","    # write data\n","    return  {'score' : score, 'mae' : mae, 'df': df_test_result, 'mse' : mse, 'mape' : mape, 'rrmse' : rrmse}\n","\n","def make_future_prediction(model, scaler, future_step, config):\n","    df = get_data(config, stock_name)\n","    windows_size = config['windows_size']\n","    input_col = config['input_col']\n","    output_col = config['output_col']\n","    time_col = config['time_col']\n","    prediction_col = config['prediction_col']\n","\n","    time_col = time_col[0]\n","    prediction_size = config['prediction_size']\n","    batch_size = config['batch_size']\n","\n","    stock_calendar = mcal.get_calendar('stock')\n","    time = df[time_col][-1:].values[0]\n","    stock_time = stock_calendar.valid_days(start_date=time + np.timedelta64(1, 'D'), end_date=time + np.timedelta64(future_step * 2, 'D'))\n","    \n","    pred_res = df[input_col][-batch_size:].copy()\n","    pred_res[prediction_col] = pred_res[output_col]\n","    '''Generates the next data window from the given index location i'''\n","    for step in range(future_step):\n","        x = pred_res[input_col][-windows_size:].values\n","        x = scaler.transform(x)\n","        x = x.reshape(1, x.shape[0], x.shape[1])\n","            \n","        y_pred = model.predict(x)\n","        y_pred = np.repeat(y_pred, len(input_col), axis=1)\n","        y_pred = scaler.inverse_transform(y_pred)[:, [0]][0][0]\n","\n","        pred_res = pred_res.append({time_col : stock_time[step], prediction_col:y_pred, output_col:np.repeat(y_pred, len(input_col), axis=1)}, ignore_index=True )\n","\n","    return pred_res\n","\n","def plot_furure_prediction(df, df_predict, stock_name, config):\n","    # Plotly\n","    output_col = config['output_col']\n","    prediction_col = config['prediction_col']\n","    time_col = config['time_col']\n","    time_col = time_col[0]\n","    trace0 = go.Scatter(\n","        x=df.index,\n","        y=df[output_col[0]],\n","        name='Thực tế',\n","        line=dict(\n","            color=('#5042f4'),\n","            width=2)\n","    )\n","\n","    trace1 = go.Scatter(\n","        x=df_predict[time_col],\n","        y=df_predict[prediction_col],\n","        name='Dự đoán',\n","        line=dict(\n","            color=('#005b4e'),\n","            width=2,\n","            dash='dot'\n","        )  # dash options include 'dash', 'dot', and 'dashdot'\n","    )\n","\n","    data = [trace0, trace1]\n","\n","    # Edit the layout\n","    layout = dict(title='Biểu đồ dự đoán',\n","                  xaxis=dict(title='Date'),\n","                  yaxis=dict(title='Price'),\n","                  paper_bgcolor='#FFF9F5',\n","                  plot_bgcolor='#FFF9F5'\n","                  )\n","\n","    fig = go.Figure(data=data, layout=layout)\n","    plot_dir = config[\"plot_dir\"]\n","    fig.write_html(os.path.join(plot_dir, '%s_predict.html' % (stock_name)), auto_open=False)\n","    fig.show()\n","# endregion\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# Make future frame For 6 year, 3 year, 1 year, 1 month.\n","\n","# Hyperparameter Tuning\n","#   + Train / test split valdiation\n","#   + Droprate\n","#   + Activation\n","#   + Number of layer\n","\n","# Agents \n","# Stock List\n","if __name__ == \"__main__\":\n","    stock_name_list = ['FLC']\n","\n","    for stock_name in stock_name_list:\n","        force_train = config.get('force_train', False)\n","        train_result = load_model(stock_name, config)\n","        if train_result is None or force_train:\n","            train_result = do_train(stock_name, config)\n","        test_result = do_test(stock_name, train_result ,config)\n","        \n","        future_predict = make_future_prediction(train_result['model'], train_result['scaler'] ,10, config)\n","        plot_test_result(test_result['df'], stock_name, config)\n","        plot_furure_prediction(test_result['df'], future_predict, stock_name, config)\n","\n","        result_dir = config['result_dir']\n","        future_pred_file_path = f'{result_dir}/{stock_name}_pred.csv'\n","        future_predict.to_csv(future_pred_file_path)\n","\n","        \n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}