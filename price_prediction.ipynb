{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  },
  "colab": {
   "name": "price_prediction.ipynb",
   "provenance": [],
   "collapsed_sections": []
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "id": "mlCxjIkEb8Gv",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 79
    },
    "outputId": "ccf4752a-e64f-4b1e-825e-79a2cd639931"
   },
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"working.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1llsccnklCzs7EZSELP6MVysncixaZnQR\n",
    "\n",
    "## Notebook settings\n",
    "\"\"\"\n",
    "# region Import\n",
    "# Data download\n",
    "# Import basic\n",
    "import csv\n",
    "import math\n",
    "import os\n",
    "import warnings\n",
    "# Init google drive\n",
    "# from google.colab import drive\n",
    "from datetime import datetime\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Plottool\n",
    "import plotly.graph_objs as go\n",
    "# IPython\n",
    "from IPython.display import display\n",
    "# Hyperopt bayesian optimization\n",
    "from hyperopt import hp, Trials, tpe, fmin, STATUS_OK, partial\n",
    "# Keras\n",
    "from keras import Sequential\n",
    "from keras import optimizers\n",
    "from keras.activations import softmax\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint  \n",
    "from keras.initializers import random_normal, Ones \n",
    "from keras.layers import LSTM, Dropout, Input\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "# SKLearn\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# endregion"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "id": "TgJgqIMKb8G9",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "ea98594d-e263-4bf3-dea0-146f799695a7"
   },
   "source": [
    "try:\n",
    "  from google.colab import drive\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "\n",
    "current_timestamp = datetime.now().strftime('%d%m%Y_%H%M%S')\n",
    "if not IN_COLAB:\n",
    "    \n",
    "    # region File mount and config\n",
    "    # drive.mount('/content/gdrive', force_remount=True)\n",
    "    root_dir = \"\"\n",
    "    \n",
    "    time_dir = os.path.join(root_dir, \"result\")\n",
    "    time_dir = os.path.join(time_dir, current_timestamp)\n",
    "    \n",
    "    data_dir = root_dir + 'data'\n",
    "    model_dir = os.path.join(time_dir, 'model')\n",
    "    plot_dir = os.path.join(time_dir, 'plot')\n",
    "    result_dir = os.path.join(time_dir, 'result')\n",
    "    # Create folder if not exists\n",
    "    \n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "        \n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    if not os.path.exists(plot_dir):\n",
    "        os.makedirs(plot_dir)\n",
    "        \n",
    "    if not os.path.exists(result_dir):\n",
    "        os.makedirs(result_dir)\n",
    "else:\n",
    "    # region File mount and config\n",
    "    drive.mount('/content/gdrive', force_remount=True)\n",
    "    root_dir = \"/content/gdrive/My Drive/stock\"\n",
    "    \n",
    "    time_dir = os.path.join(root_dir, \"result\")\n",
    "    \n",
    "    data_dir = os.path.join(root_dir, \"data\")\n",
    "    model_dir = os.path.join(time_dir, 'model')\n",
    "    plot_dir = os.path.join(time_dir, 'plot')\n",
    "    result_dir = os.path.join(time_dir, 'result')\n",
    "    \n",
    "pd.options.display.max_columns = 12\n",
    "pd.options.display.max_rows = 24\n",
    "\n",
    "# disable warnings in Anaconda\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# endregion"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "id": "Vz_7V4YIb8HF",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# region Data Loading\n",
    "stock_name = '000001.SS'  # SSE Composite Index\n",
    "# df_org = yf.download(stock_name, start=\"1991-01-01\", end=\"2016-12-31\", interval=\"1wk\")\n",
    "df_org = pd.read_csv(f'{data_dir}/{stock_name}.csv', parse_dates=['Date'])\n",
    "df_org = df_org.sort_values('Date')\n",
    "# df_org.to_csv(f'{base_dir}/{stock_name}.csv')\n",
    "df_org.reset_index(inplace=True)\n",
    "df_org = df_org[['Date', 'Close', 'Open', 'High', 'Low', 'Adj Close', 'Volume']]\n",
    "\n",
    "# endregion"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "id": "DB8zk98xb8HN",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# region Data ploting\n",
    "def plot_ohlc(df):\n",
    "    trace = go.Ohlc(x=df['Date'],\n",
    "                    open=df['Open'],\n",
    "                    high=df['High'],\n",
    "                    low=df['Low'],\n",
    "                    close=df['Close'],\n",
    "                    increasing=dict(line=dict(color='#58FA58')),\n",
    "                    decreasing=dict(line=dict(color='#FA5858')))\n",
    "\n",
    "    layout = {\n",
    "        'title': f'{stock_name} Historical Price',\n",
    "        'xaxis': {'title': 'Date',\n",
    "                  'rangeslider': {'visible': False}},\n",
    "        'yaxis': {'title': f'Price'}\n",
    "    }\n",
    "\n",
    "    data = [trace]\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    fig.write_html(os.path.join(plot_dir, '%s_ohlc.html' % (stock_name)), auto_open=False)\n",
    "\n",
    "\n",
    "plot_ohlc(df_org)\n",
    "# endregion"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "id": "LfCTIEcwb8HV",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# region Create csv result file\n",
    "# File to save first results\n",
    "result_save_fname = os.path.join(result_dir, 'result_%s-%s.csv' % (stock_name, current_timestamp))\n",
    "of_connection = open(result_save_fname, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "# Write the headers to the file\n",
    "writer.writerow(['stock_name', 'year', 'loss', 'params', 'iteration', 'windows_size', 'train_time'])\n",
    "of_connection.close()\n",
    "\n",
    "# Create file to save bayer best\n",
    "bayer_save_fname = os.path.join(result_dir, 'bayer_best_%s-%s.csv' % (stock_name, current_timestamp))\n",
    "of_connection = open(bayer_save_fname, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "# Write the headers to the file\n",
    "writer.writerow(['stock_name', 'year', 'params', 'model_save_location'])\n",
    "of_connection.close()\n",
    "# endregion"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "id": "3BXIGePCb8Hf",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "outputId": "5155e34c-4ff9-46e6-e41f-4c656c7a75b3"
   },
   "source": [
    "# region Sample data\n",
    "\n",
    "df_org.sample(10)\n",
    "\n",
    "# endregion"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>2005-10-25</td>\n",
       "      <td>1092.817017</td>\n",
       "      <td>1140.172974</td>\n",
       "      <td>1140.172974</td>\n",
       "      <td>1067.406982</td>\n",
       "      <td>1092.817017</td>\n",
       "      <td>86200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>2010-04-27</td>\n",
       "      <td>2870.610107</td>\n",
       "      <td>2962.145020</td>\n",
       "      <td>2962.145020</td>\n",
       "      <td>2820.948975</td>\n",
       "      <td>2870.610107</td>\n",
       "      <td>370200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>2005-03-22</td>\n",
       "      <td>1200.113037</td>\n",
       "      <td>1230.682007</td>\n",
       "      <td>1231.676025</td>\n",
       "      <td>1185.456055</td>\n",
       "      <td>1200.113037</td>\n",
       "      <td>58000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>2013-09-17</td>\n",
       "      <td>2221.043945</td>\n",
       "      <td>2230.387939</td>\n",
       "      <td>2230.927979</td>\n",
       "      <td>2172.042969</td>\n",
       "      <td>2221.043945</td>\n",
       "      <td>402800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>2004-01-27</td>\n",
       "      <td>1623.880005</td>\n",
       "      <td>1600.430054</td>\n",
       "      <td>1650.291016</td>\n",
       "      <td>1585.958008</td>\n",
       "      <td>1623.880005</td>\n",
       "      <td>77000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>2002-12-10</td>\n",
       "      <td>1408.515015</td>\n",
       "      <td>1400.557983</td>\n",
       "      <td>1409.942993</td>\n",
       "      <td>1367.312012</td>\n",
       "      <td>1408.515015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2005-08-23</td>\n",
       "      <td>1154.427979</td>\n",
       "      <td>1158.828979</td>\n",
       "      <td>1174.536987</td>\n",
       "      <td>1139.239014</td>\n",
       "      <td>1154.427979</td>\n",
       "      <td>117200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1993-03-30</td>\n",
       "      <td>947.869995</td>\n",
       "      <td>958.049988</td>\n",
       "      <td>958.049988</td>\n",
       "      <td>925.909973</td>\n",
       "      <td>947.869995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>1993-08-10</td>\n",
       "      <td>1023.869995</td>\n",
       "      <td>862.080017</td>\n",
       "      <td>1023.869995</td>\n",
       "      <td>862.080017</td>\n",
       "      <td>1023.869995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>2010-07-27</td>\n",
       "      <td>2672.516113</td>\n",
       "      <td>2581.590088</td>\n",
       "      <td>2675.761963</td>\n",
       "      <td>2564.156006</td>\n",
       "      <td>2672.516113</td>\n",
       "      <td>562600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date        Close         Open         High          Low  \\\n",
       "773  2005-10-25  1092.817017  1140.172974  1140.172974  1067.406982   \n",
       "1007 2010-04-27  2870.610107  2962.145020  2962.145020  2820.948975   \n",
       "742  2005-03-22  1200.113037  1230.682007  1231.676025  1185.456055   \n",
       "1184 2013-09-17  2221.043945  2230.387939  2230.927979  2172.042969   \n",
       "682  2004-01-27  1623.880005  1600.430054  1650.291016  1585.958008   \n",
       "623  2002-12-10  1408.515015  1400.557983  1409.942993  1367.312012   \n",
       "764  2005-08-23  1154.427979  1158.828979  1174.536987  1139.239014   \n",
       "117  1993-03-30   947.869995   958.049988   958.049988   925.909973   \n",
       "136  1993-08-10  1023.869995   862.080017  1023.869995   862.080017   \n",
       "1020 2010-07-27  2672.516113  2581.590088  2675.761963  2564.156006   \n",
       "\n",
       "        Adj Close  Volume  \n",
       "773   1092.817017   86200  \n",
       "1007  2870.610107  370200  \n",
       "742   1200.113037   58000  \n",
       "1184  2221.043945  402800  \n",
       "682   1623.880005   77000  \n",
       "623   1408.515015       0  \n",
       "764   1154.427979  117200  \n",
       "117    947.869995       0  \n",
       "136   1023.869995       0  \n",
       "1020  2672.516113  562600  "
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 6
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "id": "QTdlFgoob8Hm",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# region Const\n",
    "# Declare const\n",
    "input_col = ['Close', 'Open', 'High', 'Low', 'Adj Close', 'Volume']\n",
    "output_col = ['Close']\n",
    "time_col = ['Date']\n",
    "\n",
    "# Input dimension\n",
    "input_dim = len(input_col)\n",
    "# Output dimension\n",
    "output_dim = len(output_col)\n",
    "\n",
    "# Number of session to prediction as one time\n",
    "prediction_size = 1\n",
    "# For each time model is train, the first is display\n",
    "sample_display_test_size = 5\n",
    "# Max bayer iteration\n",
    "bayer_max_evals = 100\n",
    "\n",
    "\n",
    "# endregion"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "id": "Qk2bP_fgb8Hs",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# region Declare model\n",
    "# declare model\n",
    "def softMaxAxis1(x):\n",
    "    return softmax(x, axis=1)\n",
    "\n",
    "\n",
    "def get_model(input_dim, window_size, output_dim, lstm_layer_count=5, drop_rate=0.2):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=100, input_shape=(window_size, input_dim), return_sequences=True))\n",
    "    model.add(Dropout(rate=drop_rate))\n",
    "\n",
    "    for i in range(lstm_layer_count - 2):\n",
    "        model.add(LSTM(units=100, return_sequences=True))\n",
    "        model.add(Dropout(rate=drop_rate))\n",
    "    \n",
    "    model.add(LSTM(output_dim, activation=softMaxAxis1))\n",
    "    opt = optimizers.Adam(lr=0.05, beta_1=0.99, beta_2=0.999)\n",
    "    model.compile(loss='MAE', optimizer=opt)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# endregion"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "shZCZlwbfSA6",
    "colab_type": "code",
    "colab": {}
   },
   "source": [],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "id": "y0p2kGBFb8Hx",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# region Error metric\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def root_mean_square_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "\n",
    "    return np.mean((y_true - y_pred) / y_true)\n",
    "\n",
    "\n",
    "def relative_root_mean_square_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    res = (y_true - y_pred) / y_true\n",
    "    res = np.power(res, 2)\n",
    "    res = np.mean(res)\n",
    "    res = math.sqrt(res)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "# endregion"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "id": "TQexGPe5b8H3",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# region Data preprocessing\n",
    "# reprocessing data\n",
    "def next_window(df, i, windows_size, prediction_size, input_col, output_col, time_col):\n",
    "    '''Generates the next data window from the given index location i'''\n",
    "    window = df[i: i + windows_size + prediction_size]\n",
    "    x = window[input_col][:-prediction_size]\n",
    "    y = window[output_col][-prediction_size:]\n",
    "    y_time = window[time_col][-prediction_size:]\n",
    "    return x, y, y_time\n",
    "\n",
    "def smooting_data(df, window_size):\n",
    "    return df.ewm(span=window_size).mean()\n",
    "\n",
    "def preprocessing_data(df, windows_size, prediction_size, input_col, output_col, time_col):\n",
    "    '''\n",
    "    Create x, y train data windows\n",
    "    Warning: batch method, not generative, make sure you have enough memory to\n",
    "    load data, otherwise use generate_training_window() method.\n",
    "    '''\n",
    "\n",
    "\n",
    "    data_x = []\n",
    "    data_y = []\n",
    "    data_y_time = []\n",
    "    for i in range(len(df) - windows_size - prediction_size):\n",
    "        x, y, y_time = next_window(df, i, windows_size, prediction_size, input_col, output_col, time_col)\n",
    "        data_x.append(x.values)\n",
    "        data_y.append(y.values)\n",
    "        data_y_time.append(y_time)\n",
    "\n",
    "    time = pd.concat(data_y_time)\n",
    "\n",
    "    return np.array(data_x), np.array(data_y), time.values\n",
    "\n",
    "\n",
    "def split_train_test_data(X, y):\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "    return X_train, y_train, X_valid, y_valid\n",
    "\n",
    "\n",
    "# endregion"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "id": "KdX8GHtvb8H9",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# region Model train\n",
    "# Trainning model\n",
    "def train_model(model, X_train, y_train, X_valid, y_valid, stock_name, year, window_size):\n",
    "    if not IN_COLAB:\n",
    "        model_save_fname = os.path.join(model_dir, '%s-%s-w%d.h5' % (stock_name, year, window_size))\n",
    "    else:\n",
    "        model_save_fname = os.path.join(model_dir, '%s-%s-w%d-%s.h5' % (stock_name, year, window_size, datetime.now().strftime('%d%m%Y_%H%M%S')))\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=100),\n",
    "        ModelCheckpoint(filepath=model_save_fname, monitor='val_loss', save_best_only=True)\n",
    "    ]\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=1000,\n",
    "        batch_size=10000,\n",
    "        validation_data=(X_valid, y_valid),\n",
    "        verbose=1,\n",
    "        callbacks=callbacks,\n",
    "        shuffle=False)\n",
    "    model.save(model_save_fname)\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "# endregion"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "id": "CKmceaTnb8ID",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# region Test model\n",
    "def test_model(model, test_data, window_size, prediction_size, input_col, output_col, time_col):\n",
    "    X, y, time = preprocessing_data(test_data, window_size, prediction_size, input_col, output_col, time_col)\n",
    "    \n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    y_pred = np.repeat(y_pred, input_dim, axis=1)\n",
    "    y_pred = scaler.inverse_transform(y_pred)[:, [0]]\n",
    "    y_pred = pd.Series(y_pred.flatten())\n",
    "\n",
    "    df_test_result = pd.DataFrame(time, columns=['Date'])\n",
    "    df_test_result['Prediction'] = y_pred\n",
    "    df_test_result.set_index('Date', inplace=True)\n",
    "\n",
    "    return df_test_result\n",
    "\n",
    "\n",
    "def plot_test_result(test_result, stock_name, year, window_size):\n",
    "    # Plotly\n",
    "    trace0 = go.Scatter(\n",
    "        x=test_result.index,\n",
    "        y=test_result['Close'],\n",
    "        name='Thực tế',\n",
    "        line=dict(\n",
    "            color=('#5042f4'),\n",
    "            width=2)\n",
    "    )\n",
    "\n",
    "    trace1 = go.Scatter(\n",
    "        x=test_result.index,\n",
    "        y=test_result['Prediction'],\n",
    "        name='Dự đoán',\n",
    "        line=dict(\n",
    "            color=('#005b4e'),\n",
    "            width=2,\n",
    "            dash='dot'\n",
    "        )  # dash options include 'dash', 'dot', and 'dashdot'\n",
    "    )\n",
    "\n",
    "    data = [trace0, trace1]\n",
    "\n",
    "    # Edit the layout\n",
    "    layout = dict(title='Biểu đồ dự đoán',\n",
    "                  xaxis=dict(title='Date'),\n",
    "                  yaxis=dict(title='Price'),\n",
    "                  paper_bgcolor='#FFF9F5',\n",
    "                  plot_bgcolor='#FFF9F5'\n",
    "                  )\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    if not IN_COLAB:\n",
    "        fig.write_html(os.path.join(plot_dir, '%s_%s_w%d.html' % (stock_name, year, window_size)), auto_open=False)\n",
    "    else:\n",
    "        fig.write_html(os.path.join(plot_dir, '%s_%s_w%d_%s.html' % (stock_name, year, window_size, datetime.now().strftime('%d%m%Y_%H%M%S'))), auto_open=False)\n",
    "        \n",
    "# endregion"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "id": "A4S45MJvb8II",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "250a10f2-8088-4ec0-8b2e-9e3eb6eaa97c"
   },
   "source": [
    "# region Bayers\n",
    "def objective(params, df):\n",
    "    # Keep track of evals\n",
    "    global ITERATION\n",
    "\n",
    "    ITERATION += 1\n",
    "\n",
    "    # Make sure windows_size is int\n",
    "    windows_size = int(params['windows_size'])\n",
    "    print(f'Window size is {windows_size}')\n",
    "\n",
    "    model = get_model(input_dim, windows_size, output_dim)\n",
    "\n",
    "    start = timer()\n",
    "\n",
    "    # Handle data\n",
    "    df.describe()\n",
    "    # TODO: smoothing ddata\n",
    "    df[input_col] = smooting_data(df[input_col], windows_size)\n",
    "\n",
    "    X, y, time = preprocessing_data(df, windows_size, prediction_size, input_col, output_col, time_col)\n",
    "\n",
    "    # Reshape data\n",
    "    y = y.reshape((y.shape[0], y.shape[1]))\n",
    "\n",
    "    X_train, y_train, X_valid, y_valid = split_train_test_data(X, y)\n",
    "\n",
    "    # Perform n_train\n",
    "    history = train_model(model, X_train, y_train, X_valid, y_valid, stock_name, year, windows_size)\n",
    "\n",
    "    run_time = timer() - start\n",
    "\n",
    "    # Test generated loss\n",
    "    test_result = test_model(model, df, windows_size, prediction_size, input_col, output_col, time_col)\n",
    "    test_result = test_result.join(df_org.set_index('Date'))\n",
    "    plot_test_result(test_result, stock_name, year, windows_size)\n",
    "\n",
    "    score = model.evaluate(X, y, 10000, 1)\n",
    "    print(f'Window size {windows_size} score = {score}')\n",
    "    #mae = mean_absolute_error(test_result['Close'], test_result['Prediction'])\n",
    "    #mse = mean_squared_error(test_result['Close'], test_result['Prediction'])\n",
    "    #mape = mean_absolute_percentage_error(test_result['Close'], test_result['Prediction'])\n",
    "    #rrmse = relative_root_mean_square_error(test_result['Close'], test_result['Prediction'])\n",
    "\n",
    "    #print(f'{stock_name} prediction for {prediction_size} day ahead')\n",
    "    #print(f'MAE = {mae}')\n",
    "    #print(f'MSE = {mse}')\n",
    "    #print(f'MAPE = {mape}')\n",
    "    #print(f'RRMSE = {rrmse}')\n",
    "    #loss = mape\n",
    "    loss = score\n",
    "    # write row\n",
    "    of_connection = open(result_save_fname, 'a')\n",
    "    writer = csv.writer(of_connection)\n",
    "    writer.writerow([stock_name, year, loss, params, ITERATION, windows_size, run_time])\n",
    "    of_connection.close()\n",
    "\n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': loss, 'params': params, 'iteration': ITERATION, 'test_result': test_result,\n",
    "            'train_time': run_time, 'status': STATUS_OK}\n",
    "\n",
    "start_year = df_org['Date'].values[:1][0]\n",
    "start_year = pd.to_datetime(start_year).year\n",
    "\n",
    "end_year = df_org['Date'].values[-1:][0]\n",
    "end_year = pd.to_datetime(end_year).year\n",
    "\n",
    "windows_size_best = []\n",
    "# Global variable\n",
    "global ITERATION\n",
    "\n",
    "for year in range(start_year, end_year + 1):\n",
    "    df = df_org[df_org['Date'].dt.year == year]\n",
    "\n",
    "    # Data too small, skip\n",
    "    if df.shape[0] < 10:\n",
    "        continue\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 2))\n",
    "    scaled_cols = scaler.fit_transform(df[input_col])\n",
    "    df[input_col] = scaled_cols\n",
    "\n",
    "    # Hyperparameter grid\n",
    "    param_grid = {\n",
    "        'windows_size': hp.choice('windows_size', np.arange(1, 8, dtype=int))\n",
    "    }\n",
    "\n",
    "    bayes_trials = Trials()\n",
    "\n",
    "    # Create the algorithm\n",
    "    bayes_algo = tpe.suggest\n",
    "\n",
    "    ITERATION = 0\n",
    "\n",
    "    fmin_objective = partial(objective, df=df)\n",
    "    bayes_best = fmin(fn=fmin_objective, space=param_grid,\n",
    "                      algo=bayes_algo, trials=bayes_trials,\n",
    "                      max_evals=bayer_max_evals)\n",
    "\n",
    "    of_connection = open(bayer_save_fname, 'a')\n",
    "    writer = csv.writer(of_connection)\n",
    "    writer.writerow([stock_name, year, bayes_best, best_model_fname])\n",
    "    of_connection.close()\n",
    "\n",
    "    windows_size_best.append([year, bayes_best])\n",
    "# endregion\n"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Window size is 7\n",
      "  0%|          | 0/100 [00:00<?, ?it/s, best loss: ?]WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 36 samples, validate on 9 samples\n",
      "Epoch 1/1000\n",
      "  0%|          | 0/100 [00:11<?, ?it/s, best loss: ?]WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "36/36 [==============================]\n",
      " - 8s 228ms/step - loss: 0.2805 - val_loss: 0.8803\n",
      "\n",
      "Epoch 2/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.2727 - val_loss: 0.9343\n",
      "\n",
      "Epoch 3/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.2575 - val_loss: 1.0437\n",
      "\n",
      "Epoch 4/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.2343 - val_loss: 1.2447\n",
      "\n",
      "Epoch 5/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.2112 - val_loss: 1.2957\n",
      "\n",
      "Epoch 6/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.2407 - val_loss: 1.1468\n",
      "\n",
      "Epoch 7/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1970 - val_loss: 1.0348\n",
      "\n",
      "Epoch 8/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1949 - val_loss: 0.9656\n",
      "\n",
      "Epoch 9/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.2007 - val_loss: 0.9175\n",
      "\n",
      "Epoch 10/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.2074 - val_loss: 0.8794\n",
      "\n",
      "Epoch 11/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.2030 - val_loss: 0.8447\n",
      "\n",
      "Epoch 12/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.2006 - val_loss: 0.8080\n",
      "\n",
      "Epoch 13/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1933 - val_loss: 0.7650\n",
      "\n",
      "Epoch 14/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1822 - val_loss: 0.7119\n",
      "\n",
      "Epoch 15/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1727 - val_loss: 0.6453\n",
      "\n",
      "Epoch 16/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1574 - val_loss: 0.5633\n",
      "\n",
      "Epoch 17/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1528 - val_loss: 0.4687\n",
      "\n",
      "Epoch 18/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1373 - val_loss: 0.3910\n",
      "\n",
      "Epoch 19/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1281 - val_loss: 0.3438\n",
      "\n",
      "Epoch 20/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1237 - val_loss: 0.3418\n",
      "\n",
      "Epoch 21/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1267 - val_loss: 0.3418\n",
      "\n",
      "Epoch 22/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1319 - val_loss: 0.3418\n",
      "\n",
      "Epoch 23/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1341 - val_loss: 0.3418\n",
      "\n",
      "Epoch 24/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1325 - val_loss: 0.3418\n",
      "\n",
      "Epoch 25/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1485 - val_loss: 0.3418\n",
      "\n",
      "Epoch 26/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1533 - val_loss: 0.3418\n",
      "\n",
      "Epoch 27/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1422 - val_loss: 0.3418\n",
      "\n",
      "Epoch 28/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1444 - val_loss: 0.3418\n",
      "\n",
      "Epoch 29/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1489 - val_loss: 0.3418\n",
      "\n",
      "Epoch 30/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1510 - val_loss: 0.3418\n",
      "\n",
      "Epoch 31/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1536 - val_loss: 0.3418\n",
      "\n",
      "Epoch 32/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1525 - val_loss: 0.3418\n",
      "\n",
      "Epoch 33/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1466 - val_loss: 0.3418\n",
      "\n",
      "Epoch 34/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1416 - val_loss: 0.3418\n",
      "\n",
      "Epoch 35/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1426 - val_loss: 0.3418\n",
      "\n",
      "Epoch 36/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1357 - val_loss: 0.3418\n",
      "\n",
      "Epoch 37/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1503 - val_loss: 0.3418\n",
      "\n",
      "Epoch 38/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1472 - val_loss: 0.3418\n",
      "\n",
      "Epoch 39/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1348 - val_loss: 0.3418\n",
      "\n",
      "Epoch 40/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1374 - val_loss: 0.3418\n",
      "\n",
      "Epoch 41/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1344 - val_loss: 0.3418\n",
      "\n",
      "Epoch 42/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1344 - val_loss: 0.3418\n",
      "\n",
      "Epoch 43/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1268 - val_loss: 0.3418\n",
      "\n",
      "Epoch 44/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1337 - val_loss: 0.3418\n",
      "\n",
      "Epoch 45/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1317 - val_loss: 0.3418\n",
      "\n",
      "Epoch 46/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1319 - val_loss: 0.3418\n",
      "\n",
      "Epoch 47/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1373 - val_loss: 0.3418\n",
      "\n",
      "Epoch 48/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1360 - val_loss: 0.3418\n",
      "\n",
      "Epoch 49/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1245 - val_loss: 0.3418\n",
      "\n",
      "Epoch 50/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1230 - val_loss: 0.3418\n",
      "\n",
      "Epoch 51/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1263 - val_loss: 0.3418\n",
      "\n",
      "Epoch 52/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1261 - val_loss: 0.3418\n",
      "\n",
      "Epoch 53/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1281 - val_loss: 0.3418\n",
      "\n",
      "Epoch 54/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1185 - val_loss: 0.3418\n",
      "\n",
      "Epoch 55/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1133 - val_loss: 0.3418\n",
      "\n",
      "Epoch 56/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1173 - val_loss: 0.3418\n",
      "\n",
      "Epoch 57/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1140 - val_loss: 0.3418\n",
      "\n",
      "Epoch 58/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1116 - val_loss: 0.3428\n",
      "\n",
      "Epoch 59/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1199 - val_loss: 0.3488\n",
      "\n",
      "Epoch 60/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1227 - val_loss: 0.3572\n",
      "\n",
      "Epoch 61/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1239 - val_loss: 0.3652\n",
      "\n",
      "Epoch 62/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1266 - val_loss: 0.3724\n",
      "\n",
      "Epoch 63/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1151 - val_loss: 0.3778\n",
      "\n",
      "Epoch 64/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1288 - val_loss: 0.3818\n",
      "\n",
      "Epoch 65/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1261 - val_loss: 0.3845\n",
      "\n",
      "Epoch 66/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1197 - val_loss: 0.3855\n",
      "\n",
      "Epoch 67/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1266 - val_loss: 0.3849\n",
      "\n",
      "Epoch 68/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1313 - val_loss: 0.3830\n",
      "\n",
      "Epoch 69/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1240 - val_loss: 0.3800\n",
      "\n",
      "Epoch 70/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1277 - val_loss: 0.3765\n",
      "\n",
      "Epoch 71/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1226 - val_loss: 0.3722\n",
      "\n",
      "Epoch 72/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1199 - val_loss: 0.3670\n",
      "\n",
      "Epoch 73/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1199 - val_loss: 0.3612\n",
      "\n",
      "Epoch 74/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1249 - val_loss: 0.3562\n",
      "\n",
      "Epoch 75/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1251 - val_loss: 0.3506\n",
      "\n",
      "Epoch 76/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1178 - val_loss: 0.3465\n",
      "\n",
      "Epoch 77/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1130 - val_loss: 0.3430\n",
      "\n",
      "Epoch 78/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1150 - val_loss: 0.3410\n",
      "\n",
      "Epoch 79/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1152 - val_loss: 0.3418\n",
      "\n",
      "Epoch 80/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1154 - val_loss: 0.3418\n",
      "\n",
      "Epoch 81/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1137 - val_loss: 0.3418\n",
      "\n",
      "Epoch 82/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1127 - val_loss: 0.3418\n",
      "\n",
      "Epoch 83/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1155 - val_loss: 0.3418\n",
      "\n",
      "Epoch 84/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1165 - val_loss: 0.3418\n",
      "\n",
      "Epoch 85/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1162 - val_loss: 0.3418\n",
      "\n",
      "Epoch 86/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1151 - val_loss: 0.3418\n",
      "\n",
      "Epoch 87/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1234 - val_loss: 0.3418\n",
      "\n",
      "Epoch 88/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1201 - val_loss: 0.3418\n",
      "\n",
      "Epoch 89/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1167 - val_loss: 0.3418\n",
      "\n",
      "Epoch 90/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1224 - val_loss: 0.3418\n",
      "\n",
      "Epoch 91/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1206 - val_loss: 0.3418\n",
      "\n",
      "Epoch 92/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1196 - val_loss: 0.3418\n",
      "\n",
      "Epoch 93/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1209 - val_loss: 0.3418\n",
      "\n",
      "Epoch 94/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1168 - val_loss: 0.3418\n",
      "\n",
      "Epoch 95/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1237 - val_loss: 0.3418\n",
      "\n",
      "Epoch 96/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1204 - val_loss: 0.3418\n",
      "\n",
      "Epoch 97/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1171 - val_loss: 0.3418\n",
      "\n",
      "Epoch 98/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1181 - val_loss: 0.3418\n",
      "\n",
      "Epoch 99/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1211 - val_loss: 0.3418\n",
      "\n",
      "Epoch 100/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1190 - val_loss: 0.3418\n",
      "\n",
      "Epoch 101/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1119 - val_loss: 0.3418\n",
      "\n",
      "Epoch 102/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1196 - val_loss: 0.3418\n",
      "\n",
      "Epoch 103/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1181 - val_loss: 0.3418\n",
      "\n",
      "Epoch 104/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1201 - val_loss: 0.3418\n",
      "\n",
      "Epoch 105/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1165 - val_loss: 0.3418\n",
      "\n",
      "Epoch 106/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1171 - val_loss: 0.3418\n",
      "\n",
      "Epoch 107/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1165 - val_loss: 0.3418\n",
      "\n",
      "Epoch 108/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1169 - val_loss: 0.3418\n",
      "\n",
      "Epoch 109/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1134 - val_loss: 0.3418\n",
      "\n",
      "Epoch 110/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1165 - val_loss: 0.3418\n",
      "\n",
      "Epoch 111/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1106 - val_loss: 0.3418\n",
      "\n",
      "Epoch 112/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1077 - val_loss: 0.3418\n",
      "\n",
      "Epoch 113/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1098 - val_loss: 0.3418\n",
      "\n",
      "Epoch 114/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1147 - val_loss: 0.3418\n",
      "\n",
      "Epoch 115/1000\n",
      "36/36 [==============================]\n",
      " - 0s 5ms/step - loss: 0.1128 - val_loss: 0.3418\n",
      "\n",
      "Epoch 116/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1072 - val_loss: 0.3418\n",
      "\n",
      "Epoch 117/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1150 - val_loss: 0.3418\n",
      "\n",
      "Epoch 118/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1129 - val_loss: 0.3418\n",
      "\n",
      "Epoch 119/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1035 - val_loss: 0.3418\n",
      "\n",
      "Epoch 120/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1139 - val_loss: 0.3418\n",
      "\n",
      "Epoch 121/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1092 - val_loss: 0.3418\n",
      "\n",
      "Epoch 122/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1139 - val_loss: 0.3418\n",
      "\n",
      "Epoch 123/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1121 - val_loss: 0.3418\n",
      "\n",
      "Epoch 124/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1141 - val_loss: 0.3418\n",
      "\n",
      "Epoch 125/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1100 - val_loss: 0.3418\n",
      "\n",
      "Epoch 126/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1029 - val_loss: 0.3418\n",
      "\n",
      "Epoch 127/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1114 - val_loss: 0.3418\n",
      "\n",
      "Epoch 128/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1066 - val_loss: 0.3418\n",
      "\n",
      "Epoch 129/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1024 - val_loss: 0.3418\n",
      "\n",
      "Epoch 130/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1092 - val_loss: 0.3418\n",
      "\n",
      "Epoch 131/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1092 - val_loss: 0.3418\n",
      "\n",
      "Epoch 132/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1107 - val_loss: 0.3418\n",
      "\n",
      "Epoch 133/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1118 - val_loss: 0.3418\n",
      "\n",
      "Epoch 134/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1130 - val_loss: 0.3418\n",
      "\n",
      "Epoch 135/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1128 - val_loss: 0.3418\n",
      "\n",
      "Epoch 136/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1135 - val_loss: 0.3418\n",
      "\n",
      "Epoch 137/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1155 - val_loss: 0.3418\n",
      "\n",
      "Epoch 138/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1174 - val_loss: 0.3418\n",
      "\n",
      "Epoch 139/1000\n",
      "36/36 [==============================]\n",
      " - 0s 5ms/step - loss: 0.1146 - val_loss: 0.3418\n",
      "\n",
      "Epoch 140/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1086 - val_loss: 0.3418\n",
      "\n",
      "Epoch 141/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1102 - val_loss: 0.3418\n",
      "\n",
      "Epoch 142/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1115 - val_loss: 0.3418\n",
      "\n",
      "Epoch 143/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1096 - val_loss: 0.3418\n",
      "\n",
      "Epoch 144/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1097 - val_loss: 0.3418\n",
      "\n",
      "Epoch 145/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1108 - val_loss: 0.3418\n",
      "\n",
      "Epoch 146/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1113 - val_loss: 0.3418\n",
      "\n",
      "Epoch 147/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1120 - val_loss: 0.3418\n",
      "\n",
      "Epoch 148/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1109 - val_loss: 0.3418\n",
      "\n",
      "Epoch 149/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1055 - val_loss: 0.3418\n",
      "\n",
      "Epoch 150/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1068 - val_loss: 0.3418\n",
      "\n",
      "Epoch 151/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1073 - val_loss: 0.3418\n",
      "\n",
      "Epoch 152/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1077 - val_loss: 0.3418\n",
      "\n",
      "Epoch 153/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1047 - val_loss: 0.3418\n",
      "\n",
      "Epoch 154/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1148 - val_loss: 0.3418\n",
      "\n",
      "Epoch 155/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1077 - val_loss: 0.3418\n",
      "\n",
      "Epoch 156/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1129 - val_loss: 0.3418\n",
      "\n",
      "Epoch 157/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1088 - val_loss: 0.3418\n",
      "\n",
      "Epoch 158/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1088 - val_loss: 0.3418\n",
      "\n",
      "Epoch 159/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1015 - val_loss: 0.3418\n",
      "\n",
      "Epoch 160/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1064 - val_loss: 0.3418\n",
      "\n",
      "Epoch 161/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1074 - val_loss: 0.3418\n",
      "\n",
      "Epoch 162/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1076 - val_loss: 0.3418\n",
      "\n",
      "Epoch 163/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1054 - val_loss: 0.3418\n",
      "\n",
      "Epoch 164/1000\n",
      "36/36 [==============================]\n",
      " - 0s 5ms/step - loss: 0.1104 - val_loss: 0.3418\n",
      "\n",
      "Epoch 165/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1047 - val_loss: 0.3418\n",
      "\n",
      "Epoch 166/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1007 - val_loss: 0.3418\n",
      "\n",
      "Epoch 167/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1047 - val_loss: 0.3418\n",
      "\n",
      "Epoch 168/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0993 - val_loss: 0.3418\n",
      "\n",
      "Epoch 169/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1047 - val_loss: 0.3418\n",
      "\n",
      "Epoch 170/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1039 - val_loss: 0.3418\n",
      "\n",
      "Epoch 171/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1039 - val_loss: 0.3418\n",
      "\n",
      "Epoch 172/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1087 - val_loss: 0.3418\n",
      "\n",
      "Epoch 173/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1137 - val_loss: 0.3418\n",
      "\n",
      "Epoch 174/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1022 - val_loss: 0.3418\n",
      "\n",
      "Epoch 175/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1052 - val_loss: 0.3418\n",
      "\n",
      "Epoch 176/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1056 - val_loss: 0.3418\n",
      "\n",
      "Epoch 177/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1132 - val_loss: 0.3418\n",
      "\n",
      "Epoch 178/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1067 - val_loss: 0.3418\n",
      "\n",
      "45/45 [==============================]\n",
      " - 0s 332us/step\n",
      "\n",
      "Window size 7 score = 0.15395906567573547\n",
      "Window size is 5\n",
      "Train on 37 samples, validate on 10 samples\n",
      "Epoch 1/1000\n",
      "37/37 [==============================]\n",
      " - 11s 290ms/step - loss: 0.2394 - val_loss: 0.7164\n",
      "\n",
      "Epoch 2/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.2300 - val_loss: 0.7644\n",
      "\n",
      "Epoch 3/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.2162 - val_loss: 0.8587\n",
      "\n",
      "Epoch 4/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1916 - val_loss: 1.0208\n",
      "\n",
      "Epoch 5/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1577 - val_loss: 1.1301\n",
      "\n",
      "Epoch 6/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1688 - val_loss: 1.0696\n",
      "\n",
      "Epoch 7/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1632 - val_loss: 0.9914\n",
      "\n",
      "Epoch 8/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1472 - val_loss: 0.9358\n",
      "\n",
      "Epoch 9/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1484 - val_loss: 0.9081\n",
      "\n",
      "Epoch 10/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1522 - val_loss: 0.8991\n",
      "\n",
      "Epoch 11/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1486 - val_loss: 0.9027\n",
      "\n",
      "Epoch 12/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1487 - val_loss: 0.9125\n",
      "\n",
      "Epoch 13/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1405 - val_loss: 0.9288\n",
      "\n",
      "Epoch 14/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1392 - val_loss: 0.9432\n",
      "\n",
      "Epoch 15/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1402 - val_loss: 0.9557\n",
      "\n",
      "Epoch 16/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1428 - val_loss: 0.9613\n",
      "\n",
      "Epoch 17/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1423 - val_loss: 0.9616\n",
      "\n",
      "Epoch 18/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1440 - val_loss: 0.9584\n",
      "\n",
      "Epoch 19/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1482 - val_loss: 0.9523\n",
      "\n",
      "Epoch 20/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1436 - val_loss: 0.9429\n",
      "\n",
      "Epoch 21/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1462 - val_loss: 0.9328\n",
      "\n",
      "Epoch 22/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1407 - val_loss: 0.9218\n",
      "\n",
      "Epoch 23/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1368 - val_loss: 0.9112\n",
      "\n",
      "Epoch 24/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1419 - val_loss: 0.9012\n",
      "\n",
      "Epoch 25/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1359 - val_loss: 0.8926\n",
      "\n",
      "Epoch 26/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1341 - val_loss: 0.8850\n",
      "\n",
      "Epoch 27/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1402 - val_loss: 0.8785\n",
      "\n",
      "Epoch 28/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1371 - val_loss: 0.8729\n",
      "\n",
      "Epoch 29/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1362 - val_loss: 0.8688\n",
      "\n",
      "Epoch 30/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1363 - val_loss: 0.8657\n",
      "\n",
      "Epoch 31/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1396 - val_loss: 0.8635\n",
      "\n",
      "Epoch 32/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1383 - val_loss: 0.8615\n",
      "\n",
      "Epoch 33/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1348 - val_loss: 0.8603\n",
      "\n",
      "Epoch 34/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1345 - val_loss: 0.8590\n",
      "\n",
      "Epoch 35/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1348 - val_loss: 0.8577\n",
      "\n",
      "Epoch 36/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1360 - val_loss: 0.8563\n",
      "\n",
      "Epoch 37/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1333 - val_loss: 0.8547\n",
      "\n",
      "Epoch 38/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1315 - val_loss: 0.8527\n",
      "\n",
      "Epoch 39/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1300 - val_loss: 0.8505\n",
      "\n",
      "Epoch 40/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1305 - val_loss: 0.8475\n",
      "\n",
      "Epoch 41/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1341 - val_loss: 0.8440\n",
      "\n",
      "Epoch 42/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1318 - val_loss: 0.8395\n",
      "\n",
      "Epoch 43/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1326 - val_loss: 0.8340\n",
      "\n",
      "Epoch 44/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1313 - val_loss: 0.8274\n",
      "\n",
      "Epoch 45/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1305 - val_loss: 0.8198\n",
      "\n",
      "Epoch 46/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1290 - val_loss: 0.8110\n",
      "\n",
      "Epoch 47/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1325 - val_loss: 0.8010\n",
      "\n",
      "Epoch 48/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1248 - val_loss: 0.7894\n",
      "\n",
      "Epoch 49/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1259 - val_loss: 0.7763\n",
      "\n",
      "Epoch 50/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1173 - val_loss: 0.7618\n",
      "\n",
      "Epoch 51/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1244 - val_loss: 0.7456\n",
      "\n",
      "Epoch 52/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1261 - val_loss: 0.7276\n",
      "\n",
      "Epoch 53/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1288 - val_loss: 0.7076\n",
      "\n",
      "Epoch 54/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1153 - val_loss: 0.6860\n",
      "\n",
      "Epoch 55/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1202 - val_loss: 0.6623\n",
      "\n",
      "Epoch 56/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1182 - val_loss: 0.6366\n",
      "\n",
      "Epoch 57/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1176 - val_loss: 0.6095\n",
      "\n",
      "Epoch 58/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1159 - val_loss: 0.5812\n",
      "\n",
      "Epoch 59/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1134 - val_loss: 0.5510\n",
      "\n",
      "Epoch 60/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1137 - val_loss: 0.5193\n",
      "\n",
      "Epoch 61/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1098 - val_loss: 0.4868\n",
      "\n",
      "Epoch 62/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1051 - val_loss: 0.4524\n",
      "\n",
      "Epoch 63/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1044 - val_loss: 0.4165\n",
      "\n",
      "Epoch 64/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1012 - val_loss: 0.3795\n",
      "\n",
      "Epoch 65/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0977 - val_loss: 0.3413\n",
      "\n",
      "Epoch 66/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1005 - val_loss: 0.3062\n",
      "\n",
      "Epoch 67/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0943 - val_loss: 0.2743\n",
      "\n",
      "Epoch 68/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0930 - val_loss: 0.2455\n",
      "\n",
      "Epoch 69/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0868 - val_loss: 0.2216\n",
      "\n",
      "Epoch 70/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0891 - val_loss: 0.2005\n",
      "\n",
      "Epoch 71/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0867 - val_loss: 0.1914\n",
      "\n",
      "Epoch 72/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0814 - val_loss: 0.1983\n",
      "\n",
      "Epoch 73/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0812 - val_loss: 0.2082\n",
      "\n",
      "Epoch 74/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0860 - val_loss: 0.2138\n",
      "\n",
      "Epoch 75/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0787 - val_loss: 0.2164\n",
      "\n",
      "Epoch 76/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0816 - val_loss: 0.2178\n",
      "\n",
      "Epoch 77/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0790 - val_loss: 0.2189\n",
      "\n",
      "Epoch 78/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0768 - val_loss: 0.2197\n",
      "\n",
      "Epoch 79/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0823 - val_loss: 0.2203\n",
      "\n",
      "Epoch 80/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0832 - val_loss: 0.2203\n",
      "\n",
      "Epoch 81/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0847 - val_loss: 0.2203\n",
      "\n",
      "Epoch 82/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0886 - val_loss: 0.2203\n",
      "\n",
      "Epoch 83/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0949 - val_loss: 0.2203\n",
      "\n",
      "Epoch 84/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1026 - val_loss: 0.2203\n",
      "\n",
      "Epoch 85/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0920 - val_loss: 0.2203\n",
      "\n",
      "Epoch 86/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0935 - val_loss: 0.2203\n",
      "\n",
      "Epoch 87/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0903 - val_loss: 0.2203\n",
      "\n",
      "Epoch 88/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0937 - val_loss: 0.2203\n",
      "\n",
      "Epoch 89/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0997 - val_loss: 0.2203\n",
      "\n",
      "Epoch 90/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0804 - val_loss: 0.2203\n",
      "\n",
      "Epoch 91/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0877 - val_loss: 0.2203\n",
      "\n",
      "Epoch 92/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0961 - val_loss: 0.2203\n",
      "\n",
      "Epoch 93/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0943 - val_loss: 0.2203\n",
      "\n",
      "Epoch 94/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0935 - val_loss: 0.2203\n",
      "\n",
      "Epoch 95/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0849 - val_loss: 0.2203\n",
      "\n",
      "Epoch 96/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0935 - val_loss: 0.2203\n",
      "\n",
      "Epoch 97/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0963 - val_loss: 0.2203\n",
      "\n",
      "Epoch 98/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0946 - val_loss: 0.2203\n",
      "\n",
      "Epoch 99/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0869 - val_loss: 0.2203\n",
      "\n",
      "Epoch 100/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0897 - val_loss: 0.2203\n",
      "\n",
      "Epoch 101/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0938 - val_loss: 0.2203\n",
      "\n",
      "Epoch 102/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0948 - val_loss: 0.2203\n",
      "\n",
      "Epoch 103/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0830 - val_loss: 0.2203\n",
      "\n",
      "Epoch 104/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0884 - val_loss: 0.2203\n",
      "\n",
      "Epoch 105/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0805 - val_loss: 0.2203\n",
      "\n",
      "Epoch 106/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0798 - val_loss: 0.2203\n",
      "\n",
      "Epoch 107/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0820 - val_loss: 0.2185\n",
      "\n",
      "Epoch 108/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0781 - val_loss: 0.2167\n",
      "\n",
      "Epoch 109/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0846 - val_loss: 0.2147\n",
      "\n",
      "Epoch 110/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0874 - val_loss: 0.2110\n",
      "\n",
      "Epoch 111/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0804 - val_loss: 0.2072\n",
      "\n",
      "Epoch 112/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0879 - val_loss: 0.2023\n",
      "\n",
      "Epoch 113/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0906 - val_loss: 0.1974\n",
      "\n",
      "Epoch 114/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0776 - val_loss: 0.1929\n",
      "\n",
      "Epoch 115/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0806 - val_loss: 0.1902\n",
      "\n",
      "Epoch 116/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0840 - val_loss: 0.1903\n",
      "\n",
      "Epoch 117/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0871 - val_loss: 0.1904\n",
      "\n",
      "Epoch 118/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0836 - val_loss: 0.1918\n",
      "\n",
      "Epoch 119/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0795 - val_loss: 0.1945\n",
      "\n",
      "Epoch 120/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0852 - val_loss: 0.1971\n",
      "\n",
      "Epoch 121/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0766 - val_loss: 0.1989\n",
      "\n",
      "Epoch 122/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0834 - val_loss: 0.2004\n",
      "\n",
      "Epoch 123/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0805 - val_loss: 0.2012\n",
      "\n",
      "Epoch 124/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0851 - val_loss: 0.2014\n",
      "\n",
      "Epoch 125/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0841 - val_loss: 0.2012\n",
      "\n",
      "Epoch 126/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0795 - val_loss: 0.2005\n",
      "\n",
      "Epoch 127/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0839 - val_loss: 0.1995\n",
      "\n",
      "Epoch 128/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0793 - val_loss: 0.1982\n",
      "\n",
      "Epoch 129/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0782 - val_loss: 0.1966\n",
      "\n",
      "Epoch 130/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0789 - val_loss: 0.1954\n",
      "\n",
      "Epoch 131/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0762 - val_loss: 0.1943\n",
      "\n",
      "Epoch 132/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0867 - val_loss: 0.1931\n",
      "\n",
      "Epoch 133/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0763 - val_loss: 0.1924\n",
      "\n",
      "Epoch 134/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0796 - val_loss: 0.1922\n",
      "\n",
      "Epoch 135/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0823 - val_loss: 0.1923\n",
      "\n",
      "Epoch 136/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0826 - val_loss: 0.1923\n",
      "\n",
      "Epoch 137/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0801 - val_loss: 0.1923\n",
      "\n",
      "Epoch 138/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0870 - val_loss: 0.1923\n",
      "\n",
      "Epoch 139/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0798 - val_loss: 0.1925\n",
      "\n",
      "Epoch 140/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0815 - val_loss: 0.1933\n",
      "\n",
      "Epoch 141/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0814 - val_loss: 0.1939\n",
      "\n",
      "Epoch 142/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0883 - val_loss: 0.1947\n",
      "\n",
      "Epoch 143/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0831 - val_loss: 0.1953\n",
      "\n",
      "Epoch 144/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0856 - val_loss: 0.1960\n",
      "\n",
      "Epoch 145/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0884 - val_loss: 0.1969\n",
      "\n",
      "Epoch 146/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0872 - val_loss: 0.1976\n",
      "\n",
      "Epoch 147/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0851 - val_loss: 0.1982\n",
      "\n",
      "Epoch 148/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0821 - val_loss: 0.1986\n",
      "\n",
      "Epoch 149/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0872 - val_loss: 0.1990\n",
      "\n",
      "Epoch 150/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0876 - val_loss: 0.1994\n",
      "\n",
      "Epoch 151/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0904 - val_loss: 0.1997\n",
      "\n",
      "Epoch 152/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0830 - val_loss: 0.1999\n",
      "\n",
      "Epoch 153/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0897 - val_loss: 0.1999\n",
      "\n",
      "Epoch 154/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0822 - val_loss: 0.1998\n",
      "\n",
      "Epoch 155/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0807 - val_loss: 0.1996\n",
      "\n",
      "Epoch 156/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0847 - val_loss: 0.1992\n",
      "\n",
      "Epoch 157/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0889 - val_loss: 0.1985\n",
      "\n",
      "Epoch 158/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0801 - val_loss: 0.1978\n",
      "\n",
      "Epoch 159/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0808 - val_loss: 0.1972\n",
      "\n",
      "Epoch 160/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0815 - val_loss: 0.1965\n",
      "\n",
      "Epoch 161/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0802 - val_loss: 0.1957\n",
      "\n",
      "Epoch 162/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0860 - val_loss: 0.1950\n",
      "\n",
      "Epoch 163/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0779 - val_loss: 0.1941\n",
      "\n",
      "Epoch 164/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0811 - val_loss: 0.1936\n",
      "\n",
      "Epoch 165/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0777 - val_loss: 0.1931\n",
      "\n",
      "Epoch 166/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0813 - val_loss: 0.1926\n",
      "\n",
      "Epoch 167/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0804 - val_loss: 0.1921\n",
      "\n",
      "Epoch 168/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0824 - val_loss: 0.1916\n",
      "\n",
      "Epoch 169/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0824 - val_loss: 0.1912\n",
      "\n",
      "Epoch 170/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0784 - val_loss: 0.1908\n",
      "\n",
      "Epoch 171/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0757 - val_loss: 0.1904\n",
      "\n",
      "Epoch 172/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0714 - val_loss: 0.1901\n",
      "\n",
      "Epoch 173/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0733 - val_loss: 0.1898\n",
      "\n",
      "Epoch 174/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0744 - val_loss: 0.1896\n",
      "\n",
      "Epoch 175/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0753 - val_loss: 0.1895\n",
      "\n",
      "Epoch 176/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0756 - val_loss: 0.1894\n",
      "\n",
      "Epoch 177/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0759 - val_loss: 0.1893\n",
      "\n",
      "Epoch 178/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0759 - val_loss: 0.1891\n",
      "\n",
      "Epoch 179/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0769 - val_loss: 0.1890\n",
      "\n",
      "Epoch 180/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0724 - val_loss: 0.1888\n",
      "\n",
      "Epoch 181/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0753 - val_loss: 0.1887\n",
      "\n",
      "Epoch 182/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0728 - val_loss: 0.1888\n",
      "\n",
      "Epoch 183/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0793 - val_loss: 0.1890\n",
      "\n",
      "Epoch 184/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0774 - val_loss: 0.1894\n",
      "\n",
      "Epoch 185/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0706 - val_loss: 0.1898\n",
      "\n",
      "Epoch 186/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0821 - val_loss: 0.1905\n",
      "\n",
      "Epoch 187/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0855 - val_loss: 0.1915\n",
      "\n",
      "Epoch 188/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0738 - val_loss: 0.1927\n",
      "\n",
      "Epoch 189/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0706 - val_loss: 0.1940\n",
      "\n",
      "Epoch 190/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0782 - val_loss: 0.1954\n",
      "\n",
      "Epoch 191/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0731 - val_loss: 0.1970\n",
      "\n",
      "Epoch 192/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0764 - val_loss: 0.1986\n",
      "\n",
      "Epoch 193/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0729 - val_loss: 0.2004\n",
      "\n",
      "Epoch 194/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0740 - val_loss: 0.2023\n",
      "\n",
      "Epoch 195/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0777 - val_loss: 0.2042\n",
      "\n",
      "Epoch 196/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0778 - val_loss: 0.2056\n",
      "\n",
      "Epoch 197/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0742 - val_loss: 0.2069\n",
      "\n",
      "Epoch 198/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0776 - val_loss: 0.2081\n",
      "\n",
      "Epoch 199/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0728 - val_loss: 0.2093\n",
      "\n",
      "Epoch 200/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0752 - val_loss: 0.2105\n",
      "\n",
      "Epoch 201/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0809 - val_loss: 0.2117\n",
      "\n",
      "Epoch 202/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0756 - val_loss: 0.2130\n",
      "\n",
      "Epoch 203/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0778 - val_loss: 0.2142\n",
      "\n",
      "Epoch 204/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0774 - val_loss: 0.2149\n",
      "\n",
      "Epoch 205/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0755 - val_loss: 0.2155\n",
      "\n",
      "Epoch 206/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0750 - val_loss: 0.2161\n",
      "\n",
      "Epoch 207/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0775 - val_loss: 0.2168\n",
      "\n",
      "Epoch 208/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0758 - val_loss: 0.2174\n",
      "\n",
      "Epoch 209/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0791 - val_loss: 0.2180\n",
      "\n",
      "Epoch 210/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0732 - val_loss: 0.2185\n",
      "\n",
      "Epoch 211/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0767 - val_loss: 0.2190\n",
      "\n",
      "Epoch 212/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0804 - val_loss: 0.2195\n",
      "\n",
      "Epoch 213/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0800 - val_loss: 0.2200\n",
      "\n",
      "Epoch 214/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0885 - val_loss: 0.2203\n",
      "\n",
      "Epoch 215/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0780 - val_loss: 0.2203\n",
      "\n",
      "Epoch 216/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0820 - val_loss: 0.2203\n",
      "\n",
      "Epoch 217/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0757 - val_loss: 0.2203\n",
      "\n",
      "Epoch 218/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0709 - val_loss: 0.2203\n",
      "\n",
      "Epoch 219/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0701 - val_loss: 0.2203\n",
      "\n",
      "Epoch 220/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0745 - val_loss: 0.2203\n",
      "\n",
      "Epoch 221/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0719 - val_loss: 0.2203\n",
      "\n",
      "Epoch 222/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0896 - val_loss: 0.2203\n",
      "\n",
      "Epoch 223/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0736 - val_loss: 0.2203\n",
      "\n",
      "Epoch 224/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0756 - val_loss: 0.2203\n",
      "\n",
      "Epoch 225/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0759 - val_loss: 0.2203\n",
      "\n",
      "Epoch 226/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0743 - val_loss: 0.2203\n",
      "\n",
      "Epoch 227/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0793 - val_loss: 0.2203\n",
      "\n",
      "Epoch 228/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0765 - val_loss: 0.2203\n",
      "\n",
      "Epoch 229/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0768 - val_loss: 0.2203\n",
      "\n",
      "Epoch 230/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0776 - val_loss: 0.2203\n",
      "\n",
      "Epoch 231/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0749 - val_loss: 0.2203\n",
      "\n",
      "Epoch 232/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0699 - val_loss: 0.2203\n",
      "\n",
      "Epoch 233/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0770 - val_loss: 0.2203\n",
      "\n",
      "Epoch 234/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0767 - val_loss: 0.2203\n",
      "\n",
      "Epoch 235/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0717 - val_loss: 0.2203\n",
      "\n",
      "Epoch 236/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0802 - val_loss: 0.2203\n",
      "\n",
      "Epoch 237/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0752 - val_loss: 0.2203\n",
      "\n",
      "Epoch 238/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0801 - val_loss: 0.2203\n",
      "\n",
      "Epoch 239/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0746 - val_loss: 0.2203\n",
      "\n",
      "Epoch 240/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0754 - val_loss: 0.2200\n",
      "\n",
      "Epoch 241/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0742 - val_loss: 0.2197\n",
      "\n",
      "Epoch 242/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0780 - val_loss: 0.2194\n",
      "\n",
      "Epoch 243/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0766 - val_loss: 0.2191\n",
      "\n",
      "Epoch 244/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0747 - val_loss: 0.2188\n",
      "\n",
      "Epoch 245/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0746 - val_loss: 0.2184\n",
      "\n",
      "Epoch 246/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0710 - val_loss: 0.2181\n",
      "\n",
      "Epoch 247/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0780 - val_loss: 0.2177\n",
      "\n",
      "Epoch 248/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0847 - val_loss: 0.2173\n",
      "\n",
      "Epoch 249/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0855 - val_loss: 0.2169\n",
      "\n",
      "Epoch 250/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0750 - val_loss: 0.2165\n",
      "\n",
      "Epoch 251/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0715 - val_loss: 0.2161\n",
      "\n",
      "Epoch 252/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0692 - val_loss: 0.2158\n",
      "\n",
      "Epoch 253/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0722 - val_loss: 0.2154\n",
      "\n",
      "Epoch 254/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0709 - val_loss: 0.2150\n",
      "\n",
      "Epoch 255/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0716 - val_loss: 0.2143\n",
      "\n",
      "Epoch 256/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0694 - val_loss: 0.2136\n",
      "\n",
      "Epoch 257/1000\n",
      "37/37 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0743 - val_loss: 0.2128\n",
      "\n",
      "Epoch 258/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0684 - val_loss: 0.2121\n",
      "\n",
      "Epoch 259/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0815 - val_loss: 0.2114\n",
      "\n",
      "Epoch 260/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0742 - val_loss: 0.2107\n",
      "\n",
      "Epoch 261/1000\n",
      "37/37 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0696 - val_loss: 0.2100\n",
      "\n",
      "Epoch 262/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0752 - val_loss: 0.2094\n",
      "\n",
      "Epoch 263/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0683 - val_loss: 0.2088\n",
      "\n",
      "Epoch 264/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0719 - val_loss: 0.2083\n",
      "\n",
      "Epoch 265/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0739 - val_loss: 0.2077\n",
      "\n",
      "Epoch 266/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0743 - val_loss: 0.2072\n",
      "\n",
      "Epoch 267/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0724 - val_loss: 0.2067\n",
      "\n",
      "Epoch 268/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0709 - val_loss: 0.2059\n",
      "\n",
      "Epoch 269/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0715 - val_loss: 0.2052\n",
      "\n",
      "Epoch 270/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0752 - val_loss: 0.2045\n",
      "\n",
      "Epoch 271/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0747 - val_loss: 0.2038\n",
      "\n",
      "Epoch 272/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0718 - val_loss: 0.2031\n",
      "\n",
      "Epoch 273/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0741 - val_loss: 0.2023\n",
      "\n",
      "Epoch 274/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0708 - val_loss: 0.2016\n",
      "\n",
      "Epoch 275/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0740 - val_loss: 0.2008\n",
      "\n",
      "Epoch 276/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0754 - val_loss: 0.2001\n",
      "\n",
      "Epoch 277/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0733 - val_loss: 0.1993\n",
      "\n",
      "Epoch 278/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0723 - val_loss: 0.1986\n",
      "\n",
      "Epoch 279/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0772 - val_loss: 0.1978\n",
      "\n",
      "Epoch 280/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0739 - val_loss: 0.1971\n",
      "\n",
      "Epoch 281/1000\n",
      "37/37 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0684 - val_loss: 0.1965\n",
      "\n",
      "47/47 [==============================]\n",
      " - 0s 272us/step\n",
      "\n",
      "Window size 5 score = 0.0965782105922699\n",
      "Window size is 6\n",
      "Train on 36 samples, validate on 10 samples\n",
      "Epoch 1/1000\n",
      "36/36 [==============================]\n",
      " - 11s 318ms/step - loss: 0.2646 - val_loss: 0.5073\n",
      "\n",
      "Epoch 2/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.2504 - val_loss: 0.5715\n",
      "\n",
      "Epoch 3/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.2231 - val_loss: 0.7072\n",
      "\n",
      "Epoch 4/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1746 - val_loss: 0.9570\n",
      "\n",
      "Epoch 5/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1332 - val_loss: 0.9768\n",
      "\n",
      "Epoch 6/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1453 - val_loss: 0.9074\n",
      "\n",
      "Epoch 7/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1218 - val_loss: 0.8093\n",
      "\n",
      "Epoch 8/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1162 - val_loss: 0.7705\n",
      "\n",
      "Epoch 9/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1265 - val_loss: 0.7650\n",
      "\n",
      "Epoch 10/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1285 - val_loss: 0.7781\n",
      "\n",
      "Epoch 11/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1152 - val_loss: 0.7989\n",
      "\n",
      "Epoch 12/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1168 - val_loss: 0.8203\n",
      "\n",
      "Epoch 13/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1107 - val_loss: 0.8428\n",
      "\n",
      "Epoch 14/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1136 - val_loss: 0.8543\n",
      "\n",
      "Epoch 15/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1181 - val_loss: 0.8564\n",
      "\n",
      "Epoch 16/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1221 - val_loss: 0.8495\n",
      "\n",
      "Epoch 17/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1177 - val_loss: 0.8366\n",
      "\n",
      "Epoch 18/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1107 - val_loss: 0.8191\n",
      "\n",
      "Epoch 19/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1174 - val_loss: 0.7999\n",
      "\n",
      "Epoch 20/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1133 - val_loss: 0.7809\n",
      "\n",
      "Epoch 21/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1067 - val_loss: 0.7648\n",
      "\n",
      "Epoch 22/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1086 - val_loss: 0.7523\n",
      "\n",
      "Epoch 23/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1092 - val_loss: 0.7427\n",
      "\n",
      "Epoch 24/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1105 - val_loss: 0.7348\n",
      "\n",
      "Epoch 25/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1115 - val_loss: 0.7295\n",
      "\n",
      "Epoch 26/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1151 - val_loss: 0.7268\n",
      "\n",
      "Epoch 27/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1131 - val_loss: 0.7261\n",
      "\n",
      "Epoch 28/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1120 - val_loss: 0.7275\n",
      "\n",
      "Epoch 29/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1140 - val_loss: 0.7304\n",
      "\n",
      "Epoch 30/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1111 - val_loss: 0.7346\n",
      "\n",
      "Epoch 31/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1074 - val_loss: 0.7406\n",
      "\n",
      "Epoch 32/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1075 - val_loss: 0.7463\n",
      "\n",
      "Epoch 33/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1133 - val_loss: 0.7524\n",
      "\n",
      "Epoch 34/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1060 - val_loss: 0.7585\n",
      "\n",
      "Epoch 35/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1034 - val_loss: 0.7644\n",
      "\n",
      "Epoch 36/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1040 - val_loss: 0.7703\n",
      "\n",
      "Epoch 37/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1099 - val_loss: 0.7757\n",
      "\n",
      "Epoch 38/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1049 - val_loss: 0.7804\n",
      "\n",
      "Epoch 39/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1088 - val_loss: 0.7842\n",
      "\n",
      "Epoch 40/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1066 - val_loss: 0.7868\n",
      "\n",
      "Epoch 41/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1080 - val_loss: 0.7879\n",
      "\n",
      "Epoch 42/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1121 - val_loss: 0.7882\n",
      "\n",
      "Epoch 43/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1126 - val_loss: 0.7874\n",
      "\n",
      "Epoch 44/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1098 - val_loss: 0.7859\n",
      "\n",
      "Epoch 45/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1084 - val_loss: 0.7835\n",
      "\n",
      "Epoch 46/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1118 - val_loss: 0.7804\n",
      "\n",
      "Epoch 47/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1087 - val_loss: 0.7769\n",
      "\n",
      "Epoch 48/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1086 - val_loss: 0.7732\n",
      "\n",
      "Epoch 49/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1095 - val_loss: 0.7694\n",
      "\n",
      "Epoch 50/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1030 - val_loss: 0.7654\n",
      "\n",
      "Epoch 51/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1071 - val_loss: 0.7613\n",
      "\n",
      "Epoch 52/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1040 - val_loss: 0.7573\n",
      "\n",
      "Epoch 53/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1068 - val_loss: 0.7533\n",
      "\n",
      "Epoch 54/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1025 - val_loss: 0.7494\n",
      "\n",
      "Epoch 55/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1083 - val_loss: 0.7460\n",
      "\n",
      "Epoch 56/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1076 - val_loss: 0.7425\n",
      "\n",
      "Epoch 57/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1062 - val_loss: 0.7393\n",
      "\n",
      "Epoch 58/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1049 - val_loss: 0.7364\n",
      "\n",
      "Epoch 59/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1113 - val_loss: 0.7338\n",
      "\n",
      "Epoch 60/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1066 - val_loss: 0.7314\n",
      "\n",
      "Epoch 61/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1054 - val_loss: 0.7294\n",
      "\n",
      "Epoch 62/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1080 - val_loss: 0.7275\n",
      "\n",
      "Epoch 63/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1099 - val_loss: 0.7258\n",
      "\n",
      "Epoch 64/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1133 - val_loss: 0.7244\n",
      "\n",
      "Epoch 65/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1089 - val_loss: 0.7235\n",
      "\n",
      "Epoch 66/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1124 - val_loss: 0.7230\n",
      "\n",
      "Epoch 67/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1065 - val_loss: 0.7228\n",
      "\n",
      "Epoch 68/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1060 - val_loss: 0.7226\n",
      "\n",
      "Epoch 69/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1071 - val_loss: 0.7228\n",
      "\n",
      "Epoch 70/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1097 - val_loss: 0.7231\n",
      "\n",
      "Epoch 71/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1036 - val_loss: 0.7236\n",
      "\n",
      "Epoch 72/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1094 - val_loss: 0.7241\n",
      "\n",
      "Epoch 73/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1050 - val_loss: 0.7246\n",
      "\n",
      "Epoch 74/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1070 - val_loss: 0.7254\n",
      "\n",
      "Epoch 75/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1078 - val_loss: 0.7264\n",
      "\n",
      "Epoch 76/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1077 - val_loss: 0.7273\n",
      "\n",
      "Epoch 77/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1053 - val_loss: 0.7284\n",
      "\n",
      "Epoch 78/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1008 - val_loss: 0.7294\n",
      "\n",
      "Epoch 79/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1013 - val_loss: 0.7305\n",
      "\n",
      "Epoch 80/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1049 - val_loss: 0.7317\n",
      "\n",
      "Epoch 81/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1041 - val_loss: 0.7328\n",
      "\n",
      "Epoch 82/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1076 - val_loss: 0.7341\n",
      "\n",
      "Epoch 83/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1033 - val_loss: 0.7353\n",
      "\n",
      "Epoch 84/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1026 - val_loss: 0.7365\n",
      "\n",
      "Epoch 85/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1042 - val_loss: 0.7377\n",
      "\n",
      "Epoch 86/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1062 - val_loss: 0.7388\n",
      "\n",
      "Epoch 87/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1031 - val_loss: 0.7398\n",
      "\n",
      "Epoch 88/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1061 - val_loss: 0.7407\n",
      "\n",
      "Epoch 89/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1035 - val_loss: 0.7414\n",
      "\n",
      "Epoch 90/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1036 - val_loss: 0.7421\n",
      "\n",
      "Epoch 91/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1066 - val_loss: 0.7426\n",
      "\n",
      "Epoch 92/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1025 - val_loss: 0.7430\n",
      "\n",
      "Epoch 93/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1030 - val_loss: 0.7432\n",
      "\n",
      "Epoch 94/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1082 - val_loss: 0.7431\n",
      "\n",
      "Epoch 95/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1069 - val_loss: 0.7428\n",
      "\n",
      "Epoch 96/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1007 - val_loss: 0.7423\n",
      "\n",
      "Epoch 97/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1064 - val_loss: 0.7416\n",
      "\n",
      "Epoch 98/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1063 - val_loss: 0.7407\n",
      "\n",
      "Epoch 99/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1041 - val_loss: 0.7396\n",
      "\n",
      "Epoch 100/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1051 - val_loss: 0.7383\n",
      "\n",
      "Epoch 101/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1050 - val_loss: 0.7367\n",
      "\n",
      "46/46 [==============================]\n",
      " - 0s 387us/step\n",
      "\n",
      "Window size 6 score = 0.2415153682231903\n",
      "Window size is 2\n",
      "Train on 40 samples, validate on 10 samples\n",
      "Epoch 1/1000\n",
      "40/40 [==============================]\n",
      " - 14s 339ms/step - loss: 0.2165 - val_loss: 0.5129\n",
      "\n",
      "Epoch 2/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.2115 - val_loss: 0.5217\n",
      "\n",
      "Epoch 3/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.2057 - val_loss: 0.5333\n",
      "\n",
      "Epoch 4/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1990 - val_loss: 0.5490\n",
      "\n",
      "Epoch 5/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1902 - val_loss: 0.5696\n",
      "\n",
      "Epoch 6/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1795 - val_loss: 0.5966\n",
      "\n",
      "Epoch 7/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1686 - val_loss: 0.6314\n",
      "\n",
      "Epoch 8/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1554 - val_loss: 0.6753\n",
      "\n",
      "Epoch 9/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1361 - val_loss: 0.7300\n",
      "\n",
      "Epoch 10/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1181 - val_loss: 0.7958\n",
      "\n",
      "Epoch 11/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1020 - val_loss: 0.8631\n",
      "\n",
      "Epoch 12/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1128 - val_loss: 0.9059\n",
      "\n",
      "Epoch 13/1000\n",
      "40/40 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1216 - val_loss: 0.9172\n",
      "\n",
      "Epoch 14/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1290 - val_loss: 0.9116\n",
      "\n",
      "Epoch 15/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1235 - val_loss: 0.8978\n",
      "\n",
      "Epoch 16/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1227 - val_loss: 0.8768\n",
      "\n",
      "Epoch 17/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1218 - val_loss: 0.8528\n",
      "\n",
      "Epoch 18/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1122 - val_loss: 0.8288\n",
      "\n",
      "Epoch 19/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1042 - val_loss: 0.8057\n",
      "\n",
      "Epoch 20/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1017 - val_loss: 0.7845\n",
      "\n",
      "Epoch 21/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0976 - val_loss: 0.7653\n",
      "\n",
      "Epoch 22/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1018 - val_loss: 0.7482\n",
      "\n",
      "Epoch 23/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0987 - val_loss: 0.7338\n",
      "\n",
      "Epoch 24/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0991 - val_loss: 0.7220\n",
      "\n",
      "Epoch 25/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0978 - val_loss: 0.7130\n",
      "\n",
      "Epoch 26/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1008 - val_loss: 0.7061\n",
      "\n",
      "Epoch 27/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1017 - val_loss: 0.7010\n",
      "\n",
      "Epoch 28/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1029 - val_loss: 0.6973\n",
      "\n",
      "Epoch 29/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1063 - val_loss: 0.6949\n",
      "\n",
      "Epoch 30/1000\n",
      "40/40 [==============================]\n",
      " - 0s 4ms/step - loss: 0.1071 - val_loss: 0.6936\n",
      "\n",
      "Epoch 31/1000\n",
      "40/40 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1049 - val_loss: 0.6932\n",
      "\n",
      "Epoch 32/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1035 - val_loss: 0.6935\n",
      "\n",
      "Epoch 33/1000\n",
      "40/40 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1043 - val_loss: 0.6944\n",
      "\n",
      "Epoch 34/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1020 - val_loss: 0.6958\n",
      "\n",
      "Epoch 35/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1039 - val_loss: 0.6976\n",
      "\n",
      "Epoch 36/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0964 - val_loss: 0.6999\n",
      "\n",
      "Epoch 37/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0998 - val_loss: 0.7024\n",
      "\n",
      "Epoch 38/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0975 - val_loss: 0.7051\n",
      "\n",
      "Epoch 39/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0982 - val_loss: 0.7081\n",
      "\n",
      "Epoch 40/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0954 - val_loss: 0.7114\n",
      "\n",
      "Epoch 41/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0975 - val_loss: 0.7148\n",
      "\n",
      "Epoch 42/1000\n",
      "40/40 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0957 - val_loss: 0.7182\n",
      "\n",
      "Epoch 43/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0931 - val_loss: 0.7216\n",
      "\n",
      "Epoch 44/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0954 - val_loss: 0.7249\n",
      "\n",
      "Epoch 45/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0982 - val_loss: 0.7279\n",
      "\n",
      "Epoch 46/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0980 - val_loss: 0.7309\n",
      "\n",
      "Epoch 47/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0929 - val_loss: 0.7336\n",
      "\n",
      "Epoch 48/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0944 - val_loss: 0.7362\n",
      "\n",
      "Epoch 49/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0950 - val_loss: 0.7385\n",
      "\n",
      "Epoch 50/1000\n",
      "40/40 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0956 - val_loss: 0.7407\n",
      "\n",
      "Epoch 51/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0952 - val_loss: 0.7428\n",
      "\n",
      "Epoch 52/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0963 - val_loss: 0.7445\n",
      "\n",
      "Epoch 53/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0995 - val_loss: 0.7460\n",
      "\n",
      "Epoch 54/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0988 - val_loss: 0.7474\n",
      "\n",
      "Epoch 55/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0949 - val_loss: 0.7485\n",
      "\n",
      "Epoch 56/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0953 - val_loss: 0.7494\n",
      "\n",
      "Epoch 57/1000\n",
      "40/40 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0936 - val_loss: 0.7501\n",
      "\n",
      "Epoch 58/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0980 - val_loss: 0.7505\n",
      "\n",
      "Epoch 59/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0993 - val_loss: 0.7508\n",
      "\n",
      "Epoch 60/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1003 - val_loss: 0.7509\n",
      "\n",
      "Epoch 61/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0985 - val_loss: 0.7508\n",
      "\n",
      "Epoch 62/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1006 - val_loss: 0.7504\n",
      "\n",
      "Epoch 63/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1000 - val_loss: 0.7499\n",
      "\n",
      "Epoch 64/1000\n",
      "40/40 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0964 - val_loss: 0.7493\n",
      "\n",
      "Epoch 65/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1002 - val_loss: 0.7485\n",
      "\n",
      "Epoch 66/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0977 - val_loss: 0.7476\n",
      "\n",
      "Epoch 67/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0974 - val_loss: 0.7467\n",
      "\n",
      "Epoch 68/1000\n",
      "40/40 [==============================]\n",
      " - 0s 1ms/step - loss: 0.0992 - val_loss: 0.7456\n",
      "\n",
      "Epoch 69/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0986 - val_loss: 0.7445\n",
      "\n",
      "Epoch 70/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0968 - val_loss: 0.7432\n",
      "\n",
      "Epoch 71/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0994 - val_loss: 0.7419\n",
      "\n",
      "Epoch 72/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0947 - val_loss: 0.7406\n",
      "\n",
      "Epoch 73/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0949 - val_loss: 0.7392\n",
      "\n",
      "Epoch 74/1000\n",
      "40/40 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0931 - val_loss: 0.7378\n",
      "\n",
      "Epoch 75/1000\n",
      "40/40 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0962 - val_loss: 0.7364\n",
      "\n",
      "Epoch 76/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0947 - val_loss: 0.7350\n",
      "\n",
      "Epoch 77/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0928 - val_loss: 0.7335\n",
      "\n",
      "Epoch 78/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0934 - val_loss: 0.7320\n",
      "\n",
      "Epoch 79/1000\n",
      "40/40 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0932 - val_loss: 0.7306\n",
      "\n",
      "Epoch 80/1000\n",
      "40/40 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0965 - val_loss: 0.7291\n",
      "\n",
      "Epoch 81/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0945 - val_loss: 0.7276\n",
      "\n",
      "Epoch 82/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0940 - val_loss: 0.7262\n",
      "\n",
      "Epoch 83/1000\n",
      "40/40 [==============================]\n",
      " - 0s 1ms/step - loss: 0.0950 - val_loss: 0.7247\n",
      "\n",
      "Epoch 84/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0918 - val_loss: 0.7233\n",
      "\n",
      "Epoch 85/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0917 - val_loss: 0.7218\n",
      "\n",
      "Epoch 86/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0945 - val_loss: 0.7205\n",
      "\n",
      "Epoch 87/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0919 - val_loss: 0.7191\n",
      "\n",
      "Epoch 88/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0896 - val_loss: 0.7178\n",
      "\n",
      "Epoch 89/1000\n",
      "40/40 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0930 - val_loss: 0.7165\n",
      "\n",
      "Epoch 90/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0922 - val_loss: 0.7152\n",
      "\n",
      "Epoch 91/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0941 - val_loss: 0.7140\n",
      "\n",
      "Epoch 92/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0950 - val_loss: 0.7128\n",
      "\n",
      "Epoch 93/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0926 - val_loss: 0.7116\n",
      "\n",
      "Epoch 94/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0935 - val_loss: 0.7104\n",
      "\n",
      "Epoch 95/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0909 - val_loss: 0.7093\n",
      "\n",
      "Epoch 96/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0919 - val_loss: 0.7082\n",
      "\n",
      "Epoch 97/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0940 - val_loss: 0.7071\n",
      "\n",
      "Epoch 98/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0941 - val_loss: 0.7061\n",
      "\n",
      "Epoch 99/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0935 - val_loss: 0.7052\n",
      "\n",
      "Epoch 100/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0927 - val_loss: 0.7042\n",
      "\n",
      "Epoch 101/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0908 - val_loss: 0.7033\n",
      "\n",
      "50/50 [==============================]\n",
      " - 0s 179us/step\n",
      "\n",
      "Window size 2 score = 0.21425218880176544\n",
      "Window size is 6\n",
      "Train on 36 samples, validate on 10 samples\n",
      "Epoch 1/1000\n",
      "36/36 [==============================]\n",
      " - 13s 368ms/step - loss: 0.2483 - val_loss: 0.3592\n",
      "\n",
      "Epoch 2/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.2299 - val_loss: 0.4255\n",
      "\n",
      "Epoch 3/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1927 - val_loss: 0.5703\n",
      "\n",
      "Epoch 4/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1227 - val_loss: 0.8014\n",
      "\n",
      "Epoch 5/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1122 - val_loss: 0.7839\n",
      "\n",
      "Epoch 6/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1064 - val_loss: 0.6986\n",
      "\n",
      "Epoch 7/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0876 - val_loss: 0.6244\n",
      "\n",
      "Epoch 8/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0921 - val_loss: 0.5911\n",
      "\n",
      "Epoch 9/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0951 - val_loss: 0.5844\n",
      "\n",
      "Epoch 10/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0970 - val_loss: 0.5933\n",
      "\n",
      "Epoch 11/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0912 - val_loss: 0.6090\n",
      "\n",
      "Epoch 12/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0840 - val_loss: 0.6310\n",
      "\n",
      "Epoch 13/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0788 - val_loss: 0.6509\n",
      "\n",
      "Epoch 14/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0826 - val_loss: 0.6656\n",
      "\n",
      "Epoch 15/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0880 - val_loss: 0.6741\n",
      "\n",
      "Epoch 16/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0824 - val_loss: 0.6777\n",
      "\n",
      "Epoch 17/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0801 - val_loss: 0.6765\n",
      "\n",
      "Epoch 18/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0888 - val_loss: 0.6710\n",
      "\n",
      "Epoch 19/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0852 - val_loss: 0.6609\n",
      "\n",
      "Epoch 20/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0806 - val_loss: 0.6483\n",
      "\n",
      "Epoch 21/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0809 - val_loss: 0.6353\n",
      "\n",
      "Epoch 22/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0777 - val_loss: 0.6241\n",
      "\n",
      "Epoch 23/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0772 - val_loss: 0.6131\n",
      "\n",
      "Epoch 24/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0807 - val_loss: 0.6026\n",
      "\n",
      "Epoch 25/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0808 - val_loss: 0.5934\n",
      "\n",
      "Epoch 26/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0822 - val_loss: 0.5861\n",
      "\n",
      "Epoch 27/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0795 - val_loss: 0.5806\n",
      "\n",
      "Epoch 28/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0800 - val_loss: 0.5772\n",
      "\n",
      "Epoch 29/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0792 - val_loss: 0.5755\n",
      "\n",
      "Epoch 30/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0833 - val_loss: 0.5755\n",
      "\n",
      "Epoch 31/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0834 - val_loss: 0.5769\n",
      "\n",
      "Epoch 32/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0781 - val_loss: 0.5789\n",
      "\n",
      "Epoch 33/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0792 - val_loss: 0.5812\n",
      "\n",
      "Epoch 34/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0753 - val_loss: 0.5841\n",
      "\n",
      "Epoch 35/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0775 - val_loss: 0.5876\n",
      "\n",
      "Epoch 36/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0778 - val_loss: 0.5912\n",
      "\n",
      "Epoch 37/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0790 - val_loss: 0.5949\n",
      "\n",
      "Epoch 38/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0771 - val_loss: 0.5985\n",
      "\n",
      "Epoch 39/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0803 - val_loss: 0.6020\n",
      "\n",
      "Epoch 40/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0834 - val_loss: 0.6056\n",
      "\n",
      "Epoch 41/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0716 - val_loss: 0.6087\n",
      "\n",
      "Epoch 42/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0762 - val_loss: 0.6113\n",
      "\n",
      "Epoch 43/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0780 - val_loss: 0.6135\n",
      "\n",
      "Epoch 44/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0739 - val_loss: 0.6156\n",
      "\n",
      "Epoch 45/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0761 - val_loss: 0.6174\n",
      "\n",
      "Epoch 46/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0776 - val_loss: 0.6190\n",
      "\n",
      "Epoch 47/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0816 - val_loss: 0.6200\n",
      "\n",
      "Epoch 48/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0792 - val_loss: 0.6206\n",
      "\n",
      "Epoch 49/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0765 - val_loss: 0.6207\n",
      "\n",
      "Epoch 50/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0763 - val_loss: 0.6203\n",
      "\n",
      "Epoch 51/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0797 - val_loss: 0.6196\n",
      "\n",
      "Epoch 52/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0771 - val_loss: 0.6185\n",
      "\n",
      "Epoch 53/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0806 - val_loss: 0.6170\n",
      "\n",
      "Epoch 54/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0824 - val_loss: 0.6150\n",
      "\n",
      "Epoch 55/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0751 - val_loss: 0.6130\n",
      "\n",
      "Epoch 56/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0765 - val_loss: 0.6107\n",
      "\n",
      "Epoch 57/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0769 - val_loss: 0.6084\n",
      "\n",
      "Epoch 58/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0802 - val_loss: 0.6059\n",
      "\n",
      "Epoch 59/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0732 - val_loss: 0.6034\n",
      "\n",
      "Epoch 60/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0687 - val_loss: 0.6009\n",
      "\n",
      "Epoch 61/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0804 - val_loss: 0.5985\n",
      "\n",
      "Epoch 62/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0810 - val_loss: 0.5959\n",
      "\n",
      "Epoch 63/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0797 - val_loss: 0.5933\n",
      "\n",
      "Epoch 64/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0784 - val_loss: 0.5908\n",
      "\n",
      "Epoch 65/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0758 - val_loss: 0.5884\n",
      "\n",
      "Epoch 66/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0741 - val_loss: 0.5861\n",
      "\n",
      "Epoch 67/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0764 - val_loss: 0.5841\n",
      "\n",
      "Epoch 68/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0795 - val_loss: 0.5822\n",
      "\n",
      "Epoch 69/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0753 - val_loss: 0.5806\n",
      "\n",
      "Epoch 70/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0746 - val_loss: 0.5790\n",
      "\n",
      "Epoch 71/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0772 - val_loss: 0.5778\n",
      "\n",
      "Epoch 72/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0755 - val_loss: 0.5770\n",
      "\n",
      "Epoch 73/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0774 - val_loss: 0.5765\n",
      "\n",
      "Epoch 74/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0772 - val_loss: 0.5759\n",
      "\n",
      "Epoch 75/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0787 - val_loss: 0.5754\n",
      "\n",
      "Epoch 76/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0783 - val_loss: 0.5752\n",
      "\n",
      "Epoch 77/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0774 - val_loss: 0.5751\n",
      "\n",
      "Epoch 78/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0750 - val_loss: 0.5752\n",
      "\n",
      "Epoch 79/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0821 - val_loss: 0.5753\n",
      "\n",
      "Epoch 80/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0755 - val_loss: 0.5756\n",
      "\n",
      "Epoch 81/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0747 - val_loss: 0.5761\n",
      "\n",
      "Epoch 82/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0755 - val_loss: 0.5766\n",
      "\n",
      "Epoch 83/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0741 - val_loss: 0.5772\n",
      "\n",
      "Epoch 84/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0796 - val_loss: 0.5778\n",
      "\n",
      "Epoch 85/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0773 - val_loss: 0.5784\n",
      "\n",
      "Epoch 86/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0735 - val_loss: 0.5790\n",
      "\n",
      "Epoch 87/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0744 - val_loss: 0.5797\n",
      "\n",
      "Epoch 88/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0784 - val_loss: 0.5803\n",
      "\n",
      "Epoch 89/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0732 - val_loss: 0.5812\n",
      "\n",
      "Epoch 90/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0737 - val_loss: 0.5820\n",
      "\n",
      "Epoch 91/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0759 - val_loss: 0.5828\n",
      "\n",
      "Epoch 92/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0782 - val_loss: 0.5838\n",
      "\n",
      "Epoch 93/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0752 - val_loss: 0.5847\n",
      "\n",
      "Epoch 94/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0767 - val_loss: 0.5855\n",
      "\n",
      "Epoch 95/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0784 - val_loss: 0.5864\n",
      "\n",
      "Epoch 96/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0738 - val_loss: 0.5872\n",
      "\n",
      "Epoch 97/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0747 - val_loss: 0.5880\n",
      "\n",
      "Epoch 98/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0747 - val_loss: 0.5888\n",
      "\n",
      "Epoch 99/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0749 - val_loss: 0.5896\n",
      "\n",
      "Epoch 100/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0793 - val_loss: 0.5904\n",
      "\n",
      "Epoch 101/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0777 - val_loss: 0.5912\n",
      "\n",
      "46/46 [==============================]\n",
      " - 0s 298us/step\n",
      "\n",
      "Window size 6 score = 0.18677964806556702\n",
      "Window size is 7\n",
      "Train on 36 samples, validate on 9 samples\n",
      "Epoch 1/1000\n",
      "36/36 [==============================]\n",
      " - 10s 290ms/step - loss: 0.2434 - val_loss: 0.2515\n",
      "\n",
      "Epoch 2/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.2178 - val_loss: 0.3419\n",
      "\n",
      "Epoch 3/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1600 - val_loss: 0.5500\n",
      "\n",
      "Epoch 4/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0698 - val_loss: 0.6714\n",
      "\n",
      "Epoch 5/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1289 - val_loss: 0.5673\n",
      "\n",
      "Epoch 6/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0746 - val_loss: 0.4574\n",
      "\n",
      "Epoch 7/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0814 - val_loss: 0.4172\n",
      "\n",
      "Epoch 8/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1015 - val_loss: 0.4094\n",
      "\n",
      "Epoch 9/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1041 - val_loss: 0.4187\n",
      "\n",
      "Epoch 10/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1014 - val_loss: 0.4389\n",
      "\n",
      "Epoch 11/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0856 - val_loss: 0.4683\n",
      "\n",
      "Epoch 12/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0691 - val_loss: 0.5006\n",
      "\n",
      "Epoch 13/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0636 - val_loss: 0.5295\n",
      "\n",
      "Epoch 14/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0639 - val_loss: 0.5523\n",
      "\n",
      "Epoch 15/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0713 - val_loss: 0.5627\n",
      "\n",
      "Epoch 16/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0761 - val_loss: 0.5627\n",
      "\n",
      "Epoch 17/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0812 - val_loss: 0.5571\n",
      "\n",
      "Epoch 18/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0771 - val_loss: 0.5440\n",
      "\n",
      "Epoch 19/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0757 - val_loss: 0.5282\n",
      "\n",
      "Epoch 20/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0684 - val_loss: 0.5119\n",
      "\n",
      "Epoch 21/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0680 - val_loss: 0.4954\n",
      "\n",
      "Epoch 22/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0652 - val_loss: 0.4802\n",
      "\n",
      "Epoch 23/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0583 - val_loss: 0.4674\n",
      "\n",
      "Epoch 24/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0646 - val_loss: 0.4564\n",
      "\n",
      "Epoch 25/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0632 - val_loss: 0.4479\n",
      "\n",
      "Epoch 26/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0637 - val_loss: 0.4420\n",
      "\n",
      "Epoch 27/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0693 - val_loss: 0.4382\n",
      "\n",
      "Epoch 28/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0704 - val_loss: 0.4369\n",
      "\n",
      "Epoch 29/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0746 - val_loss: 0.4376\n",
      "\n",
      "Epoch 30/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0730 - val_loss: 0.4398\n",
      "\n",
      "Epoch 31/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0694 - val_loss: 0.4435\n",
      "\n",
      "Epoch 32/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0690 - val_loss: 0.4483\n",
      "\n",
      "Epoch 33/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0681 - val_loss: 0.4539\n",
      "\n",
      "Epoch 34/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0615 - val_loss: 0.4601\n",
      "\n",
      "Epoch 35/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0656 - val_loss: 0.4666\n",
      "\n",
      "Epoch 36/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0658 - val_loss: 0.4729\n",
      "\n",
      "Epoch 37/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0619 - val_loss: 0.4792\n",
      "\n",
      "Epoch 38/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0655 - val_loss: 0.4854\n",
      "\n",
      "Epoch 39/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0595 - val_loss: 0.4911\n",
      "\n",
      "Epoch 40/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0649 - val_loss: 0.4963\n",
      "\n",
      "Epoch 41/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0651 - val_loss: 0.5010\n",
      "\n",
      "Epoch 42/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0605 - val_loss: 0.5051\n",
      "\n",
      "Epoch 43/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0610 - val_loss: 0.5084\n",
      "\n",
      "Epoch 44/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0614 - val_loss: 0.5111\n",
      "\n",
      "Epoch 45/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0653 - val_loss: 0.5133\n",
      "\n",
      "Epoch 46/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0628 - val_loss: 0.5146\n",
      "\n",
      "Epoch 47/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0670 - val_loss: 0.5154\n",
      "\n",
      "Epoch 48/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0679 - val_loss: 0.5157\n",
      "\n",
      "Epoch 49/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0692 - val_loss: 0.5153\n",
      "\n",
      "Epoch 50/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0667 - val_loss: 0.5142\n",
      "\n",
      "Epoch 51/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0617 - val_loss: 0.5126\n",
      "\n",
      "Epoch 52/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0648 - val_loss: 0.5105\n",
      "\n",
      "Epoch 53/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0678 - val_loss: 0.5082\n",
      "\n",
      "Epoch 54/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0620 - val_loss: 0.5054\n",
      "\n",
      "Epoch 55/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0628 - val_loss: 0.5026\n",
      "\n",
      "Epoch 56/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0632 - val_loss: 0.4996\n",
      "\n",
      "Epoch 57/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0648 - val_loss: 0.4963\n",
      "\n",
      "Epoch 58/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0599 - val_loss: 0.4930\n",
      "\n",
      "Epoch 59/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0598 - val_loss: 0.4895\n",
      "\n",
      "Epoch 60/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0638 - val_loss: 0.4860\n",
      "\n",
      "Epoch 61/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0621 - val_loss: 0.4826\n",
      "\n",
      "Epoch 62/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0603 - val_loss: 0.4793\n",
      "\n",
      "Epoch 63/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0600 - val_loss: 0.4761\n",
      "\n",
      "Epoch 64/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0603 - val_loss: 0.4730\n",
      "\n",
      "Epoch 65/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0573 - val_loss: 0.4701\n",
      "\n",
      "Epoch 66/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0612 - val_loss: 0.4673\n",
      "\n",
      "Epoch 67/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0622 - val_loss: 0.4645\n",
      "\n",
      "Epoch 68/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0575 - val_loss: 0.4619\n",
      "\n",
      "Epoch 69/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0612 - val_loss: 0.4595\n",
      "\n",
      "Epoch 70/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0627 - val_loss: 0.4574\n",
      "\n",
      "Epoch 71/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0640 - val_loss: 0.4555\n",
      "\n",
      "Epoch 72/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0623 - val_loss: 0.4538\n",
      "\n",
      "Epoch 73/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0619 - val_loss: 0.4523\n",
      "\n",
      "Epoch 74/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0624 - val_loss: 0.4510\n",
      "\n",
      "Epoch 75/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0643 - val_loss: 0.4499\n",
      "\n",
      "Epoch 76/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0661 - val_loss: 0.4490\n",
      "\n",
      "Epoch 77/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0627 - val_loss: 0.4484\n",
      "\n",
      "Epoch 78/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0612 - val_loss: 0.4479\n",
      "\n",
      "Epoch 79/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0676 - val_loss: 0.4476\n",
      "\n",
      "Epoch 80/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0591 - val_loss: 0.4474\n",
      "\n",
      "Epoch 81/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0675 - val_loss: 0.4475\n",
      "\n",
      "Epoch 82/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0641 - val_loss: 0.4476\n",
      "\n",
      "Epoch 83/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0660 - val_loss: 0.4478\n",
      "\n",
      "Epoch 84/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0618 - val_loss: 0.4482\n",
      "\n",
      "Epoch 85/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0634 - val_loss: 0.4487\n",
      "\n",
      "Epoch 86/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0613 - val_loss: 0.4494\n",
      "\n",
      "Epoch 87/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0635 - val_loss: 0.4502\n",
      "\n",
      "Epoch 88/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0580 - val_loss: 0.4510\n",
      "\n",
      "Epoch 89/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0609 - val_loss: 0.4519\n",
      "\n",
      "Epoch 90/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0579 - val_loss: 0.4528\n",
      "\n",
      "Epoch 91/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0612 - val_loss: 0.4538\n",
      "\n",
      "Epoch 92/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0620 - val_loss: 0.4548\n",
      "\n",
      "Epoch 93/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0606 - val_loss: 0.4559\n",
      "\n",
      "Epoch 94/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0657 - val_loss: 0.4570\n",
      "\n",
      "Epoch 95/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0573 - val_loss: 0.4582\n",
      "\n",
      "Epoch 96/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0625 - val_loss: 0.4593\n",
      "\n",
      "Epoch 97/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0613 - val_loss: 0.4605\n",
      "\n",
      "Epoch 98/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0595 - val_loss: 0.4617\n",
      "\n",
      "Epoch 99/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0544 - val_loss: 0.4629\n",
      "\n",
      "Epoch 100/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0599 - val_loss: 0.4641\n",
      "\n",
      "Epoch 101/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0591 - val_loss: 0.4653\n",
      "\n",
      "45/45 [==============================]\n",
      " - 0s 298us/step\n",
      "\n",
      "Window size 7 score = 0.14055132865905762\n",
      "Window size is 7\n",
      "Train on 36 samples, validate on 9 samples\n",
      "Epoch 1/1000\n",
      "36/36 [==============================]\n",
      " - 11s 315ms/step - loss: 0.2326 - val_loss: 0.1397\n",
      "\n",
      "Epoch 2/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.2101 - val_loss: 0.1977\n",
      "\n",
      "Epoch 3/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1531 - val_loss: 0.3515\n",
      "\n",
      "Epoch 4/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0534 - val_loss: 0.5561\n",
      "\n",
      "Epoch 5/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.2101 - val_loss: 0.5561\n",
      "\n",
      "Epoch 6/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.2071 - val_loss: 0.5132\n",
      "\n",
      "Epoch 7/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1301 - val_loss: 0.3869\n",
      "\n",
      "Epoch 8/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0516 - val_loss: 0.3006\n",
      "\n",
      "Epoch 9/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0648 - val_loss: 0.2642\n",
      "\n",
      "Epoch 10/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0932 - val_loss: 0.2491\n",
      "\n",
      "Epoch 11/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1056 - val_loss: 0.2453\n",
      "\n",
      "Epoch 12/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1090 - val_loss: 0.2481\n",
      "\n",
      "Epoch 13/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1011 - val_loss: 0.2557\n",
      "\n",
      "Epoch 14/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0960 - val_loss: 0.2672\n",
      "\n",
      "Epoch 15/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0849 - val_loss: 0.2826\n",
      "\n",
      "Epoch 16/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0772 - val_loss: 0.3014\n",
      "\n",
      "Epoch 17/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0588 - val_loss: 0.3227\n",
      "\n",
      "Epoch 18/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0528 - val_loss: 0.3452\n",
      "\n",
      "Epoch 19/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0473 - val_loss: 0.3681\n",
      "\n",
      "Epoch 20/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0515 - val_loss: 0.3886\n",
      "\n",
      "Epoch 21/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0567 - val_loss: 0.4049\n",
      "\n",
      "Epoch 22/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0671 - val_loss: 0.4147\n",
      "\n",
      "Epoch 23/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0737 - val_loss: 0.4191\n",
      "\n",
      "Epoch 24/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0748 - val_loss: 0.4191\n",
      "\n",
      "Epoch 25/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0703 - val_loss: 0.4154\n",
      "\n",
      "Epoch 26/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0720 - val_loss: 0.4086\n",
      "\n",
      "Epoch 27/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0602 - val_loss: 0.3999\n",
      "\n",
      "Epoch 28/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0569 - val_loss: 0.3903\n",
      "\n",
      "Epoch 29/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0537 - val_loss: 0.3806\n",
      "\n",
      "Epoch 30/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0544 - val_loss: 0.3706\n",
      "\n",
      "Epoch 31/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0531 - val_loss: 0.3608\n",
      "\n",
      "Epoch 32/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0478 - val_loss: 0.3514\n",
      "\n",
      "Epoch 33/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0465 - val_loss: 0.3425\n",
      "\n",
      "Epoch 34/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0474 - val_loss: 0.3344\n",
      "\n",
      "Epoch 35/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0455 - val_loss: 0.3272\n",
      "\n",
      "Epoch 36/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0512 - val_loss: 0.3206\n",
      "\n",
      "Epoch 37/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0490 - val_loss: 0.3151\n",
      "\n",
      "Epoch 38/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0504 - val_loss: 0.3100\n",
      "\n",
      "Epoch 39/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0519 - val_loss: 0.3056\n",
      "\n",
      "Epoch 40/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0546 - val_loss: 0.3023\n",
      "\n",
      "Epoch 41/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0543 - val_loss: 0.2996\n",
      "\n",
      "Epoch 42/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0597 - val_loss: 0.2977\n",
      "\n",
      "Epoch 43/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0545 - val_loss: 0.2964\n",
      "\n",
      "Epoch 44/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0588 - val_loss: 0.2955\n",
      "\n",
      "Epoch 45/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0567 - val_loss: 0.2952\n",
      "\n",
      "Epoch 46/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0600 - val_loss: 0.2955\n",
      "\n",
      "Epoch 47/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0591 - val_loss: 0.2961\n",
      "\n",
      "Epoch 48/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0581 - val_loss: 0.2972\n",
      "\n",
      "Epoch 49/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0569 - val_loss: 0.2987\n",
      "\n",
      "Epoch 50/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0550 - val_loss: 0.3006\n",
      "\n",
      "Epoch 51/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0560 - val_loss: 0.3027\n",
      "\n",
      "Epoch 52/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0519 - val_loss: 0.3050\n",
      "\n",
      "Epoch 53/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0523 - val_loss: 0.3076\n",
      "\n",
      "Epoch 54/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0486 - val_loss: 0.3104\n",
      "\n",
      "Epoch 55/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0479 - val_loss: 0.3133\n",
      "\n",
      "Epoch 56/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0497 - val_loss: 0.3163\n",
      "\n",
      "Epoch 57/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0464 - val_loss: 0.3194\n",
      "\n",
      "Epoch 58/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0454 - val_loss: 0.3224\n",
      "\n",
      "Epoch 59/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0479 - val_loss: 0.3254\n",
      "\n",
      "Epoch 60/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0437 - val_loss: 0.3284\n",
      "\n",
      "Epoch 61/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0494 - val_loss: 0.3313\n",
      "\n",
      "Epoch 62/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0484 - val_loss: 0.3342\n",
      "\n",
      "Epoch 63/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0484 - val_loss: 0.3370\n",
      "\n",
      "Epoch 64/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0454 - val_loss: 0.3397\n",
      "\n",
      "Epoch 65/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0490 - val_loss: 0.3425\n",
      "\n",
      "Epoch 66/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0423 - val_loss: 0.3451\n",
      "\n",
      "Epoch 67/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0480 - val_loss: 0.3478\n",
      "\n",
      "Epoch 68/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0465 - val_loss: 0.3503\n",
      "\n",
      "Epoch 69/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0443 - val_loss: 0.3527\n",
      "\n",
      "Epoch 70/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0474 - val_loss: 0.3550\n",
      "\n",
      "Epoch 71/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0461 - val_loss: 0.3572\n",
      "\n",
      "Epoch 72/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0506 - val_loss: 0.3591\n",
      "\n",
      "Epoch 73/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0483 - val_loss: 0.3608\n",
      "\n",
      "Epoch 74/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0493 - val_loss: 0.3624\n",
      "\n",
      "Epoch 75/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0498 - val_loss: 0.3637\n",
      "\n",
      "Epoch 76/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0515 - val_loss: 0.3647\n",
      "\n",
      "Epoch 77/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0539 - val_loss: 0.3656\n",
      "\n",
      "Epoch 78/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0519 - val_loss: 0.3663\n",
      "\n",
      "Epoch 79/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0459 - val_loss: 0.3668\n",
      "\n",
      "Epoch 80/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0564 - val_loss: 0.3672\n",
      "\n",
      "Epoch 81/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0462 - val_loss: 0.3673\n",
      "\n",
      "Epoch 82/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0522 - val_loss: 0.3672\n",
      "\n",
      "Epoch 83/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0483 - val_loss: 0.3671\n",
      "\n",
      "Epoch 84/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0499 - val_loss: 0.3667\n",
      "\n",
      "Epoch 85/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0523 - val_loss: 0.3663\n",
      "\n",
      "Epoch 86/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0508 - val_loss: 0.3658\n",
      "\n",
      "Epoch 87/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0521 - val_loss: 0.3652\n",
      "\n",
      "Epoch 88/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0485 - val_loss: 0.3645\n",
      "\n",
      "Epoch 89/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0501 - val_loss: 0.3637\n",
      "\n",
      "Epoch 90/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0524 - val_loss: 0.3628\n",
      "\n",
      "Epoch 91/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0495 - val_loss: 0.3619\n",
      "\n",
      "Epoch 92/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0527 - val_loss: 0.3609\n",
      "\n",
      "Epoch 93/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0472 - val_loss: 0.3598\n",
      "\n",
      "Epoch 94/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0518 - val_loss: 0.3586\n",
      "\n",
      "Epoch 95/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0530 - val_loss: 0.3574\n",
      "\n",
      "Epoch 96/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0459 - val_loss: 0.3562\n",
      "\n",
      "Epoch 97/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0503 - val_loss: 0.3549\n",
      "\n",
      "Epoch 98/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0463 - val_loss: 0.3536\n",
      "\n",
      "Epoch 99/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0487 - val_loss: 0.3523\n",
      "\n",
      "Epoch 100/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0465 - val_loss: 0.3510\n",
      "\n",
      "Epoch 101/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0480 - val_loss: 0.3498\n",
      "\n",
      "45/45 [==============================]\n",
      " - 0s 276us/step\n",
      "\n",
      "Window size 7 score = 0.10635903477668762\n",
      "Window size is 6\n",
      "Train on 36 samples, validate on 10 samples\n",
      "Epoch 1/1000\n",
      "36/36 [==============================]\n",
      " - 12s 332ms/step - loss: 0.3038 - val_loss: 0.1051\n",
      "\n",
      "Epoch 2/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.2768 - val_loss: 0.1047\n",
      "\n",
      "Epoch 3/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.2159 - val_loss: 0.1765\n",
      "\n",
      "Epoch 4/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0785 - val_loss: 0.4238\n",
      "\n",
      "Epoch 5/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1796 - val_loss: 0.4222\n",
      "\n",
      "Epoch 6/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1698 - val_loss: 0.3430\n",
      "\n",
      "Epoch 7/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0764 - val_loss: 0.2329\n",
      "\n",
      "Epoch 8/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0449 - val_loss: 0.1685\n",
      "\n",
      "Epoch 9/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0808 - val_loss: 0.1470\n",
      "\n",
      "Epoch 10/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1072 - val_loss: 0.1401\n",
      "\n",
      "Epoch 11/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1137 - val_loss: 0.1404\n",
      "\n",
      "Epoch 12/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1123 - val_loss: 0.1457\n",
      "\n",
      "Epoch 13/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1054 - val_loss: 0.1553\n",
      "\n",
      "Epoch 14/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0896 - val_loss: 0.1721\n",
      "\n",
      "Epoch 15/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0788 - val_loss: 0.1961\n",
      "\n",
      "Epoch 16/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0544 - val_loss: 0.2268\n",
      "\n",
      "Epoch 17/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0451 - val_loss: 0.2578\n",
      "\n",
      "Epoch 18/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0477 - val_loss: 0.2853\n",
      "\n",
      "Epoch 19/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0571 - val_loss: 0.3071\n",
      "\n",
      "Epoch 20/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0682 - val_loss: 0.3201\n",
      "\n",
      "Epoch 21/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0706 - val_loss: 0.3246\n",
      "\n",
      "Epoch 22/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0752 - val_loss: 0.3230\n",
      "\n",
      "Epoch 23/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0793 - val_loss: 0.3151\n",
      "\n",
      "Epoch 24/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0780 - val_loss: 0.3036\n",
      "\n",
      "Epoch 25/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0705 - val_loss: 0.2897\n",
      "\n",
      "Epoch 26/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0570 - val_loss: 0.2748\n",
      "\n",
      "Epoch 27/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0482 - val_loss: 0.2592\n",
      "\n",
      "Epoch 28/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0484 - val_loss: 0.2441\n",
      "\n",
      "Epoch 29/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0393 - val_loss: 0.2300\n",
      "\n",
      "Epoch 30/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0359 - val_loss: 0.2170\n",
      "\n",
      "Epoch 31/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0403 - val_loss: 0.2054\n",
      "\n",
      "Epoch 32/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0469 - val_loss: 0.1959\n",
      "\n",
      "Epoch 33/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0506 - val_loss: 0.1878\n",
      "\n",
      "Epoch 34/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0462 - val_loss: 0.1817\n",
      "\n",
      "Epoch 35/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0565 - val_loss: 0.1776\n",
      "\n",
      "Epoch 36/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0552 - val_loss: 0.1750\n",
      "\n",
      "Epoch 37/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0587 - val_loss: 0.1739\n",
      "\n",
      "Epoch 38/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0575 - val_loss: 0.1739\n",
      "\n",
      "Epoch 39/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0586 - val_loss: 0.1749\n",
      "\n",
      "Epoch 40/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0621 - val_loss: 0.1769\n",
      "\n",
      "Epoch 41/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0629 - val_loss: 0.1797\n",
      "\n",
      "Epoch 42/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0581 - val_loss: 0.1833\n",
      "\n",
      "Epoch 43/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0505 - val_loss: 0.1875\n",
      "\n",
      "Epoch 44/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0518 - val_loss: 0.1921\n",
      "\n",
      "Epoch 45/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0517 - val_loss: 0.1973\n",
      "\n",
      "Epoch 46/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0415 - val_loss: 0.2026\n",
      "\n",
      "Epoch 47/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0370 - val_loss: 0.2083\n",
      "\n",
      "Epoch 48/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0435 - val_loss: 0.2140\n",
      "\n",
      "Epoch 49/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0410 - val_loss: 0.2198\n",
      "\n",
      "Epoch 50/1000\n",
      "36/36 [==============================]\n",
      " - 0s 1ms/step - loss: 0.0367 - val_loss: 0.2256\n",
      "\n",
      "Epoch 51/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0420 - val_loss: 0.2311\n",
      "\n",
      "Epoch 52/1000\n",
      "36/36 [==============================]\n",
      " - 0s 1ms/step - loss: 0.0460 - val_loss: 0.2365\n",
      "\n",
      "Epoch 53/1000\n",
      "36/36 [==============================]\n",
      " - 0s 1ms/step - loss: 0.0442 - val_loss: 0.2416\n",
      "\n",
      "Epoch 54/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0439 - val_loss: 0.2465\n",
      "\n",
      "Epoch 55/1000\n",
      "36/36 [==============================]\n",
      " - 0s 1ms/step - loss: 0.0475 - val_loss: 0.2508\n",
      "\n",
      "Epoch 56/1000\n",
      "36/36 [==============================]\n",
      " - 0s 1ms/step - loss: 0.0427 - val_loss: 0.2547\n",
      "\n",
      "Epoch 57/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0415 - val_loss: 0.2581\n",
      "\n",
      "Epoch 58/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0446 - val_loss: 0.2609\n",
      "\n",
      "Epoch 59/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0451 - val_loss: 0.2632\n",
      "\n",
      "Epoch 60/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0544 - val_loss: 0.2650\n",
      "\n",
      "Epoch 61/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0494 - val_loss: 0.2662\n",
      "\n",
      "Epoch 62/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0448 - val_loss: 0.2672\n",
      "\n",
      "Epoch 63/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0532 - val_loss: 0.2678\n",
      "\n",
      "Epoch 64/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0543 - val_loss: 0.2680\n",
      "\n",
      "Epoch 65/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0469 - val_loss: 0.2677\n",
      "\n",
      "Epoch 66/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0463 - val_loss: 0.2669\n",
      "\n",
      "Epoch 67/1000\n",
      "36/36 [==============================]\n",
      " - 0s 1ms/step - loss: 0.0491 - val_loss: 0.2658\n",
      "\n",
      "Epoch 68/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0519 - val_loss: 0.2643\n",
      "\n",
      "Epoch 69/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0432 - val_loss: 0.2626\n",
      "\n",
      "Epoch 70/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0555 - val_loss: 0.2607\n",
      "\n",
      "Epoch 71/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0442 - val_loss: 0.2587\n",
      "\n",
      "Epoch 72/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0478 - val_loss: 0.2565\n",
      "\n",
      "Epoch 73/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0477 - val_loss: 0.2543\n",
      "\n",
      "Epoch 74/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0430 - val_loss: 0.2518\n",
      "\n",
      "Epoch 75/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0412 - val_loss: 0.2493\n",
      "\n",
      "Epoch 76/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0434 - val_loss: 0.2466\n",
      "\n",
      "Epoch 77/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0433 - val_loss: 0.2440\n",
      "\n",
      "Epoch 78/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0391 - val_loss: 0.2412\n",
      "\n",
      "Epoch 79/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0406 - val_loss: 0.2385\n",
      "\n",
      "Epoch 80/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0463 - val_loss: 0.2359\n",
      "\n",
      "Epoch 81/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0400 - val_loss: 0.2332\n",
      "\n",
      "Epoch 82/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0407 - val_loss: 0.2306\n",
      "\n",
      "Epoch 83/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0414 - val_loss: 0.2281\n",
      "\n",
      "Epoch 84/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0361 - val_loss: 0.2256\n",
      "\n",
      "Epoch 85/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0406 - val_loss: 0.2231\n",
      "\n",
      "Epoch 86/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0346 - val_loss: 0.2207\n",
      "\n",
      "Epoch 87/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0400 - val_loss: 0.2184\n",
      "\n",
      "Epoch 88/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0387 - val_loss: 0.2162\n",
      "\n",
      "Epoch 89/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0372 - val_loss: 0.2140\n",
      "\n",
      "Epoch 90/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0379 - val_loss: 0.2121\n",
      "\n",
      "Epoch 91/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0385 - val_loss: 0.2102\n",
      "\n",
      "Epoch 92/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0384 - val_loss: 0.2083\n",
      "\n",
      "Epoch 93/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0407 - val_loss: 0.2067\n",
      "\n",
      "Epoch 94/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0428 - val_loss: 0.2051\n",
      "\n",
      "Epoch 95/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0401 - val_loss: 0.2038\n",
      "\n",
      "Epoch 96/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0366 - val_loss: 0.2025\n",
      "\n",
      "Epoch 97/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0404 - val_loss: 0.2014\n",
      "\n",
      "Epoch 98/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0395 - val_loss: 0.2004\n",
      "\n",
      "Epoch 99/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0453 - val_loss: 0.1995\n",
      "\n",
      "Epoch 100/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0422 - val_loss: 0.1987\n",
      "\n",
      "Epoch 101/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0403 - val_loss: 0.1981\n",
      "\n",
      "Epoch 102/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0388 - val_loss: 0.1975\n",
      "\n",
      "46/46 [==============================]\n",
      " - 0s 278us/step\n",
      "\n",
      "Window size 6 score = 0.07407873868942261\n",
      "Window size is 4\n",
      "Train on 38 samples, validate on 10 samples\n",
      "Epoch 1/1000\n",
      "38/38 [==============================]\n",
      " - 14s 362ms/step - loss: 0.2282 - val_loss: 0.0932\n",
      "\n",
      "Epoch 2/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.2137 - val_loss: 0.0896\n",
      "\n",
      "Epoch 3/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1882 - val_loss: 0.0939\n",
      "\n",
      "Epoch 4/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1431 - val_loss: 0.1278\n",
      "\n",
      "Epoch 5/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0745 - val_loss: 0.2395\n",
      "\n",
      "Epoch 6/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0515 - val_loss: 0.3145\n",
      "\n",
      "Epoch 7/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1118 - val_loss: 0.2862\n",
      "\n",
      "Epoch 8/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0899 - val_loss: 0.2340\n",
      "\n",
      "Epoch 9/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0569 - val_loss: 0.1854\n",
      "\n",
      "Epoch 10/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0412 - val_loss: 0.1502\n",
      "\n",
      "Epoch 11/1000\n",
      "38/38 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0472 - val_loss: 0.1324\n",
      "\n",
      "Epoch 12/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0607 - val_loss: 0.1253\n",
      "\n",
      "Epoch 13/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0697 - val_loss: 0.1230\n",
      "\n",
      "Epoch 14/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0697 - val_loss: 0.1238\n",
      "\n",
      "Epoch 15/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0667 - val_loss: 0.1270\n",
      "\n",
      "Epoch 16/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0624 - val_loss: 0.1323\n",
      "\n",
      "Epoch 17/1000\n",
      "38/38 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0547 - val_loss: 0.1409\n",
      "\n",
      "Epoch 18/1000\n",
      "38/38 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0490 - val_loss: 0.1511\n",
      "\n",
      "Epoch 19/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0438 - val_loss: 0.1631\n",
      "\n",
      "Epoch 20/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0395 - val_loss: 0.1759\n",
      "\n",
      "Epoch 21/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0375 - val_loss: 0.1883\n",
      "\n",
      "Epoch 22/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0393 - val_loss: 0.1994\n",
      "\n",
      "Epoch 23/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0432 - val_loss: 0.2088\n",
      "\n",
      "Epoch 24/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0435 - val_loss: 0.2159\n",
      "\n",
      "Epoch 25/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0475 - val_loss: 0.2204\n",
      "\n",
      "Epoch 26/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0450 - val_loss: 0.2229\n",
      "\n",
      "Epoch 27/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0581 - val_loss: 0.2232\n",
      "\n",
      "Epoch 28/1000\n",
      "38/38 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0568 - val_loss: 0.2219\n",
      "\n",
      "Epoch 29/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0532 - val_loss: 0.2194\n",
      "\n",
      "Epoch 30/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0487 - val_loss: 0.2157\n",
      "\n",
      "Epoch 31/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0512 - val_loss: 0.2111\n",
      "\n",
      "Epoch 32/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0487 - val_loss: 0.2060\n",
      "\n",
      "Epoch 33/1000\n",
      "38/38 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0425 - val_loss: 0.2003\n",
      "\n",
      "Epoch 34/1000\n",
      "38/38 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0458 - val_loss: 0.1942\n",
      "\n",
      "Epoch 35/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0443 - val_loss: 0.1879\n",
      "\n",
      "Epoch 36/1000\n",
      "38/38 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0382 - val_loss: 0.1818\n",
      "\n",
      "Epoch 37/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0414 - val_loss: 0.1759\n",
      "\n",
      "Epoch 38/1000\n",
      "38/38 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0422 - val_loss: 0.1701\n",
      "\n",
      "Epoch 39/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0391 - val_loss: 0.1647\n",
      "\n",
      "Epoch 40/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0348 - val_loss: 0.1598\n",
      "\n",
      "Epoch 41/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0384 - val_loss: 0.1553\n",
      "\n",
      "Epoch 42/1000\n",
      "38/38 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0369 - val_loss: 0.1513\n",
      "\n",
      "Epoch 43/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0411 - val_loss: 0.1480\n",
      "\n",
      "Epoch 44/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0415 - val_loss: 0.1455\n",
      "\n",
      "Epoch 45/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0414 - val_loss: 0.1435\n",
      "\n",
      "Epoch 46/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0389 - val_loss: 0.1421\n",
      "\n",
      "Epoch 47/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0439 - val_loss: 0.1410\n",
      "\n",
      "Epoch 48/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0413 - val_loss: 0.1403\n",
      "\n",
      "Epoch 49/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0424 - val_loss: 0.1399\n",
      "\n",
      "Epoch 50/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0408 - val_loss: 0.1399\n",
      "\n",
      "Epoch 51/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0421 - val_loss: 0.1401\n",
      "\n",
      "Epoch 52/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0446 - val_loss: 0.1406\n",
      "\n",
      "Epoch 53/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0418 - val_loss: 0.1413\n",
      "\n",
      "Epoch 54/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0418 - val_loss: 0.1422\n",
      "\n",
      "Epoch 55/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0409 - val_loss: 0.1434\n",
      "\n",
      "Epoch 56/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0441 - val_loss: 0.1446\n",
      "\n",
      "Epoch 57/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0406 - val_loss: 0.1460\n",
      "\n",
      "Epoch 58/1000\n",
      "38/38 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0371 - val_loss: 0.1477\n",
      "\n",
      "Epoch 59/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0381 - val_loss: 0.1498\n",
      "\n",
      "Epoch 60/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0399 - val_loss: 0.1521\n",
      "\n",
      "Epoch 61/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0405 - val_loss: 0.1544\n",
      "\n",
      "Epoch 62/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0381 - val_loss: 0.1567\n",
      "\n",
      "Epoch 63/1000\n",
      "38/38 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0381 - val_loss: 0.1591\n",
      "\n",
      "Epoch 64/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0387 - val_loss: 0.1613\n",
      "\n",
      "Epoch 65/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0349 - val_loss: 0.1636\n",
      "\n",
      "Epoch 66/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0349 - val_loss: 0.1658\n",
      "\n",
      "Epoch 67/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0379 - val_loss: 0.1679\n",
      "\n",
      "Epoch 68/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0381 - val_loss: 0.1700\n",
      "\n",
      "Epoch 69/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0400 - val_loss: 0.1720\n",
      "\n",
      "Epoch 70/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0356 - val_loss: 0.1738\n",
      "\n",
      "Epoch 71/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0361 - val_loss: 0.1755\n",
      "\n",
      "Epoch 72/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0393 - val_loss: 0.1771\n",
      "\n",
      "Epoch 73/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0361 - val_loss: 0.1786\n",
      "\n",
      "Epoch 74/1000\n",
      "38/38 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0397 - val_loss: 0.1799\n",
      "\n",
      "Epoch 75/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0353 - val_loss: 0.1812\n",
      "\n",
      "Epoch 76/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0369 - val_loss: 0.1824\n",
      "\n",
      "Epoch 77/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0377 - val_loss: 0.1835\n",
      "\n",
      "Epoch 78/1000\n",
      "38/38 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0401 - val_loss: 0.1844\n",
      "\n",
      "Epoch 79/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0360 - val_loss: 0.1852\n",
      "\n",
      "Epoch 80/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0380 - val_loss: 0.1859\n",
      "\n",
      "Epoch 81/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0367 - val_loss: 0.1865\n",
      "\n",
      "Epoch 82/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0377 - val_loss: 0.1870\n",
      "\n",
      "Epoch 83/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0367 - val_loss: 0.1872\n",
      "\n",
      "Epoch 84/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0400 - val_loss: 0.1875\n",
      "\n",
      "Epoch 85/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0354 - val_loss: 0.1876\n",
      "\n",
      "Epoch 86/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0365 - val_loss: 0.1876\n",
      "\n",
      "Epoch 87/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0401 - val_loss: 0.1874\n",
      "\n",
      "Epoch 88/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0340 - val_loss: 0.1872\n",
      "\n",
      "Epoch 89/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0389 - val_loss: 0.1868\n",
      "\n",
      "Epoch 90/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0371 - val_loss: 0.1864\n",
      "\n",
      "Epoch 91/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0409 - val_loss: 0.1859\n",
      "\n",
      "Epoch 92/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0387 - val_loss: 0.1853\n",
      "\n",
      "Epoch 93/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0393 - val_loss: 0.1846\n",
      "\n",
      "Epoch 94/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0403 - val_loss: 0.1838\n",
      "\n",
      "Epoch 95/1000\n",
      "38/38 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0368 - val_loss: 0.1831\n",
      "\n",
      "Epoch 96/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0406 - val_loss: 0.1823\n",
      "\n",
      "Epoch 97/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0396 - val_loss: 0.1814\n",
      "\n",
      "Epoch 98/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0367 - val_loss: 0.1805\n",
      "\n",
      "Epoch 99/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0410 - val_loss: 0.1795\n",
      "\n",
      "Epoch 100/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0387 - val_loss: 0.1784\n",
      "\n",
      "Epoch 101/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0390 - val_loss: 0.1773\n",
      "\n",
      "Epoch 102/1000\n",
      "38/38 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0354 - val_loss: 0.1762\n",
      "\n",
      "48/48 [==============================]\n",
      " - 0s 207us/step\n",
      "\n",
      "Window size 4 score = 0.06520500779151917\n",
      "Window size is 1\n",
      "Train on 40 samples, validate on 11 samples\n",
      "Epoch 1/1000\n",
      "40/40 [==============================]\n",
      " - 20s 490ms/step - loss: 0.2762 - val_loss: 0.1324\n",
      "\n",
      "Epoch 2/1000\n",
      "40/40 [==============================]\n",
      " - 0s 1ms/step - loss: 0.2714 - val_loss: 0.1292\n",
      "\n",
      "Epoch 3/1000\n",
      "40/40 [==============================]\n",
      " - 0s 1ms/step - loss: 0.2663 - val_loss: 0.1256\n",
      "\n",
      "Epoch 4/1000\n",
      "40/40 [==============================]\n",
      " - 0s 1ms/step - loss: 0.2607 - val_loss: 0.1217\n",
      "\n",
      "Epoch 5/1000\n",
      "40/40 [==============================]\n",
      " - 0s 1ms/step - loss: 0.2543 - val_loss: 0.1186\n",
      "\n",
      "Epoch 6/1000\n",
      "40/40 [==============================]\n",
      " - 0s 1ms/step - loss: 0.2474 - val_loss: 0.1151\n",
      "\n",
      "Epoch 7/1000\n",
      "40/40 [==============================]\n",
      " - 0s 1ms/step - loss: 0.2396 - val_loss: 0.1113\n",
      "\n",
      "Epoch 8/1000\n",
      "40/40 [==============================]\n",
      " - 0s 1ms/step - loss: 0.2309 - val_loss: 0.1071\n",
      "\n",
      "Epoch 9/1000\n",
      "40/40 [==============================]\n",
      " - 0s 1ms/step - loss: 0.2214 - val_loss: 0.1042\n",
      "\n",
      "Epoch 10/1000\n",
      "40/40 [==============================]\n",
      " - 0s 1ms/step - loss: 0.2114 - val_loss: 0.1015\n",
      "\n",
      "Epoch 11/1000\n",
      "40/40 [==============================]\n",
      " - 0s 1ms/step - loss: 0.1984 - val_loss: 0.0987\n",
      "\n",
      "Epoch 12/1000\n",
      "40/40 [==============================]\n",
      " - 0s 1ms/step - loss: 0.1878 - val_loss: 0.0986\n",
      "\n",
      "Epoch 13/1000\n",
      "40/40 [==============================]\n",
      " - 0s 1ms/step - loss: 0.1735 - val_loss: 0.0986\n",
      "\n",
      "Epoch 14/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1565 - val_loss: 0.1017\n",
      "\n",
      "Epoch 15/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1403 - val_loss: 0.1059\n",
      "\n",
      "Epoch 16/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.1226 - val_loss: 0.1143\n",
      "\n",
      "Epoch 17/1000\n",
      "40/40 [==============================]\n",
      " - 0s 1ms/step - loss: 0.1020 - val_loss: 0.1254\n",
      "\n",
      "Epoch 18/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0869 - val_loss: 0.1401\n",
      "\n",
      "Epoch 19/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0585 - val_loss: 0.1602\n",
      "\n",
      "Epoch 20/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0479 - val_loss: 0.1858\n",
      "\n",
      "Epoch 21/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0455 - val_loss: 0.2159\n",
      "\n",
      "Epoch 22/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0507 - val_loss: 0.2445\n",
      "\n",
      "Epoch 23/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0607 - val_loss: 0.2671\n",
      "\n",
      "Epoch 24/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0748 - val_loss: 0.2822\n",
      "\n",
      "Epoch 25/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0816 - val_loss: 0.2910\n",
      "\n",
      "Epoch 26/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0816 - val_loss: 0.2950\n",
      "\n",
      "Epoch 27/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0888 - val_loss: 0.2955\n",
      "\n",
      "Epoch 28/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0951 - val_loss: 0.2926\n",
      "\n",
      "Epoch 29/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0902 - val_loss: 0.2874\n",
      "\n",
      "Epoch 30/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0847 - val_loss: 0.2808\n",
      "\n",
      "Epoch 31/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0812 - val_loss: 0.2729\n",
      "\n",
      "Epoch 32/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0855 - val_loss: 0.2641\n",
      "\n",
      "Epoch 33/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0724 - val_loss: 0.2545\n",
      "\n",
      "Epoch 34/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0620 - val_loss: 0.2447\n",
      "\n",
      "Epoch 35/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0586 - val_loss: 0.2349\n",
      "\n",
      "Epoch 36/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0620 - val_loss: 0.2252\n",
      "\n",
      "Epoch 37/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0526 - val_loss: 0.2156\n",
      "\n",
      "Epoch 38/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0503 - val_loss: 0.2063\n",
      "\n",
      "Epoch 39/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0454 - val_loss: 0.1973\n",
      "\n",
      "Epoch 40/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0419 - val_loss: 0.1888\n",
      "\n",
      "Epoch 41/1000\n",
      "40/40 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0395 - val_loss: 0.1808\n",
      "\n",
      "Epoch 42/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0423 - val_loss: 0.1741\n",
      "\n",
      "Epoch 43/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0441 - val_loss: 0.1679\n",
      "\n",
      "Epoch 44/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0369 - val_loss: 0.1621\n",
      "\n",
      "Epoch 45/1000\n",
      "40/40 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0433 - val_loss: 0.1568\n",
      "\n",
      "Epoch 46/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0402 - val_loss: 0.1523\n",
      "\n",
      "Epoch 47/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0444 - val_loss: 0.1486\n",
      "\n",
      "Epoch 48/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0435 - val_loss: 0.1454\n",
      "\n",
      "Epoch 49/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0450 - val_loss: 0.1425\n",
      "\n",
      "Epoch 50/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0494 - val_loss: 0.1399\n",
      "\n",
      "Epoch 51/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0518 - val_loss: 0.1377\n",
      "\n",
      "Epoch 52/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0532 - val_loss: 0.1358\n",
      "\n",
      "Epoch 53/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0530 - val_loss: 0.1343\n",
      "\n",
      "Epoch 54/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0557 - val_loss: 0.1330\n",
      "\n",
      "Epoch 55/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0559 - val_loss: 0.1321\n",
      "\n",
      "Epoch 56/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0560 - val_loss: 0.1313\n",
      "\n",
      "Epoch 57/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0592 - val_loss: 0.1309\n",
      "\n",
      "Epoch 58/1000\n",
      "40/40 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0554 - val_loss: 0.1306\n",
      "\n",
      "Epoch 59/1000\n",
      "40/40 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0565 - val_loss: 0.1306\n",
      "\n",
      "Epoch 60/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0595 - val_loss: 0.1307\n",
      "\n",
      "Epoch 61/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0581 - val_loss: 0.1310\n",
      "\n",
      "Epoch 62/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0558 - val_loss: 0.1314\n",
      "\n",
      "Epoch 63/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0585 - val_loss: 0.1320\n",
      "\n",
      "Epoch 64/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0540 - val_loss: 0.1327\n",
      "\n",
      "Epoch 65/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0556 - val_loss: 0.1335\n",
      "\n",
      "Epoch 66/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0529 - val_loss: 0.1345\n",
      "\n",
      "Epoch 67/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0500 - val_loss: 0.1355\n",
      "\n",
      "Epoch 68/1000\n",
      "40/40 [==============================]\n",
      " - 0s 1ms/step - loss: 0.0514 - val_loss: 0.1366\n",
      "\n",
      "Epoch 69/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0454 - val_loss: 0.1378\n",
      "\n",
      "Epoch 70/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0451 - val_loss: 0.1391\n",
      "\n",
      "Epoch 71/1000\n",
      "40/40 [==============================]\n",
      " - 0s 1ms/step - loss: 0.0477 - val_loss: 0.1404\n",
      "\n",
      "Epoch 72/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0481 - val_loss: 0.1418\n",
      "\n",
      "Epoch 73/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0472 - val_loss: 0.1433\n",
      "\n",
      "Epoch 74/1000\n",
      "40/40 [==============================]\n",
      " - 0s 1ms/step - loss: 0.0470 - val_loss: 0.1448\n",
      "\n",
      "Epoch 75/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0451 - val_loss: 0.1464\n",
      "\n",
      "Epoch 76/1000\n",
      "40/40 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0465 - val_loss: 0.1480\n",
      "\n",
      "Epoch 77/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0442 - val_loss: 0.1497\n",
      "\n",
      "Epoch 78/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0463 - val_loss: 0.1518\n",
      "\n",
      "Epoch 79/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0409 - val_loss: 0.1538\n",
      "\n",
      "Epoch 80/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0410 - val_loss: 0.1559\n",
      "\n",
      "Epoch 81/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0397 - val_loss: 0.1579\n",
      "\n",
      "Epoch 82/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0379 - val_loss: 0.1600\n",
      "\n",
      "Epoch 83/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0335 - val_loss: 0.1621\n",
      "\n",
      "Epoch 84/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0410 - val_loss: 0.1641\n",
      "\n",
      "Epoch 85/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0365 - val_loss: 0.1661\n",
      "\n",
      "Epoch 86/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0408 - val_loss: 0.1681\n",
      "\n",
      "Epoch 87/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0409 - val_loss: 0.1701\n",
      "\n",
      "Epoch 88/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0460 - val_loss: 0.1720\n",
      "\n",
      "Epoch 89/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0452 - val_loss: 0.1741\n",
      "\n",
      "Epoch 90/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0404 - val_loss: 0.1762\n",
      "\n",
      "Epoch 91/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0408 - val_loss: 0.1782\n",
      "\n",
      "Epoch 92/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0403 - val_loss: 0.1802\n",
      "\n",
      "Epoch 93/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0466 - val_loss: 0.1820\n",
      "\n",
      "Epoch 94/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0408 - val_loss: 0.1838\n",
      "\n",
      "Epoch 95/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0446 - val_loss: 0.1855\n",
      "\n",
      "Epoch 96/1000\n",
      "40/40 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0472 - val_loss: 0.1871\n",
      "\n",
      "Epoch 97/1000\n",
      "40/40 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0462 - val_loss: 0.1885\n",
      "\n",
      "Epoch 98/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0433 - val_loss: 0.1899\n",
      "\n",
      "Epoch 99/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0436 - val_loss: 0.1912\n",
      "\n",
      "Epoch 100/1000\n",
      "40/40 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0431 - val_loss: 0.1923\n",
      "\n",
      "Epoch 101/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0513 - val_loss: 0.1934\n",
      "\n",
      "Epoch 102/1000\n",
      "40/40 [==============================]\n",
      " - 0s 1ms/step - loss: 0.0421 - val_loss: 0.1944\n",
      "\n",
      "Epoch 103/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0510 - val_loss: 0.1953\n",
      "\n",
      "Epoch 104/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0413 - val_loss: 0.1960\n",
      "\n",
      "Epoch 105/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0467 - val_loss: 0.1968\n",
      "\n",
      "Epoch 106/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0412 - val_loss: 0.1974\n",
      "\n",
      "Epoch 107/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0412 - val_loss: 0.1979\n",
      "\n",
      "Epoch 108/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0500 - val_loss: 0.1983\n",
      "\n",
      "Epoch 109/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0472 - val_loss: 0.1987\n",
      "\n",
      "Epoch 110/1000\n",
      "40/40 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0479 - val_loss: 0.1990\n",
      "\n",
      "Epoch 111/1000\n",
      "40/40 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0421 - val_loss: 0.1992\n",
      "\n",
      "Epoch 112/1000\n",
      "40/40 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0482 - val_loss: 0.1993\n",
      "\n",
      "51/51 [==============================]\n",
      " - 0s 182us/step\n",
      "\n",
      "Window size 1 score = 0.07885855436325073\n",
      "Window size is 6\n",
      "Train on 36 samples, validate on 10 samples\n",
      "Epoch 1/1000\n",
      "36/36 [==============================]\n",
      " - 29s 818ms/step - loss: 0.3454 - val_loss: 0.2180\n",
      "\n",
      "Epoch 2/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.3216 - val_loss: 0.1711\n",
      "\n",
      "Epoch 3/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.2742 - val_loss: 0.1023\n",
      "\n",
      "Epoch 4/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1754 - val_loss: 0.1177\n",
      "\n",
      "Epoch 5/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0533 - val_loss: 0.2262\n",
      "\n",
      "Epoch 6/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.1274 - val_loss: 0.1457\n",
      "\n",
      "Epoch 7/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0625 - val_loss: 0.0912\n",
      "\n",
      "Epoch 8/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0530 - val_loss: 0.0827\n",
      "\n",
      "Epoch 9/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0774 - val_loss: 0.0818\n",
      "\n",
      "Epoch 10/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0887 - val_loss: 0.0826\n",
      "\n",
      "Epoch 11/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0637 - val_loss: 0.0895\n",
      "\n",
      "Epoch 12/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0488 - val_loss: 0.1065\n",
      "\n",
      "Epoch 13/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0443 - val_loss: 0.1312\n",
      "\n",
      "Epoch 14/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0558 - val_loss: 0.1547\n",
      "\n",
      "Epoch 15/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0673 - val_loss: 0.1680\n",
      "\n",
      "Epoch 16/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0729 - val_loss: 0.1672\n",
      "\n",
      "Epoch 17/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0762 - val_loss: 0.1547\n",
      "\n",
      "Epoch 18/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0667 - val_loss: 0.1370\n",
      "\n",
      "Epoch 19/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0661 - val_loss: 0.1195\n",
      "\n",
      "Epoch 20/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0480 - val_loss: 0.1060\n",
      "\n",
      "Epoch 21/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0418 - val_loss: 0.0957\n",
      "\n",
      "Epoch 22/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0410 - val_loss: 0.0896\n",
      "\n",
      "Epoch 23/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0414 - val_loss: 0.0853\n",
      "\n",
      "Epoch 24/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0493 - val_loss: 0.0833\n",
      "\n",
      "Epoch 25/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0547 - val_loss: 0.0827\n",
      "\n",
      "Epoch 26/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0537 - val_loss: 0.0826\n",
      "\n",
      "Epoch 27/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0525 - val_loss: 0.0830\n",
      "\n",
      "Epoch 28/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0527 - val_loss: 0.0844\n",
      "\n",
      "Epoch 29/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0484 - val_loss: 0.0871\n",
      "\n",
      "Epoch 30/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0535 - val_loss: 0.0904\n",
      "\n",
      "Epoch 31/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0422 - val_loss: 0.0938\n",
      "\n",
      "Epoch 32/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0413 - val_loss: 0.0989\n",
      "\n",
      "Epoch 33/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0361 - val_loss: 0.1042\n",
      "\n",
      "Epoch 34/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0342 - val_loss: 0.1098\n",
      "\n",
      "Epoch 35/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0431 - val_loss: 0.1156\n",
      "\n",
      "Epoch 36/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0373 - val_loss: 0.1206\n",
      "\n",
      "Epoch 37/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0478 - val_loss: 0.1251\n",
      "\n",
      "Epoch 38/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0432 - val_loss: 0.1288\n",
      "\n",
      "Epoch 39/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0493 - val_loss: 0.1310\n",
      "\n",
      "Epoch 40/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0455 - val_loss: 0.1320\n",
      "\n",
      "Epoch 41/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0462 - val_loss: 0.1322\n",
      "\n",
      "Epoch 42/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0465 - val_loss: 0.1313\n",
      "\n",
      "Epoch 43/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0436 - val_loss: 0.1297\n",
      "\n",
      "Epoch 44/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0415 - val_loss: 0.1270\n",
      "\n",
      "Epoch 45/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0456 - val_loss: 0.1237\n",
      "\n",
      "Epoch 46/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0392 - val_loss: 0.1201\n",
      "\n",
      "Epoch 47/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0413 - val_loss: 0.1166\n",
      "\n",
      "Epoch 48/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0393 - val_loss: 0.1128\n",
      "\n",
      "Epoch 49/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0355 - val_loss: 0.1089\n",
      "\n",
      "Epoch 50/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0434 - val_loss: 0.1050\n",
      "\n",
      "Epoch 51/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0404 - val_loss: 0.1019\n",
      "\n",
      "Epoch 52/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0350 - val_loss: 0.0988\n",
      "\n",
      "Epoch 53/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0353 - val_loss: 0.0960\n",
      "\n",
      "Epoch 54/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0325 - val_loss: 0.0932\n",
      "\n",
      "Epoch 55/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0392 - val_loss: 0.0910\n",
      "\n",
      "Epoch 56/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0360 - val_loss: 0.0896\n",
      "\n",
      "Epoch 57/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0402 - val_loss: 0.0885\n",
      "\n",
      "Epoch 58/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0418 - val_loss: 0.0876\n",
      "\n",
      "Epoch 59/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0390 - val_loss: 0.0870\n",
      "\n",
      "Epoch 60/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0398 - val_loss: 0.0865\n",
      "\n",
      "Epoch 61/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0456 - val_loss: 0.0861\n",
      "\n",
      "Epoch 62/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0423 - val_loss: 0.0858\n",
      "\n",
      "Epoch 63/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0446 - val_loss: 0.0857\n",
      "\n",
      "Epoch 64/1000\n",
      "36/36 [==============================]\n",
      " - 0s 5ms/step - loss: 0.0366 - val_loss: 0.0858\n",
      "\n",
      "Epoch 65/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0490 - val_loss: 0.0859\n",
      "\n",
      "Epoch 66/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0443 - val_loss: 0.0863\n",
      "\n",
      "Epoch 67/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0397 - val_loss: 0.0868\n",
      "\n",
      "Epoch 68/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0416 - val_loss: 0.0875\n",
      "\n",
      "Epoch 69/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0431 - val_loss: 0.0882\n",
      "\n",
      "Epoch 70/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0423 - val_loss: 0.0892\n",
      "\n",
      "Epoch 71/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0396 - val_loss: 0.0902\n",
      "\n",
      "Epoch 72/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0421 - val_loss: 0.0916\n",
      "\n",
      "Epoch 73/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0370 - val_loss: 0.0933\n",
      "\n",
      "Epoch 74/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0416 - val_loss: 0.0951\n",
      "\n",
      "Epoch 75/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0374 - val_loss: 0.0969\n",
      "\n",
      "Epoch 76/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0319 - val_loss: 0.0986\n",
      "\n",
      "Epoch 77/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0343 - val_loss: 0.1002\n",
      "\n",
      "Epoch 78/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0339 - val_loss: 0.1019\n",
      "\n",
      "Epoch 79/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0394 - val_loss: 0.1035\n",
      "\n",
      "Epoch 80/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0375 - val_loss: 0.1056\n",
      "\n",
      "Epoch 81/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0360 - val_loss: 0.1075\n",
      "\n",
      "Epoch 82/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0489 - val_loss: 0.1093\n",
      "\n",
      "Epoch 83/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0404 - val_loss: 0.1108\n",
      "\n",
      "Epoch 84/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0395 - val_loss: 0.1122\n",
      "\n",
      "Epoch 85/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0388 - val_loss: 0.1133\n",
      "\n",
      "Epoch 86/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0483 - val_loss: 0.1144\n",
      "\n",
      "Epoch 87/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0417 - val_loss: 0.1152\n",
      "\n",
      "Epoch 88/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0413 - val_loss: 0.1159\n",
      "\n",
      "Epoch 89/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0376 - val_loss: 0.1164\n",
      "\n",
      "Epoch 90/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0407 - val_loss: 0.1167\n",
      "\n",
      "Epoch 91/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0370 - val_loss: 0.1169\n",
      "\n",
      "Epoch 92/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0455 - val_loss: 0.1169\n",
      "\n",
      "Epoch 93/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0359 - val_loss: 0.1169\n",
      "\n",
      "Epoch 94/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0383 - val_loss: 0.1166\n",
      "\n",
      "Epoch 95/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0440 - val_loss: 0.1162\n",
      "\n",
      "Epoch 96/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0421 - val_loss: 0.1157\n",
      "\n",
      "Epoch 97/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0450 - val_loss: 0.1151\n",
      "\n",
      "Epoch 98/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0407 - val_loss: 0.1144\n",
      "\n",
      "Epoch 99/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0370 - val_loss: 0.1135\n",
      "\n",
      "Epoch 100/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0417 - val_loss: 0.1126\n",
      "\n",
      "Epoch 101/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0366 - val_loss: 0.1117\n",
      "\n",
      "Epoch 102/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0376 - val_loss: 0.1107\n",
      "\n",
      "Epoch 103/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0389 - val_loss: 0.1096\n",
      "\n",
      "Epoch 104/1000\n",
      "36/36 [==============================]\n",
      " - 0s 2ms/step - loss: 0.0380 - val_loss: 0.1085\n",
      "\n",
      "Epoch 105/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0360 - val_loss: 0.1074\n",
      "\n",
      "Epoch 106/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0373 - val_loss: 0.1063\n",
      "\n",
      "Epoch 107/1000\n",
      "36/36 [==============================]\n",
      " - 0s 3ms/step - loss: 0.0368 - val_loss: 0.1051\n",
      "\n",
      "Epoch 108/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0351 - val_loss: 0.1039\n",
      "\n",
      "Epoch 109/1000\n",
      "36/36 [==============================]\n",
      " - 0s 4ms/step - loss: 0.0343 - val_loss: 0.1027\n",
      "\n",
      "46/46 [==============================]\n",
      " - 0s 442us/step\n",
      "\n",
      "Window size 6 score = 0.049731772392988205\n",
      "Window size is 4\n",
      " 11%|█         | 11/100 [10:33<1:42:07, 68.85s/it, best loss: 0.049731772392988205]"
     ],
     "name": "stdout"
    }
   ]
  }
 ]
}