{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"working.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1llsccnklCzs7EZSELP6MVysncixaZnQR\n",
    "\n",
    "## Notebook settings\n",
    "\"\"\"\n",
    "# region Import\n",
    "# Data download\n",
    "# Import basic\n",
    "import csv\n",
    "import math\n",
    "import os\n",
    "import warnings\n",
    "# Init google drive\n",
    "# from google.colab import drive\n",
    "from datetime import datetime\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Plottool\n",
    "import plotly.graph_objs as go\n",
    "# IPython\n",
    "from IPython.display import display\n",
    "# Hyperopt bayesian optimization\n",
    "from hyperopt import hp, Trials, tpe, fmin, STATUS_OK, partial\n",
    "# Keras\n",
    "from keras import Sequential\n",
    "from keras.activations import softmax\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.initializers import Ones\n",
    "from keras.layers import LSTM, Dropout, Input\n",
    "from keras.models import Model\n",
    "# SKLearn\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# region File mount and config\n",
    "# drive.mount('/content/gdrive', force_remount=True)\n",
    "root_dir = \"\"\n",
    "\n",
    "data_dir = root_dir + 'data'\n",
    "model_dir = root_dir + 'model'\n",
    "plot_dir = root_dir + 'plot'\n",
    "result_dir = root_dir + 'result'\n",
    "# Create folder if not exists\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    \n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)\n",
    "    \n",
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir)\n",
    "    \n",
    "pd.options.display.max_columns = 12\n",
    "pd.options.display.max_rows = 24\n",
    "\n",
    "# disable warnings in Anaconda\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "current_timestamp = datetime.now().strftime('%d%m%Y-%H%M%S')\n",
    "# endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# region Data Loading\n",
    "stock_name = '000001.SS'  # SSE Composite Index\n",
    "# df_org = yf.download(stock_name, start=\"1991-01-01\", end=\"2016-12-31\", interval=\"1wk\")\n",
    "df_org = pd.read_csv(f'{data_dir}/{stock_name}.csv', parse_dates=['Date'])\n",
    "df_org = df_org.sort_values('Date')\n",
    "# df_org.to_csv(f'{base_dir}/{stock_name}.csv')\n",
    "df_org.reset_index(inplace=True)\n",
    "df_org = df_org[['Date', 'Close', 'Open', 'High', 'Low', 'Adj Close', 'Volume']]\n",
    "\n",
    "# endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# region Data ploting\n",
    "def plot_ohlc(df):\n",
    "    trace = go.Ohlc(x=df['Date'],\n",
    "                    open=df['Open'],\n",
    "                    high=df['High'],\n",
    "                    low=df['Low'],\n",
    "                    close=df['Close'],\n",
    "                    increasing=dict(line=dict(color='#58FA58')),\n",
    "                    decreasing=dict(line=dict(color='#FA5858')))\n",
    "\n",
    "    layout = {\n",
    "        'title': f'{stock_name} Historical Price',\n",
    "        'xaxis': {'title': 'Date',\n",
    "                  'rangeslider': {'visible': False}},\n",
    "        'yaxis': {'title': f'Price'}\n",
    "    }\n",
    "\n",
    "    data = [trace]\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    fig.write_html(os.path.join(plot_dir, '%s_ohlc.html' % (stock_name)), auto_open=False)\n",
    "\n",
    "\n",
    "plot_ohlc(df_org)\n",
    "# endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# region Create csv result file\n",
    "# File to save first results\n",
    "result_save_fname = os.path.join(result_dir, 'result_%s-%s.csv' % (stock_name, current_timestamp))\n",
    "of_connection = open(result_save_fname, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "# Write the headers to the file\n",
    "writer.writerow(['stock_name', 'year', 'loss', 'params', 'iteration', 'windows_size', 'train_time'])\n",
    "of_connection.close()\n",
    "\n",
    "# Create file to save bayer best\n",
    "bayer_save_fname = os.path.join(result_dir, 'bayer_best_%s-%s.csv' % (stock_name, current_timestamp))\n",
    "of_connection = open(bayer_save_fname, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "# Write the headers to the file\n",
    "writer.writerow(['stock_name', 'year', 'params'])\n",
    "of_connection.close()\n",
    "# endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# region Sample data\n",
    "\n",
    "df_org.sample(10)\n",
    "\n",
    "# endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# region Const\n",
    "# Declare const\n",
    "input_col = ['Close', 'Open', 'High', 'Low', 'Adj Close', 'Volume']\n",
    "output_col = ['Close']\n",
    "time_col = ['Date']\n",
    "\n",
    "# Input dimension\n",
    "input_dim = len(input_col)\n",
    "# Output dimension\n",
    "output_dim = len(output_col)\n",
    "\n",
    "# Number of session to prediction as one time\n",
    "prediction_size = 1\n",
    "# For each time model is train, the first is display\n",
    "sample_display_test_size = 5\n",
    "# Max bayer iteration\n",
    "bayer_max_evals = 1\n",
    "\n",
    "\n",
    "# endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# region Declare model\n",
    "# declare model\n",
    "def softMaxAxis1(x):\n",
    "    return softmax(x, axis=1)\n",
    "\n",
    "\n",
    "def get_model(input_dim, window_size, output_dim, lstm_layer_count=5, drop_rate=0.2):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=100, input_shape=(window_size, input_dim), return_sequences=True, kernel_initializer=Ones()))\n",
    "    model.add(Dropout(rate=0.2))\n",
    "\n",
    "    for i in range(lstm_layer_count - 2):\n",
    "        model.add(LSTM(units=100, return_sequences=True))\n",
    "        model.add(Dropout(rate=drop_rate))\n",
    "    \n",
    "    model.add(LSTM(output_dim, activation=softMaxAxis1))\n",
    "    # TODO: custom loss function\n",
    "    model.compile(loss='mae', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# region Error metric\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "\n",
    "def root_mean_square_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "\n",
    "    return np.mean((y_true - y_pred) / y_true)\n",
    "\n",
    "\n",
    "def relative_root_mean_square_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    res = (y_true - y_pred) / y_true\n",
    "    res = np.power(res, 2)\n",
    "    res = np.mean(res)\n",
    "    res = math.sqrt(res)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "# endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# region Data preprocessing\n",
    "# reprocessing data\n",
    "def next_window(df, i, windows_size, prediction_size, input_col, output_col, time_col):\n",
    "    '''Generates the next data window from the given index location i'''\n",
    "    window = df[i: i + windows_size + prediction_size]\n",
    "    x = window[input_col][:-prediction_size]\n",
    "    y = window[output_col][-prediction_size:]\n",
    "    y_time = window[time_col][-prediction_size:]\n",
    "    return x, y, y_time\n",
    "\n",
    "def smooting_data(df, window_size):\n",
    "    return df.ewm(span=window_size).mean()\n",
    "\n",
    "def preprocessing_data(df, windows_size, prediction_size, input_col, output_col, time_col):\n",
    "    '''\n",
    "    Create x, y train data windows\n",
    "    Warning: batch method, not generative, make sure you have enough memory to\n",
    "    load data, otherwise use generate_training_window() method.\n",
    "    '''\n",
    "\n",
    "\n",
    "    data_x = []\n",
    "    data_y = []\n",
    "    data_y_time = []\n",
    "    for i in range(len(df) - windows_size - prediction_size):\n",
    "        x, y, y_time = next_window(df, i, windows_size, prediction_size, input_col, output_col, time_col)\n",
    "        data_x.append(x.values)\n",
    "        data_y.append(y.values)\n",
    "        data_y_time.append(y_time)\n",
    "\n",
    "    time = pd.concat(data_y_time)\n",
    "\n",
    "    return np.array(data_x), np.array(data_y), time.values\n",
    "\n",
    "\n",
    "def split_train_test_data(X, y):\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "    return X_train, y_train, X_valid, y_valid\n",
    "\n",
    "\n",
    "# endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# region Model train\n",
    "# Trainning model\n",
    "def train_model(model, X_train, y_train, X_valid, y_valid, stock_name, year, window_size):\n",
    "    model_save_fname = os.path.join(save_dir, '%s-%s-w%d-%s.h5' % (stock_name, year, window_size, current_timestamp))\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=100),\n",
    "        ModelCheckpoint(filepath=model_save_fname, monitor='val_loss', save_best_only=True)\n",
    "    ]\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=1000,\n",
    "        batch_size=10000,\n",
    "        validation_data=(X_valid, y_valid),\n",
    "        verbose=1,\n",
    "        callbacks=callbacks,\n",
    "        shuffle=False)\n",
    "    model.save(model_save_fname)\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "# endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# region Test model\n",
    "def test_model(model, test_data, window_size, prediction_size, input_col, output_col, time_col):\n",
    "    X, y, time = preprocessing_data(test_data, window_size, prediction_size, input_col, output_col, time_col)\n",
    "    \n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    y_pred = np.repeat(y_pred, input_dim, axis=1)\n",
    "    y_pred = scaler.inverse_transform(y_pred)[:, [0]]\n",
    "    y_pred = pd.Series(y_pred.flatten())\n",
    "\n",
    "    df_test_result = pd.DataFrame(time, columns=['Date'])\n",
    "    df_test_result['Prediction'] = y_pred\n",
    "    df_test_result.set_index('Date', inplace=True)\n",
    "\n",
    "    return df_test_result\n",
    "\n",
    "\n",
    "def plot_test_result(test_result, stock_name, year, window_size):\n",
    "    # Plotly\n",
    "    trace0 = go.Scatter(\n",
    "        x=test_result.index,\n",
    "        y=test_result['Close'],\n",
    "        name='Thực tế',\n",
    "        line=dict(\n",
    "            color=('#5042f4'),\n",
    "            width=2)\n",
    "    )\n",
    "\n",
    "    trace1 = go.Scatter(\n",
    "        x=test_result.index,\n",
    "        y=test_result['Prediction'],\n",
    "        name='Dự đoán',\n",
    "        line=dict(\n",
    "            color=('#005b4e'),\n",
    "            width=2,\n",
    "            dash='dot'\n",
    "        )  # dash options include 'dash', 'dot', and 'dashdot'\n",
    "    )\n",
    "\n",
    "    data = [trace0, trace1]\n",
    "\n",
    "    # Edit the layout\n",
    "    layout = dict(title='Biểu đồ dự đoán',\n",
    "                  xaxis=dict(title='Date'),\n",
    "                  yaxis=dict(title='Price'),\n",
    "                  paper_bgcolor='#FFF9F5',\n",
    "                  plot_bgcolor='#FFF9F5'\n",
    "                  )\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    fig.write_html(os.path.join(plot_dir, '%s_%s_w%d_%s.html' % (stock_name, year, window_size, current_timestamp)), auto_open=False)\n",
    "\n",
    "# endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# region Bayers\n",
    "def objective(params, df):\n",
    "    # Keep track of evals\n",
    "    global ITERATION\n",
    "\n",
    "    ITERATION += 1\n",
    "\n",
    "    # Make sure windows_size is int\n",
    "    windows_size = int(params['windows_size'])\n",
    "    print(f'Window size is {windows_size}')\n",
    "\n",
    "    model = get_model(input_dim, windows_size, output_dim)\n",
    "\n",
    "    start = timer()\n",
    "\n",
    "    # Handle data\n",
    "    df.describe()\n",
    "    # TODO: smoothing ddata\n",
    "    df[input_col] = smooting_data(df[input_col], windows_size)\n",
    "\n",
    "    X, y, time = preprocessing_data(df, windows_size, prediction_size, input_col, output_col, time_col)\n",
    "\n",
    "    # Reshape data\n",
    "    y = y.reshape((y.shape[0], y.shape[1]))\n",
    "\n",
    "    X_train, y_train, X_valid, y_valid = split_train_test_data(X, y)\n",
    "\n",
    "    # Perform n_train\n",
    "    history = train_model(model, X_train, y_train, X_valid, y_valid, stock_name, year, windows_size)\n",
    "\n",
    "    run_time = timer() - start\n",
    "\n",
    "    # Test generated loss\n",
    "    test_result = test_model(model, df, windows_size, prediction_size, input_col, output_col, time_col)\n",
    "    test_result = test_result.join(df_org.set_index('Date'), stock_name, year, windows_size)\n",
    "\n",
    "    mae = mean_absolute_error(test_result['Close'], test_result['Prediction'])\n",
    "    mse = mean_squared_error(test_result['Close'], test_result['Prediction'])\n",
    "    mape = mean_absolute_percentage_error(test_result['Close'], test_result['Prediction'])\n",
    "    rrmse = relative_root_mean_square_erro  r(test_result['Close'], test_result['Prediction'])\n",
    "\n",
    "    #print(f'{stock_name} prediction for {prediction_size} day ahead')\n",
    "    #print(f'MAE = {mae}')\n",
    "    #print(f'MSE = {mse}')\n",
    "    #print(f'MAPE = {mape}')\n",
    "    #print(f'RRMSE = {rrmse}')\n",
    "\n",
    "    plot_test_result(test_result)\n",
    "    #display(test_result.sample(10))\n",
    "    loss = mae\n",
    "\n",
    "    # write row\n",
    "    of_connection = open(result_save_fname, 'a')\n",
    "    writer = csv.writer(of_connection)\n",
    "    writer.writerow([stock_name, year, loss, params, ITERATION, windows_size, run_time])\n",
    "    of_connection.close()\n",
    "\n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': loss, 'params': params, 'iteration': ITERATION, 'test_result': test_result,\n",
    "            'train_time': run_time, 'status': STATUS_OK}\n",
    "\n",
    "start_year = df_org['Date'].values[:1][0]\n",
    "start_year = pd.to_datetime(start_year).year\n",
    "\n",
    "end_year = df_org['Date'].values[-1:][0]\n",
    "end_year = pd.to_datetime(end_year).year\n",
    "\n",
    "windows_size_best = []\n",
    "# Global variable\n",
    "global ITERATION\n",
    "\n",
    "for year in range(start_year, end_year + 1):\n",
    "    df = df_org[df_org['Date'].dt.year == year]\n",
    "\n",
    "    # Data too small, skip\n",
    "    if df.shape[0] < 10:\n",
    "        continue\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_cols = scaler.fit_transform(df[input_col])\n",
    "    df[input_col] = scaled_cols\n",
    "\n",
    "    # Hyperparameter grid\n",
    "    param_grid = {\n",
    "        'windows_size': hp.choice('windows_size', np.arange(1, 8, dtype=int))\n",
    "    }\n",
    "\n",
    "    bayes_trials = Trials()\n",
    "\n",
    "    # Create the algorithm\n",
    "    bayes_algo = tpe.suggest\n",
    "\n",
    "    ITERATION = 0\n",
    "\n",
    "    fmin_objective = partial(objective, df=df)\n",
    "    bayes_best = fmin(fn=fmin_objective, space=param_grid,\n",
    "                      algo=bayes_algo, trials=bayes_trials,\n",
    "                      max_evals=1)\n",
    "\n",
    "    of_connection = open(bayer_save_fname, 'a')\n",
    "    writer = csv.writer(of_connection)\n",
    "    writer.writerow([stock_name, year, bayes_best])\n",
    "    of_connection.close()\n",
    "\n",
    "    windows_size_best.append([year, bayes_best])\n",
    "# endregion\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}