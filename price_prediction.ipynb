{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"working.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1llsccnklCzs7EZSELP6MVysncixaZnQR\n",
    "\n",
    "## Notebook settings\n",
    "\"\"\"\n",
    "# region Import\n",
    "# Data download\n",
    "# Import basic\n",
    "import csv\n",
    "import math\n",
    "import os\n",
    "import warnings\n",
    "# Init google drive\n",
    "# from google.colab import drive\n",
    "from datetime import datetime\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Plottool\n",
    "import plotly.graph_objs as go\n",
    "# IPython\n",
    "from IPython.display import display\n",
    "# Hyperopt bayesian optimization\n",
    "from hyperopt import hp, Trials, tpe, fmin, STATUS_OK, partial\n",
    "# Keras\n",
    "from keras import Sequential\n",
    "from keras.activations import softmax\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint  \n",
    "from keras.initializers import Ones\n",
    "from keras.layers import LSTM, Dropout, Input\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "# SKLearn\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "current_timestamp = datetime.now().strftime('%d%m%Y_%H%M%S')\n",
    "\n",
    "# region File mount and config\n",
    "# drive.mount('/content/gdrive', force_remount=True)\n",
    "root_dir = \"\"\n",
    "\n",
    "time_dir = os.path.join(root_dir, \"result\")\n",
    "time_dir = os.path.join(time_dir, current_timestamp)\n",
    "\n",
    "data_dir = root_dir + 'data'\n",
    "model_dir = os.path.join(time_dir, 'model')\n",
    "plot_dir = os.path.join(time_dir, 'plot')\n",
    "result_dir = os.path.join(time_dir, 'result')\n",
    "# Create folder if not exists\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    \n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)\n",
    "    \n",
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir)\n",
    "    \n",
    "pd.options.display.max_columns = 12\n",
    "pd.options.display.max_rows = 24\n",
    "\n",
    "# disable warnings in Anaconda\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# region Data Loading\n",
    "stock_name = '000001.SS'  # SSE Composite Index\n",
    "# df_org = yf.download(stock_name, start=\"1991-01-01\", end=\"2016-12-31\", interval=\"1wk\")\n",
    "df_org = pd.read_csv(f'{data_dir}/{stock_name}.csv', parse_dates=['Date'])\n",
    "df_org = df_org.sort_values('Date')\n",
    "# df_org.to_csv(f'{base_dir}/{stock_name}.csv')\n",
    "df_org.reset_index(inplace=True)\n",
    "df_org = df_org[['Date', 'Close', 'Open', 'High', 'Low', 'Adj Close', 'Volume']]\n",
    "\n",
    "# endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# region Data ploting\n",
    "def plot_ohlc(df):\n",
    "    trace = go.Ohlc(x=df['Date'],\n",
    "                    open=df['Open'],\n",
    "                    high=df['High'],\n",
    "                    low=df['Low'],\n",
    "                    close=df['Close'],\n",
    "                    increasing=dict(line=dict(color='#58FA58')),\n",
    "                    decreasing=dict(line=dict(color='#FA5858')))\n",
    "\n",
    "    layout = {\n",
    "        'title': f'{stock_name} Historical Price',\n",
    "        'xaxis': {'title': 'Date',\n",
    "                  'rangeslider': {'visible': False}},\n",
    "        'yaxis': {'title': f'Price'}\n",
    "    }\n",
    "\n",
    "    data = [trace]\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    fig.write_html(os.path.join(plot_dir, '%s_ohlc.html' % (stock_name)), auto_open=False)\n",
    "\n",
    "\n",
    "plot_ohlc(df_org)\n",
    "# endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# region Create csv result file\n",
    "# File to save first results\n",
    "result_save_fname = os.path.join(result_dir, 'result_%s-%s.csv' % (stock_name, current_timestamp))\n",
    "of_connection = open(result_save_fname, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "# Write the headers to the file\n",
    "writer.writerow(['stock_name', 'year', 'loss', 'params', 'iteration', 'windows_size', 'train_time'])\n",
    "of_connection.close()\n",
    "\n",
    "# Create file to save bayer best\n",
    "bayer_save_fname = os.path.join(result_dir, 'bayer_best_%s-%s.csv' % (stock_name, current_timestamp))\n",
    "of_connection = open(bayer_save_fname, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "# Write the headers to the file\n",
    "writer.writerow(['stock_name', 'year', 'params', 'model_save_location'])\n",
    "of_connection.close()\n",
    "# endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1995-01-09</td>\n",
       "      <td>597.840027</td>\n",
       "      <td>626.000000</td>\n",
       "      <td>626.000000</td>\n",
       "      <td>597.840027</td>\n",
       "      <td>597.840027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1283</td>\n",
       "      <td>2015-09-07</td>\n",
       "      <td>3200.233887</td>\n",
       "      <td>3149.379883</td>\n",
       "      <td>3256.742920</td>\n",
       "      <td>3011.116943</td>\n",
       "      <td>3200.233887</td>\n",
       "      <td>1425100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1187</td>\n",
       "      <td>2013-11-04</td>\n",
       "      <td>2106.126953</td>\n",
       "      <td>2156.086914</td>\n",
       "      <td>2166.170898</td>\n",
       "      <td>2103.510010</td>\n",
       "      <td>2106.126953</td>\n",
       "      <td>433400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>596</td>\n",
       "      <td>2002-06-03</td>\n",
       "      <td>1529.506958</td>\n",
       "      <td>1510.246948</td>\n",
       "      <td>1540.824951</td>\n",
       "      <td>1455.305054</td>\n",
       "      <td>1529.506958</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>753</td>\n",
       "      <td>2005-06-06</td>\n",
       "      <td>1108.286011</td>\n",
       "      <td>1010.380981</td>\n",
       "      <td>1146.416992</td>\n",
       "      <td>998.228027</td>\n",
       "      <td>1108.286011</td>\n",
       "      <td>136000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>277</td>\n",
       "      <td>1996-04-22</td>\n",
       "      <td>707.609985</td>\n",
       "      <td>613.969971</td>\n",
       "      <td>707.609985</td>\n",
       "      <td>613.969971</td>\n",
       "      <td>707.609985</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>1994-08-15</td>\n",
       "      <td>713.849976</td>\n",
       "      <td>665.880005</td>\n",
       "      <td>748.559998</td>\n",
       "      <td>665.880005</td>\n",
       "      <td>713.849976</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1309</td>\n",
       "      <td>2016-03-14</td>\n",
       "      <td>2955.149902</td>\n",
       "      <td>2830.083984</td>\n",
       "      <td>2971.551025</td>\n",
       "      <td>2819.794922</td>\n",
       "      <td>2955.149902</td>\n",
       "      <td>1058300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>1996-09-16</td>\n",
       "      <td>805.539978</td>\n",
       "      <td>778.289978</td>\n",
       "      <td>805.539978</td>\n",
       "      <td>760.760010</td>\n",
       "      <td>805.539978</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>867</td>\n",
       "      <td>2007-08-20</td>\n",
       "      <td>5107.667969</td>\n",
       "      <td>4773.832031</td>\n",
       "      <td>5125.358887</td>\n",
       "      <td>4758.396973</td>\n",
       "      <td>5107.667969</td>\n",
       "      <td>520000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date        Close         Open         High          Low  \\\n",
       "210  1995-01-09   597.840027   626.000000   626.000000   597.840027   \n",
       "1283 2015-09-07  3200.233887  3149.379883  3256.742920  3011.116943   \n",
       "1187 2013-11-04  2106.126953  2156.086914  2166.170898  2103.510010   \n",
       "596  2002-06-03  1529.506958  1510.246948  1540.824951  1455.305054   \n",
       "753  2005-06-06  1108.286011  1010.380981  1146.416992   998.228027   \n",
       "277  1996-04-22   707.609985   613.969971   707.609985   613.969971   \n",
       "189  1994-08-15   713.849976   665.880005   748.559998   665.880005   \n",
       "1309 2016-03-14  2955.149902  2830.083984  2971.551025  2819.794922   \n",
       "298  1996-09-16   805.539978   778.289978   805.539978   760.760010   \n",
       "867  2007-08-20  5107.667969  4773.832031  5125.358887  4758.396973   \n",
       "\n",
       "        Adj Close   Volume  \n",
       "210    597.840027        0  \n",
       "1283  3200.233887  1425100  \n",
       "1187  2106.126953   433400  \n",
       "596   1529.506958        0  \n",
       "753   1108.286011   136000  \n",
       "277    707.609985        0  \n",
       "189    713.849976        0  \n",
       "1309  2955.149902  1058300  \n",
       "298    805.539978        0  \n",
       "867   5107.667969   520000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# region Sample data\n",
    "\n",
    "df_org.sample(10)\n",
    "\n",
    "# endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# region Const\n",
    "# Declare const\n",
    "input_col = ['Close', 'Open', 'High', 'Low', 'Adj Close', 'Volume']\n",
    "output_col = ['Close']\n",
    "time_col = ['Date']\n",
    "\n",
    "# Input dimension\n",
    "input_dim = len(input_col)\n",
    "# Output dimension\n",
    "output_dim = len(output_col)\n",
    "\n",
    "# Number of session to prediction as one time\n",
    "prediction_size = 1\n",
    "# For each time model is train, the first is display\n",
    "sample_display_test_size = 5\n",
    "# Max bayer iteration\n",
    "bayer_max_evals = 100\n",
    "\n",
    "\n",
    "# endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# region Declare model\n",
    "# declare model\n",
    "def softMaxAxis1(x):\n",
    "    return softmax(x, axis=1)\n",
    "\n",
    "\n",
    "def get_model(input_dim, window_size, output_dim, lstm_layer_count=5, drop_rate=0.2):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=100, input_shape=(window_size, input_dim), return_sequences=True, kernel_initializer=Ones()))\n",
    "    model.add(Dropout(rate=0.2))\n",
    "\n",
    "    for i in range(lstm_layer_count - 2):\n",
    "        model.add(LSTM(units=100, return_sequences=True))\n",
    "        model.add(Dropout(rate=drop_rate))\n",
    "    \n",
    "    model.add(LSTM(output_dim, activation=softMaxAxis1))\n",
    "    # TODO: custom loss function\n",
    "    model.compile(loss='MAPE', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# region Error metric\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def root_mean_square_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "\n",
    "    return np.mean((y_true - y_pred) / y_true)\n",
    "\n",
    "\n",
    "def relative_root_mean_square_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    res = (y_true - y_pred) / y_true\n",
    "    res = np.power(res, 2)\n",
    "    res = np.mean(res)\n",
    "    res = math.sqrt(res)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "# endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# region Data preprocessing\n",
    "# reprocessing data\n",
    "def next_window(df, i, windows_size, prediction_size, input_col, output_col, time_col):\n",
    "    '''Generates the next data window from the given index location i'''\n",
    "    window = df[i: i + windows_size + prediction_size]\n",
    "    x = window[input_col][:-prediction_size]\n",
    "    y = window[output_col][-prediction_size:]\n",
    "    y_time = window[time_col][-prediction_size:]\n",
    "    return x, y, y_time\n",
    "\n",
    "def smooting_data(df, window_size):\n",
    "    return df.ewm(span=window_size).mean()\n",
    "\n",
    "def preprocessing_data(df, windows_size, prediction_size, input_col, output_col, time_col):\n",
    "    '''\n",
    "    Create x, y train data windows\n",
    "    Warning: batch method, not generative, make sure you have enough memory to\n",
    "    load data, otherwise use generate_training_window() method.\n",
    "    '''\n",
    "\n",
    "\n",
    "    data_x = []\n",
    "    data_y = []\n",
    "    data_y_time = []\n",
    "    for i in range(len(df) - windows_size - prediction_size):\n",
    "        x, y, y_time = next_window(df, i, windows_size, prediction_size, input_col, output_col, time_col)\n",
    "        data_x.append(x.values)\n",
    "        data_y.append(y.values)\n",
    "        data_y_time.append(y_time)\n",
    "\n",
    "    time = pd.concat(data_y_time)\n",
    "\n",
    "    return np.array(data_x), np.array(data_y), time.values\n",
    "\n",
    "\n",
    "def split_train_test_data(X, y):\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "    return X_train, y_train, X_valid, y_valid\n",
    "\n",
    "\n",
    "# endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# region Model train\n",
    "# Trainning model\n",
    "def train_model(model, X_train, y_train, X_valid, y_valid, stock_name, year, window_size):\n",
    "    model_save_fname = os.path.join(model_dir, '%s-%s-w%d.h5' % (stock_name, year, window_size))\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=100),\n",
    "        ModelCheckpoint(filepath=model_save_fname, monitor='val_loss', save_best_only=True)\n",
    "    ]\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=1000,\n",
    "        batch_size=10000,\n",
    "        validation_data=(X_valid, y_valid),\n",
    "        verbose=1,\n",
    "        callbacks=callbacks,\n",
    "        shuffle=False)\n",
    "    model.save(model_save_fname)\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "# endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# region Test model\n",
    "def test_model(model, test_data, window_size, prediction_size, input_col, output_col, time_col):\n",
    "    X, y, time = preprocessing_data(test_data, window_size, prediction_size, input_col, output_col, time_col)\n",
    "    \n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    y_pred = np.repeat(y_pred, input_dim, axis=1)\n",
    "    y_pred = scaler.inverse_transform(y_pred)[:, [0]]\n",
    "    y_pred = pd.Series(y_pred.flatten())\n",
    "\n",
    "    df_test_result = pd.DataFrame(time, columns=['Date'])\n",
    "    df_test_result['Prediction'] = y_pred\n",
    "    df_test_result.set_index('Date', inplace=True)\n",
    "\n",
    "    return df_test_result\n",
    "\n",
    "\n",
    "def plot_test_result(test_result, stock_name, year, window_size):\n",
    "    # Plotly\n",
    "    trace0 = go.Scatter(\n",
    "        x=test_result.index,\n",
    "        y=test_result['Close'],\n",
    "        name='Thực tế',\n",
    "        line=dict(\n",
    "            color=('#5042f4'),\n",
    "            width=2)\n",
    "    )\n",
    "\n",
    "    trace1 = go.Scatter(\n",
    "        x=test_result.index,\n",
    "        y=test_result['Prediction'],\n",
    "        name='Dự đoán',\n",
    "        line=dict(\n",
    "            color=('#005b4e'),\n",
    "            width=2,\n",
    "            dash='dot'\n",
    "        )  # dash options include 'dash', 'dot', and 'dashdot'\n",
    "    )\n",
    "\n",
    "    data = [trace0, trace1]\n",
    "\n",
    "    # Edit the layout\n",
    "    layout = dict(title='Biểu đồ dự đoán',\n",
    "                  xaxis=dict(title='Date'),\n",
    "                  yaxis=dict(title='Price'),\n",
    "                  paper_bgcolor='#FFF9F5',\n",
    "                  plot_bgcolor='#FFF9F5'\n",
    "                  )\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    fig.write_html(os.path.join(plot_dir, '%s_%s_w%d.html' % (stock_name, year, window_size)), auto_open=False)\n",
    "\n",
    "# endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window size is 3                                     \n",
      "  0%|          | 0/100 [00:00<?, ?it/s, best loss: ?]WARNING:tensorflow:From C:\\Users\\Seth\\Miniconda3\\envs\\tfs\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Seth\\Miniconda3\\envs\\tfs\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Seth\\Miniconda3\\envs\\tfs\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Seth\\Miniconda3\\envs\\tfs\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Seth\\Miniconda3\\envs\\tfs\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Seth\\Miniconda3\\envs\\tfs\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Seth\\Miniconda3\\envs\\tfs\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Seth\\Miniconda3\\envs\\tfs\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Seth\\Miniconda3\\envs\\tfs\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Seth\\Miniconda3\\envs\\tfs\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 38 samples, validate on 10 samples          \n",
      "Epoch 1/1000                                         \n",
      "  0%|          | 0/100 [00:08<?, ?it/s, best loss: ?]WARNING:tensorflow:From C:\\Users\\Seth\\Miniconda3\\envs\\tfs\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Seth\\Miniconda3\\envs\\tfs\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Seth\\Miniconda3\\envs\\tfs\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Seth\\Miniconda3\\envs\\tfs\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Seth\\Miniconda3\\envs\\tfs\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "38/38 [==============================]               \n",
      " - 11s 290ms/step - loss: 581.0742 - acc: 0.0000e+00 - val_loss: 27.3235 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 2/1000                                         \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 573.1251 - acc: 0.0000e+00 - val_loss: 30.0864 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 3/1000                                         \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 565.3142 - acc: 0.0000e+00 - val_loss: 33.4165 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 4/1000                                         \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 555.6868 - acc: 0.0000e+00 - val_loss: 37.5962 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 5/1000                                         \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 544.8906 - acc: 0.0000e+00 - val_loss: 42.9326 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 6/1000                                         \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 527.6692 - acc: 0.0000e+00 - val_loss: 49.7235 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 7/1000                                         \n",
      "38/38 [==============================]               \n",
      " - 0s 3ms/step - loss: 508.7167 - acc: 0.0000e+00 - val_loss: 58.3167 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 8/1000                                         \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 487.7076 - acc: 0.0000e+00 - val_loss: 68.9752 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 9/1000                                         \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 466.2145 - acc: 0.0000e+00 - val_loss: 81.9197 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 10/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 3ms/step - loss: 429.2265 - acc: 0.0000e+00 - val_loss: 97.3216 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 11/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 4ms/step - loss: 388.4477 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 12/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 340.6403 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 13/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 3ms/step - loss: 306.4331 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 14/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 3ms/step - loss: 269.1726 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 15/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 4ms/step - loss: 223.2470 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 16/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 3ms/step - loss: 200.3593 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 17/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 139.4020 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 18/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 126.5756 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 19/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 106.6138 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 20/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 98.7164 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 21/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 96.9420 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 22/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 23/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 1ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 3ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 25/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 26/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 3ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 27/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 3ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 28/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 29/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 30/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 31/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 32/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 33/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 34/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 35/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 3ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 36/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 37/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 38/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 3ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 39/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 6ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 40/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 5ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 41/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 4ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 42/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 43/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 44/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 45/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 46/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 47/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 48/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 49/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 3ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 50/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 51/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 52/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 53/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 54/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 3ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 55/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 56/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 57/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 58/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 4ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 59/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 60/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 61/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 62/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 6ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 63/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 64/1000                                        \n",
      "38/38 [==============================]               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s 3ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 65/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 66/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 67/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 68/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 3ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 69/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 70/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 1ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 71/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 72/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 73/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 74/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 75/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 76/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 77/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 3ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 78/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 1ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 79/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 80/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 81/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 82/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 83/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 1ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 84/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 85/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 86/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 87/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 88/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 89/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 90/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 91/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 92/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 93/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 94/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 95/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 96/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 97/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 98/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 99/1000                                        \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 100/1000                                       \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 101/1000                                       \n",
      "38/38 [==============================]               \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Window size is 2                                                                \n",
      "Train on 39 samples, validate on 10 samples                                     \n",
      "Epoch 1/1000                                                                    \n",
      "39/39 [==============================]                                          \n",
      " - 15s 384ms/step - loss: 500.2750 - acc: 0.0000e+00 - val_loss: 26.6484 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 2/1000                                                                    \n",
      "39/39 [==============================]                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s 1ms/step - loss: 495.9534 - acc: 0.0000e+00 - val_loss: 28.0470 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 3/1000                                                                    \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 491.5462 - acc: 0.0000e+00 - val_loss: 29.7825 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 4/1000                                                                    \n",
      "39/39 [==============================]                                          \n",
      " - 0s 992us/step - loss: 486.8152 - acc: 0.0000e+00 - val_loss: 31.7845 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 5/1000                                                                    \n",
      "39/39 [==============================]                                          \n",
      " - 0s 865us/step - loss: 481.2051 - acc: 0.0000e+00 - val_loss: 34.2095 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 6/1000                                                                    \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 475.3090 - acc: 0.0000e+00 - val_loss: 37.2247 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 7/1000                                                                    \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 468.4413 - acc: 0.0000e+00 - val_loss: 41.0096 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 8/1000                                                                    \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 458.7439 - acc: 0.0000e+00 - val_loss: 45.7657 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 9/1000                                                                    \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 450.1798 - acc: 0.0000e+00 - val_loss: 51.7447 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 10/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 438.1952 - acc: 0.0000e+00 - val_loss: 59.1948 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 11/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 422.9598 - acc: 0.0000e+00 - val_loss: 68.3196 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 12/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 408.2711 - acc: 0.0000e+00 - val_loss: 79.3081 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 13/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 386.0086 - acc: 0.0000e+00 - val_loss: 92.3528 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 14/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 365.5237 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 15/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 336.9073 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 16/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 300.1636 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 17/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 4ms/step - loss: 284.2375 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 18/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 272.0528 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 19/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 244.3059 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 20/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 221.9722 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 21/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 3ms/step - loss: 202.2629 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 22/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 165.4967 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 23/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 7ms/step - loss: 142.4801 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 24/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 1s 18ms/step - loss: 129.1304 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 25/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 6ms/step - loss: 112.8259 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 26/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 101.6777 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 27/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 98.9354 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 28/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 98.7462 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 29/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 30/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 903us/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 31/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 32/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 33/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 34/1000                                                                   \n",
      "39/39 [==============================]                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 35/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 36/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 37/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 38/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 954us/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 39/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 40/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 41/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 42/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 43/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 44/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 45/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 46/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 47/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 48/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 49/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 50/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 5ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 51/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 52/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 53/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 54/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 55/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 56/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 57/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 58/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 3ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 59/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 60/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 61/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 62/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 63/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 3ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 64/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 65/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 3ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 66/1000                                                                   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 67/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 68/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 69/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 3ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 70/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 71/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 72/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 73/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 74/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 75/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 76/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 77/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 78/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 79/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 80/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 81/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 82/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 83/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 84/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 85/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 86/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 87/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 88/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 89/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 90/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 91/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 92/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 93/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 94/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 95/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 96/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 97/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 98/1000                                                                   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 99/1000                                                                   \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 100/1000                                                                  \n",
      "39/39 [==============================]                                          \n",
      " - 0s 2ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 101/1000                                                                  \n",
      "39/39 [==============================]                                          \n",
      " - 0s 1ms/step - loss: 100.0000 - acc: 0.0000e+00 - val_loss: 100.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Window size is 3                                                                \n",
      "Train on 38 samples, validate on 10 samples                                     \n",
      "Epoch 1/1000                                                                    \n",
      "  2%|▏         | 2/100 [01:32<1:03:10, 38.67s/it, best loss: 29.133024312122892]"
     ]
    }
   ],
   "source": [
    "# region Bayers\n",
    "def objective(params, df):\n",
    "    # Keep track of evals\n",
    "    global ITERATION\n",
    "\n",
    "    ITERATION += 1\n",
    "\n",
    "    # Make sure windows_size is int\n",
    "    windows_size = int(params['windows_size'])\n",
    "    print(f'Window size is {windows_size}')\n",
    "\n",
    "    model = get_model(input_dim, windows_size, output_dim)\n",
    "\n",
    "    start = timer()\n",
    "\n",
    "    # Handle data\n",
    "    df.describe()\n",
    "    # TODO: smoothing ddata\n",
    "    df[input_col] = smooting_data(df[input_col], windows_size)\n",
    "\n",
    "    X, y, time = preprocessing_data(df, windows_size, prediction_size, input_col, output_col, time_col)\n",
    "\n",
    "    # Reshape data\n",
    "    y = y.reshape((y.shape[0], y.shape[1]))\n",
    "\n",
    "    X_train, y_train, X_valid, y_valid = split_train_test_data(X, y)\n",
    "\n",
    "    # Perform n_train\n",
    "    history = train_model(model, X_train, y_train, X_valid, y_valid, stock_name, year, windows_size)\n",
    "\n",
    "    run_time = timer() - start\n",
    "\n",
    "    # Test generated loss\n",
    "    test_result = test_model(model, df, windows_size, prediction_size, input_col, output_col, time_col)\n",
    "    test_result = test_result.join(df_org.set_index('Date'))\n",
    "\n",
    "    mae = mean_absolute_error(test_result['Close'], test_result['Prediction'])\n",
    "    mse = mean_squared_error(test_result['Close'], test_result['Prediction'])\n",
    "    mape = mean_absolute_percentage_error(test_result['Close'], test_result['Prediction'])\n",
    "    rrmse = relative_root_mean_square_error(test_result['Close'], test_result['Prediction'])\n",
    "\n",
    "    #print(f'{stock_name} prediction for {prediction_size} day ahead')\n",
    "    #print(f'MAE = {mae}')\n",
    "    #print(f'MSE = {mse}')\n",
    "    #print(f'MAPE = {mape}')\n",
    "    #print(f'RRMSE = {rrmse}')\n",
    "\n",
    "    plot_test_result(test_result, stock_name, year, windows_size)\n",
    "    loss = mape\n",
    "\n",
    "    # write row\n",
    "    of_connection = open(result_save_fname, 'a')\n",
    "    writer = csv.writer(of_connection)\n",
    "    writer.writerow([stock_name, year, loss, params, ITERATION, windows_size, run_time])\n",
    "    of_connection.close()\n",
    "\n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': loss, 'params': params, 'iteration': ITERATION, 'test_result': test_result,\n",
    "            'train_time': run_time, 'status': STATUS_OK}\n",
    "\n",
    "start_year = df_org['Date'].values[:1][0]\n",
    "start_year = pd.to_datetime(start_year).year\n",
    "\n",
    "end_year = df_org['Date'].values[-1:][0]\n",
    "end_year = pd.to_datetime(end_year).year\n",
    "\n",
    "windows_size_best = []\n",
    "# Global variable\n",
    "global ITERATION\n",
    "\n",
    "for year in range(start_year, end_year + 1):\n",
    "    df = df_org[df_org['Date'].dt.year == year]\n",
    "\n",
    "    # Data too small, skip\n",
    "    if df.shape[0] < 10:\n",
    "        continue\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_cols = scaler.fit_transform(df[input_col])\n",
    "    df[input_col] = scaled_cols\n",
    "\n",
    "    # Hyperparameter grid\n",
    "    param_grid = {\n",
    "        'windows_size': hp.choice('windows_size', np.arange(1, 8, dtype=int))\n",
    "    }\n",
    "\n",
    "    bayes_trials = Trials()\n",
    "\n",
    "    # Create the algorithm\n",
    "    bayes_algo = tpe.suggest\n",
    "\n",
    "    ITERATION = 0\n",
    "\n",
    "    fmin_objective = partial(objective, df=df)\n",
    "    bayes_best = fmin(fn=fmin_objective, space=param_grid,\n",
    "                      algo=bayes_algo, trials=bayes_trials,\n",
    "                      max_evals=bayer_max_evals)\n",
    "\n",
    "    best_model_fname = os.path.join(model_dir, '%s-%s-w%d.h5' % (stock_name, year, bayes_best['window_size']))\n",
    "    of_connection = open(bayer_save_fname, 'a')\n",
    "    writer = csv.writer(of_connection)\n",
    "    writer.writerow([stock_name, year, bayes_best, best_model_fname])\n",
    "    of_connection.close()\n",
    "\n",
    "    windows_size_best.append([year, bayes_best])\n",
    "# endregion\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
