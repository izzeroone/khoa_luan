{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  },
  "colab": {
   "name": "price_prediction_colab.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "NVNIXoLJTtZT",
    "colab_type": "code",
    "outputId": "095c6130-71c9-4cd9-cc8b-664a3d3d2529",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "!pip install yfinance"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Requirement already satisfied: yfinance in c:\\users\\seth\\miniconda3\\envs\\tfs\\lib\\site-packages (0.1.50)\nRequirement already satisfied: numpy>=1.15 in c:\\users\\seth\\miniconda3\\envs\\tfs\\lib\\site-packages (from yfinance) (1.16.5)\nRequirement already satisfied: pandas>=0.24 in c:\\users\\seth\\miniconda3\\envs\\tfs\\lib\\site-packages (from yfinance) (0.25.1)\nRequirement already satisfied: requests>=2.20 in c:\\users\\seth\\miniconda3\\envs\\tfs\\lib\\site-packages (from yfinance) (2.22.0)\nRequirement already satisfied: multitasking>=0.0.7 in c:\\users\\seth\\miniconda3\\envs\\tfs\\lib\\site-packages (from yfinance) (0.0.9)\nRequirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\seth\\miniconda3\\envs\\tfs\\lib\\site-packages (from pandas>=0.24->yfinance) (2.8.0)\nRequirement already satisfied: pytz>=2017.2 in c:\\users\\seth\\miniconda3\\envs\\tfs\\lib\\site-packages (from pandas>=0.24->yfinance) (2019.3)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\seth\\miniconda3\\envs\\tfs\\lib\\site-packages (from requests>=2.20->yfinance) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in c:\\users\\seth\\miniconda3\\envs\\tfs\\lib\\site-packages (from requests>=2.20->yfinance) (2019.9.11)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\seth\\miniconda3\\envs\\tfs\\lib\\site-packages (from requests>=2.20->yfinance) (1.24.2)\nRequirement already satisfied: idna<2.9,>=2.5 in c:\\users\\seth\\miniconda3\\envs\\tfs\\lib\\site-packages (from requests>=2.20->yfinance) (2.8)\nRequirement already satisfied: six>=1.5 in c:\\users\\seth\\miniconda3\\envs\\tfs\\lib\\site-packages (from python-dateutil>=2.6.1->pandas>=0.24->yfinance) (1.12.0)\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "id": "lBhQeeUfTpFn",
    "colab_type": "code",
    "outputId": "6fafd253-0d60-4efb-c26a-cc5e8b28f765",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 79
    }
   },
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "# region Import\n",
    "# Data download\n",
    "# Import basic\n",
    "import csv\n",
    "import math\n",
    "import os\n",
    "import warnings\n",
    "# Init google drive\n",
    "# from google.colab import drive\n",
    "from datetime import datetime\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Plottool\n",
    "import plotly.graph_objs as go\n",
    "# IPython\n",
    "from IPython.display import display\n",
    "# Hyperopt bayesian optimization\n",
    "from hyperopt import hp, Trials, tpe, fmin, STATUS_OK, partial\n",
    "# Keras\n",
    "from keras import Sequential\n",
    "from keras.activations import softmax\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint  \n",
    "from keras.initializers import Ones\n",
    "from keras.layers import LSTM, Dropout, Input\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "# SKLearn\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# yfinance\n",
    "import yfinance as yf\n",
    "\n",
    "# endregion"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "d3tEgtncTpFt",
    "colab_type": "code",
    "outputId": "5482b058-be01-41f0-8936-89ab2be4c158",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "current_timestamp = datetime.now().strftime('%d%m%Y_%H%M%S')\n",
    "\n",
    "# region File mount and config\n",
    "# drive.mount('/content/gdrive', force_remount=True)\n",
    "# root_dir = \"/content/gdrive/My Drive/stock\"\n",
    "root_dir = \"\"\n",
    "\n",
    "time_dir = os.path.join(root_dir, \"result\")\n",
    "\n",
    "data_dir = os.path.join(root_dir, \"data\")\n",
    "model_dir = os.path.join(time_dir, 'model')\n",
    "plot_dir = os.path.join(time_dir, 'plot')\n",
    "result_dir = os.path.join(time_dir, 'result')\n",
    "    \n",
    "pd.options.display.max_columns = 12\n",
    "pd.options.display.max_rows = 24\n",
    "\n",
    "# disable warnings in Anaconda\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# endregion"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "jv4S2287TpFy",
    "colab_type": "code",
    "outputId": "d6b406a8-b982-4afc-92e4-72fac4617279",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "# region Data Loading\n",
    "stock_name = '000001.SS'  # SSE Composite Index\n",
    "df_org = yf.download(stock_name, start=\"1991-01-01\", end=\"2016-12-31\", interval=\"1wk\")\n",
    "#df_org = pd.read_csv(f'{data_dir}/{stock_name}.csv', parse_dates=['Date'])\n",
    "df_org = df_org.sort_values('Date')\n",
    "df_org.to_csv(f'{data_dir}/{stock_name}.csv')\n",
    "df_org.reset_index(inplace=True)\n",
    "df_org = df_org[['Date', 'Close', 'Open', 'High', 'Low', 'Adj Close', 'Volume']]\n",
    "\n",
    "# endregion"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "\r[*********************100%***********************]  1 of 1 completed",
      "\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "knjf7C5mTpF1",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# region Data ploting\n",
    "def plot_ohlc(df):\n",
    "    trace = go.Ohlc(x=df['Date'],\n",
    "                    open=df['Open'],\n",
    "                    high=df['High'],\n",
    "                    low=df['Low'],\n",
    "                    close=df['Close'],\n",
    "                    increasing=dict(line=dict(color='#58FA58')),\n",
    "                    decreasing=dict(line=dict(color='#FA5858')))\n",
    "\n",
    "    layout = {\n",
    "        'title': f'{stock_name} Historical Price',\n",
    "        'xaxis': {'title': 'Date',\n",
    "                  'rangeslider': {'visible': False}},\n",
    "        'yaxis': {'title': f'Price'}\n",
    "    }\n",
    "\n",
    "    data = [trace]\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    fig.write_html(os.path.join(plot_dir, '%s_ohlc.html' % (stock_name)), auto_open=False)\n",
    "\n",
    "\n",
    "plot_ohlc(df_org)\n",
    "# endregion"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f88ab9245e93>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mplot_ohlc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_org\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;31m# endregion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-f88ab9245e93>\u001b[0m in \u001b[0;36mplot_ohlc\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplot_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'%s_ohlc.html'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstock_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauto_open\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tfs\\lib\\site-packages\\plotly\\basedatatypes.py\u001b[0m in \u001b[0;36mwrite_html\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2805\u001b[0m         \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2807\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2808\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2809\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mto_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tfs\\lib\\site-packages\\plotly\\io\\_html.py\u001b[0m in \u001b[0;36mwrite_html\u001b[1;34m(fig, file, config, auto_play, include_plotlyjs, include_mathjax, post_script, full_html, animation_opts, validate, default_width, default_height, auto_open)\u001b[0m\n\u001b[0;32m    525\u001b[0m     \u001b[1;31m# Write HTML string\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfile_is_str\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'result\\\\plot\\\\000001.SS_ohlc.html'"
     ],
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'result\\\\plot\\\\000001.SS_ohlc.html'",
     "output_type": "error"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "qoDIBhOUTpF6",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# region Create csv result file\n",
    "# File to save first results\n",
    "result_save_fname = os.path.join(result_dir, 'result_%s-%s.csv' % (stock_name, current_timestamp))\n",
    "of_connection = open(result_save_fname, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "# Write the headers to the file\n",
    "writer.writerow(['stock_name', 'year', 'loss', 'params', 'iteration', 'windows_size', 'train_time'])\n",
    "of_connection.close()\n",
    "\n",
    "# Create file to save bayer best\n",
    "bayer_save_fname = os.path.join(result_dir, 'bayer_best_%s-%s.csv' % (stock_name, current_timestamp))\n",
    "of_connection = open(bayer_save_fname, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "# Write the headers to the file\n",
    "writer.writerow(['stock_name', 'year', 'params', 'model_save_location'])\n",
    "of_connection.close()\n",
    "# endregion"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "ccE650XpTpF-",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "outputId": "cddcef68-947f-4bc7-e6f4-86b88f4ffa5f"
   },
   "source": [
    "# region Sample data\n",
    "\n",
    "df_org.sample(10)\n",
    "\n",
    "# endregion"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "qeFNPDPrTpGB",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# region Const\n",
    "# Declare const\n",
    "input_col = ['Close', 'Open', 'High', 'Low', 'Adj Close', 'Volume']\n",
    "output_col = ['Close']\n",
    "time_col = ['Date']\n",
    "\n",
    "# Input dimension\n",
    "input_dim = len(input_col)\n",
    "# Output dimension\n",
    "output_dim = len(output_col)\n",
    "\n",
    "# Number of session to prediction as one time\n",
    "prediction_size = 1\n",
    "# For each time model is train, the first is display\n",
    "sample_display_test_size = 5\n",
    "# Max bayer iteration\n",
    "bayer_max_evals = 100\n",
    "\n",
    "\n",
    "# endregion"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "XVCpo_-OTpGE",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# region Declare model\n",
    "# declare model\n",
    "def softMaxAxis1(x):\n",
    "    return softmax(x, axis=1)\n",
    "\n",
    "\n",
    "def get_model(input_dim, window_size, output_dim, lstm_layer_count=5, drop_rate=0.2):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=100, input_shape=(window_size, input_dim), return_sequences=True, kernel_initializer=Ones()))\n",
    "    model.add(Dropout(rate=0.2))\n",
    "\n",
    "    for i in range(lstm_layer_count - 2):\n",
    "        model.add(LSTM(units=100, return_sequences=True))\n",
    "        model.add(Dropout(rate=drop_rate))\n",
    "    \n",
    "    model.add(LSTM(output_dim, activation=softMaxAxis1))\n",
    "    # TODO: custom loss function\n",
    "    model.compile(loss=mape_loss, optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# endregion"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "-C7Xrt3NTpGG",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# region Error metric\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "test_1 = []\n",
    "test_2 = []\n",
    "def mape_loss(y_true, y_pred):\n",
    "    test_1 = y_true\n",
    "    test_2 = y_pred\n",
    "    return K.mean(K.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def root_mean_square_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "\n",
    "    return np.mean((y_true - y_pred) / y_true)\n",
    "\n",
    "\n",
    "def relative_root_mean_square_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    res = (y_true - y_pred) / y_true\n",
    "    res = np.power(res, 2)\n",
    "    res = np.mean(res)\n",
    "    res = math.sqrt(res)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "# endregion"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "seFrKpyUTpGJ",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# region Data preprocessing\n",
    "# reprocessing data\n",
    "def next_window(df, i, windows_size, prediction_size, input_col, output_col, time_col):\n",
    "    '''Generates the next data window from the given index location i'''\n",
    "    window = df[i: i + windows_size + prediction_size]\n",
    "    x = window[input_col][:-prediction_size]\n",
    "    y = window[output_col][-prediction_size:]\n",
    "    y_time = window[time_col][-prediction_size:]\n",
    "    return x, y, y_time\n",
    "\n",
    "def smooting_data(df, window_size):\n",
    "    return df.ewm(span=window_size).mean()\n",
    "\n",
    "def preprocessing_data(df, windows_size, prediction_size, input_col, output_col, time_col):\n",
    "    '''\n",
    "    Create x, y train data windows\n",
    "    Warning: batch method, not generative, make sure you have enough memory to\n",
    "    load data, otherwise use generate_training_window() method.\n",
    "    '''\n",
    "\n",
    "\n",
    "    data_x = []\n",
    "    data_y = []\n",
    "    data_y_time = []\n",
    "    for i in range(len(df) - windows_size - prediction_size):\n",
    "        x, y, y_time = next_window(df, i, windows_size, prediction_size, input_col, output_col, time_col)\n",
    "        data_x.append(x.values)\n",
    "        data_y.append(y.values)\n",
    "        data_y_time.append(y_time)\n",
    "\n",
    "    time = pd.concat(data_y_time)\n",
    "\n",
    "    return np.array(data_x), np.array(data_y), time.values\n",
    "\n",
    "\n",
    "def split_train_test_data(X, y):\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "    return X_train, y_train, X_valid, y_valid\n",
    "\n",
    "\n",
    "# endregion"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "Y7gCFHqLTpGN",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# region Model train\n",
    "# Trainning model\n",
    "def train_model(model, X_train, y_train, X_valid, y_valid, stock_name, year, window_size):\n",
    "    model_save_fname = os.path.join(model_dir, '%s-%s-w%d-%s.h5' % (stock_name, year, window_size, current_timestamp))\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=100),\n",
    "        ModelCheckpoint(filepath=model_save_fname, monitor='val_loss', save_best_only=True)\n",
    "    ]\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=1000,\n",
    "        batch_size=10000,\n",
    "        validation_data=(X_valid, y_valid),\n",
    "        verbose=1,\n",
    "        callbacks=callbacks,\n",
    "        shuffle=False)\n",
    "    model.save(model_save_fname)\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "# endregion"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "PRoOfwYLTpGR",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# region Test model\n",
    "def test_model(model, test_data, window_size, prediction_size, input_col, output_col, time_col):\n",
    "    X, y, time = preprocessing_data(test_data, window_size, prediction_size, input_col, output_col, time_col)\n",
    "    \n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    y_pred = np.repeat(y_pred, input_dim, axis=1)\n",
    "    y_pred = scaler.inverse_transform(y_pred)[:, [0]]\n",
    "    y_pred = pd.Series(y_pred.flatten())\n",
    "\n",
    "    df_test_result = pd.DataFrame(time, columns=['Date'])\n",
    "    df_test_result['Prediction'] = y_pred\n",
    "    df_test_result.set_index('Date', inplace=True)\n",
    "\n",
    "    return df_test_result\n",
    "\n",
    "\n",
    "def plot_test_result(test_result, stock_name, year, window_size):\n",
    "    # Plotly\n",
    "    trace0 = go.Scatter(\n",
    "        x=test_result.index,\n",
    "        y=test_result['Close'],\n",
    "        name='Thực tế',\n",
    "        line=dict(\n",
    "            color=('#5042f4'),\n",
    "            width=2)\n",
    "    )\n",
    "\n",
    "    trace1 = go.Scatter(\n",
    "        x=test_result.index,\n",
    "        y=test_result['Prediction'],\n",
    "        name='Dự đoán',\n",
    "        line=dict(\n",
    "            color=('#005b4e'),\n",
    "            width=2,\n",
    "            dash='dot'\n",
    "        )  # dash options include 'dash', 'dot', and 'dashdot'\n",
    "    )\n",
    "\n",
    "    data = [trace0, trace1]\n",
    "\n",
    "    # Edit the layout\n",
    "    layout = dict(title='Biểu đồ dự đoán',\n",
    "                  xaxis=dict(title='Date'),\n",
    "                  yaxis=dict(title='Price'),\n",
    "                  paper_bgcolor='#FFF9F5',\n",
    "                  plot_bgcolor='#FFF9F5'\n",
    "                  )\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    fig.write_html(os.path.join(plot_dir, '%s_%s_w%d_%s.html' % (stock_name, year, window_size, current_timestamp)), auto_open=False)\n",
    "\n",
    "# endregion"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "6XbVQtCsTpGT",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "c765dfdc-6164-45ec-b0f2-d4689fe06575"
   },
   "source": [
    "# region Bayers\n",
    "def objective(params, df):\n",
    "    # Keep track of evals\n",
    "    global ITERATION\n",
    "\n",
    "    ITERATION += 1\n",
    "\n",
    "    # Make sure windows_size is int\n",
    "    windows_size = int(params['windows_size'])\n",
    "    print(f'Window size is {windows_size}')\n",
    "\n",
    "    model = get_model(input_dim, windows_size, output_dim)\n",
    "\n",
    "    start = timer()\n",
    "\n",
    "    # Handle data\n",
    "    df.describe()\n",
    "    # TODO: smoothing ddata\n",
    "    df[input_col] = smooting_data(df[input_col], windows_size)\n",
    "\n",
    "    X, y, time = preprocessing_data(df, windows_size, prediction_size, input_col, output_col, time_col)\n",
    "\n",
    "    # Reshape data\n",
    "    y = y.reshape((y.shape[0], y.shape[1]))\n",
    "\n",
    "    X_train, y_train, X_valid, y_valid = split_train_test_data(X, y)\n",
    "\n",
    "    # Perform n_train\n",
    "    history = train_model(model, X_train, y_train, X_valid, y_valid, stock_name, year, windows_size)\n",
    "\n",
    "    run_time = timer() - start\n",
    "\n",
    "    # Test generated loss\n",
    "    test_result = test_model(model, df, windows_size, prediction_size, input_col, output_col, time_col)\n",
    "    test_result = test_result.join(df_org.set_index('Date'))\n",
    "\n",
    "    mae = mean_absolute_error(test_result['Close'], test_result['Prediction'])\n",
    "    mse = mean_squared_error(test_result['Close'], test_result['Prediction'])\n",
    "    mape = mean_absolute_percentage_error(test_result['Close'], test_result['Prediction'])\n",
    "    rrmse = relative_root_mean_square_error(test_result['Close'], test_result['Prediction'])\n",
    "\n",
    "    #print(f'{stock_name} prediction for {prediction_size} day ahead')\n",
    "    #print(f'MAE = {mae}')\n",
    "    #print(f'MSE = {mse}')\n",
    "    #print(f'MAPE = {mape}')\n",
    "    #print(f'RRMSE = {rrmse}')\n",
    "\n",
    "    plot_test_result(test_result, stock_name, year, windows_size)\n",
    "    loss = mape\n",
    "\n",
    "    # write row\n",
    "    of_connection = open(result_save_fname, 'a')\n",
    "    writer = csv.writer(of_connection)\n",
    "    writer.writerow([stock_name, year, loss, params, ITERATION, windows_size, run_time])\n",
    "    of_connection.close()\n",
    "\n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': loss, 'params': params, 'iteration': ITERATION, 'test_result': test_result,\n",
    "            'train_time': run_time, 'status': STATUS_OK}\n",
    "\n",
    "start_year = df_org['Date'].values[:1][0]\n",
    "start_year = pd.to_datetime(start_year).year\n",
    "\n",
    "end_year = df_org['Date'].values[-1:][0]\n",
    "end_year = pd.to_datetime(end_year).year\n",
    "\n",
    "windows_size_best = []\n",
    "# Global variable\n",
    "global ITERATION\n",
    "\n",
    "for year in range(start_year, end_year + 1):\n",
    "    df = df_org[df_org['Date'].dt.year == year]\n",
    "\n",
    "    # Data too small, skip\n",
    "    if df.shape[0] < 10:\n",
    "        continue\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_cols = scaler.fit_transform(df[input_col])\n",
    "    df[input_col] = scaled_cols\n",
    "\n",
    "    # Hyperparameter grid\n",
    "    param_grid = {\n",
    "        'windows_size': hp.choice('windows_size', np.arange(1, 8, dtype=int))\n",
    "    }\n",
    "\n",
    "    bayes_trials = Trials()\n",
    "\n",
    "    # Create the algorithm\n",
    "    bayes_algo = tpe.suggest\n",
    "\n",
    "    ITERATION = 0\n",
    "\n",
    "    fmin_objective = partial(objective, df=df)\n",
    "    bayes_best = fmin(fn=fmin_objective, space=param_grid,\n",
    "                      algo=bayes_algo, trials=bayes_trials,\n",
    "                      max_evals=bayer_max_evals)\n",
    "\n",
    "    best_model_fname = os.path.join(model_dir, '%s-%s-w%d-%s.h5' % (stock_name, year, bayes_best['window_size'], current_timestamp))\n",
    "    of_connection = open(bayer_save_fname, 'a')\n",
    "    writer = csv.writer(of_connection)\n",
    "    writer.writerow([stock_name, year, bayes_best, best_model_fname])\n",
    "    of_connection.close()\n",
    "\n",
    "    windows_size_best.append([year, bayes_best])\n",
    "# endregion"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}